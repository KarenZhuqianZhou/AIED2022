ENTRYTYPE,ID,abstract,address,articleno,author,booktitle,doi,isbn,keywords,location,numpages,pages,publisher,series,title,url,year
inproceedings,10.1145/3386527.3406207,"With its roots dating to popular television shows of the 1960s such as Star Trek, fanfiction has blossomed into an extremely widespread form of creative expression. In the past 20 years, amateur fanfiction writers, often young people between the ages of 13 and 25, have published over 61.5 billion words of fiction in online repositories, an amount that rivals the Google Books English fiction corpus of 80 billion words covering the past five centuries. Far from mere shallow repositories of pop culture, these sites are accumulating significant evidence that sophisticated informal learning is taking place online in novel and unexpected ways.Dr. Katie Davis will discuss insights from her book, Writers in the Secret Garden: Fanfiction, Youth, and New Forms of Mentoring (Aragon &amp; Davis, 2019). Davis will describe how young people are utilizing new forms of technology to mentor each other in writing fanfiction, and developing their writing skills in the process.Over the course of five years, Davis and her co-author Dr. Cecilia Aragon conducted original mixed-methods research of online fanfiction repositories, combining their respective skills in data science and education. During the course of their research, they discovered a new kind of mentoring, which they call distributed mentoring, that is uniquely suited to networked communities, where people of all ages and experience levels engage with and support one another through a complex, interwoven tapestry of interactive, cumulatively sophisticated advice and informal instruction. Davis will use the insights from this research to reflect on what it is, exactly, about networked publics that can so effectively support interest-driven learning, and she will consider whether it's possible to apply these lessons to formal education environments.","New York, NY, USA",,"Davis, Katie",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406207,9.78145E+12,"fanfiction, mentorship, online communities, informal learning, interest-driven learning, distributed mentoring","Virtual Event, USA",1,1,Association for Computing Machinery,L@S '20,What My Little Pony Can Teach Us About Interest-Driven Learning,https://doi.org/10.1145/3386527.3406207,2020
inproceedings,10.1145/3386527.3405929,"The late 2000s and 2010s saw the full arc of a dramatic hype cycle in learning at scale, where charismatic technologists made bold and ultimately unfounded predictions about how technologies would disrupt schooling systems. Looking toward the 2020s, a more productive approach to learning at scale is the tinkerer's stance, one that emphasizes incremental improvements on the long history of learning at scale. This article offers two organizational constructs for navigating and building on that history. Classifying learning-at-scale technologies into three genres-instructor-guided, algorithm-guided, and peer-guided approaches-helps identify how emerging technologies build on prior efforts and throws into relief that which is genuinely new. Four as-yet intractable dilemmas-the curse of the familiar, the edtech Matthew effect, the trap of routine assessment, and the toxic power of data and experiments-offer a set of grand challenges that learning-at-scale tinkerers will need to tackle in order to see more dramatic improvements in school systems.","New York, NY, USA",,"Reich, Justin",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405929,9.78145E+12,"synthesis, adaptive tutors, learning at scale, moocs, peer learning","Virtual Event, USA",11,3?€?13,Association for Computing Machinery,L@S '20,"Two Stances, Three Genres, and Four Intractable Dilemmas for the Future of Learning at Scale",https://doi.org/10.1145/3386527.3405929,2020
inproceedings,10.1145/3386527.3405922,"As online education proliferates, one concern that has been raised is that it may fail to capture desirable emergent phe-nomena from on-campus programs. Student community is one example of such a phenomenon: on-campus student communities thrive based on synchronous collocation. An online program might be designed to capture all deliberate constructs in an on-campus program, but there may be beneficial side effects of synchronous collocation that are not apparent. In this work, we examine the issue of social isolation in an online graduate program. By happenstance, three studies were conducted in relative isolation looking at social isolation from different angles. The first study exam-ined trajectories in social presence as a semester proceeded. The second study developed an understanding of students' needs with regard to community in an online program. The third study tested out an immersive virtual environment to try to improve students' sense of connectedness. Combin-ing their findings, we find compelling evidence of the exist-ence of a Synchronicity Paradox in online education: stu-dents desire synchronicity to form strong social communi-ties, and yet part of the chief appeal of these online pro-grams is their asynchronicity. In light of this finding, we provide design guidelines for how synchronicity may be reintroduced into asynchronous programs without sacrific-ing the benefits of asynchronicity. More specifically, we propose that scale itself may be the key to building emer-gent synchronicity.","New York, NY, USA",,"Joyner, David A. and Wang, Qiaosi and Thakare, Suyash and Jing, Shan and Goel, Ashok and MacIntyre, Blair",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405922,9.78145E+12,"student communities, online education, social presence, affordable degrees at scale","Virtual Event, USA",10,15?€?24,Association for Computing Machinery,L@S '20,The Synchronicity Paradox in Online Education,https://doi.org/10.1145/3386527.3405922,2020
inproceedings,10.1145/3386527.3405923,"Following the initial proliferation of Massive Open Online Courses (MOOCs), a more recent trend has emerged toward offering ""Affordable Degrees at Scale"" or ""Large, Internet-Mediated Asynchronous Degrees"". In this research, we set out to understand this space: the range in tuition costs for these programs, the variety of admissions standards, and the types of assessments used to evaluate these non-traditional students. In the process, however, we found that in many ways, these programs may not be as new as we initially perceived: similarly-priced online programs have existed from traditional universities for years. In this research, we explore these two questions: what are these new degrees at scale, and how do they actually differ from traditional programs? To explore this, we collected materials for 35 MOOC-based graduate degrees and numerous non-MOOC-based comparable degrees. We then explored the patterns in tuition, admissions requirements, and syllabus information. In this paper, we report the trends we identified in MOOC-based degrees, and attempt to answer the question: what makes these programs different from non-MOOC-based online programs of the past? Ultimately, we find that this new era of programs is similar in many observable ways.","New York, NY, USA",,"Park, David S. and Schmidt, Robert W. and Akiri, Charankumar and Kwak, Stephanie and Joyner, David A.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405923,9.78145E+12,"scalable degrees, online degrees, mooc, affordable degrees","Virtual Event, USA",11,25?€?35,Association for Computing Machinery,L@S '20,Affordable Degrees at Scale: New Phenomenon or New Hype?,https://doi.org/10.1145/3386527.3405923,2020
inproceedings,10.1145/3386527.3405924,"""Gaming the system"" is the phenomenon where students attempt to perform well by systematically exploiting properties of the learning system, rather than learning the material. Frequent gaming tends to cause bad learning outcomes. Though existing studies tackle the problem by redesigning the system workflow to change students' behaviors automatically, gaming students discover new ways to game. We instead propose a novel way, reflective nudge, to reflectively influence students' attitudes by conveying reasons not to game via information visualizations. Particularly, we identify three common gaming contexts and involve students and instructors in co-designing three context-specific persuasive visualizations. We deploy our information visualizations in a real online learning platform. Through embedded surveys and in-person interviews, we find some evidence that the designs can promote students' reflection on gaming, and suggestive data that two of them can reduce gaming compared with control groups. Furthermore, we present insights into reflective nudge designs and practical issues concerning deployment.","New York, NY, USA",,"Xia, Meng and Asano, Yuya and Williams, Joseph Jay and Qu, Huamin and Ma, Xiaojuan",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405924,9.78145E+12,"reflective nudge, reflection, online learning, information visualization, gaming the system","Virtual Event, USA",13,37?€?49,Association for Computing Machinery,L@S '20,"Using Information Visualization to Promote Students' Reflection on ""Gaming the System"" in Online Learning",https://doi.org/10.1145/3386527.3405924,2020
inproceedings,10.1145/3386527.3405927,"Retrieval practice (also known as testing effect or test-enhanced learning) is a well-studied and established technique for improving the retention of knowledge. Many previous works have confirmed the benefits of retrieval practice in laboratory experiments involving the memorization of words or facts. In this study, we build on these works and analyze retrieval practice in an intelligent tutoring system. Using a large data set composed of the actions of almost 4 million students studying math and chemistry, we look at the possible benefits of retrieval practice in the ALEKS adaptive learning and assessment system. We compare two different types of retrieval practice---one involving the assessment of learned material, and another involving the learning of closely related content that builds on the learned material---leveraging the scale of the available data to control for several confounding variables. Finally, we look at the timing of retrieval practice within the system and the possible effect it has on forgetting. The results indicate that a delay in retrieval practice is associated with better retention and that, while being assessed on learned material is beneficial, the learning of closely related content is associated with an even higher rate of retention.","New York, NY, USA",,"Matayoshi, Jeffrey and Uzun, Hasan and Cosyn, Eric",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405927,9.78145E+12,"forgetting curves, knowledge space theory, marginal model, retrieval practice, intelligent tutoring system, generalized estimating equations","Virtual Event, USA",12,51?€?62,Association for Computing Machinery,L@S '20,Studying Retrieval Practice in an Intelligent Tutoring System,https://doi.org/10.1145/3386527.3405927,2020
inproceedings,10.1145/3386527.3405917,"Large-scale educational settings have been common domains for affect detection and recognition research. Most research emphasizes improvements in the accuracy of affect measurement to enhance instructors' efficiency in managing large numbers of students. However, these technologies are not designed from students' perspectives, nor designed for students' own usage. To identify the unique design considerations for affect sensors that consider student capacities and challenges, and explore the potential of affect sensors to support students' self-learning, we conducted semi-structured interviews and surveys with both online students and on-campus students enrolled in large in-person classes. Drawing on these studies we: (a) propose using affect data to support students' self-regulated learning behaviors through a ""scaling for empowerment'' design perspective, (b) identify design guidelines to mitigate students' concerns regarding the use of affect data at scale, (c) provide design recommendations for the physical design of affect sensors for large educational settings.","New York, NY, USA",,"Wang, Qiaosi and Jing, Shan and Joyner, David and Wilcox, Lauren and Li, Hong and Pl\""{o}tz, Thomas and Disalvo, Betsy",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405917,9.78145E+12,"education, sensor design, privacy, affective computing, self-regulated learning, design","Virtual Event, USA",14,63?€?76,Association for Computing Machinery,L@S '20,Sensing Affect to Empower Students: Learner Perspectives on Affect-Sensitive Technology in Large Educational Contexts,https://doi.org/10.1145/3386527.3405917,2020
inproceedings,10.1145/3386527.3405928,"Choices learners make when navigating a self-directed online learning tool can impact the effectiveness of the experience. But these tools often do not afford learners the agency or the information to make decisions beneficial to their learning. We evaluated the effect of varying levels of information and agency in a self-directed environment designed to teach programming. We investigated three design alternatives: informed high-agency, informed low-agency, and less informed high-agency. To investigate the effect of these alternatives on learning, we conducted a study with 79 novice programmers. Our results indicated that increased agency and information may have translated to more motivation, but not improved learning. Qualitative results suggest this was due to the burden that agency and information placed on decision-making. We interpret our results in relation to informing the design of self-directed online tools for learner agency.","New York, NY, USA",,"Xie, Benjamin and Nelson, Greg L. and Akkaraju, Harshitha and Kwok, William and Ko, Amy J.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405928,9.78145E+12,"interaction design, agency, educational technology","Virtual Event, USA",13,77?€?89,Association for Computing Machinery,L@S '20,The Effect of Informing Agency in Self-Directed Online Learning Environments,https://doi.org/10.1145/3386527.3405928,2020
inproceedings,10.1145/3386527.3405926,"While the literature on learning at scale has largely focused on MOOCs, online degree programs, and AI techniques for supporting scalable learning experiences, informal learning communities have been relatively underrepresented. None-theless, these massive open online learning communities regularly draw far more engaged users than the typical MOOC. Their informal structure, however, makes them significantly more difficult to study. In this work, we take a first step toward attempting to understand these communi-ties specifically from the perspective of scale. Taking a sample of 62 such communities, we develop a tagging sys-tem for understanding the specific features and how they relate to scale. For example, just as a MOOC cannot man-ually grade every assignment, so also an informal learning community cannot approve every contribution; and just as MOOCs therefore employ autograding, informal learning communities employ crowd-sourced moderation or plat-form-driven enforcement. Using these tags, we then select several communities for deeper case studies. We also use these tags to make sense of learning-based subreddits from the popular community site Reddit, which offers an API for programmatic analysis. Based on these techniques, we offer findings about the performance of informal learning communities at scale and issue a call to include these envi-ronments more fully in future research on learning at scale.","New York, NY, USA",,"Hudgins, Will and Lynch, Michael and Schmal, Ash and Sikka, Harsh and Swenson, Michael and Joyner, David A.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405926,9.78145E+12,"reddit, informal learning communities, informal learning, case studies, online learning","Virtual Event, USA",11,91?€?101,Association for Computing Machinery,L@S '20,Informal Learning Communities: The Other Massive Open Online 'C',https://doi.org/10.1145/3386527.3405926,2020
inproceedings,10.1145/3386527.3405915,"Programming is fast becoming a required skill set for students in every country. We present CS Bridge, a model for cross-border co-teaching of CS1, along with a corresponding open-source course-in-a-box curriculum made for easy localization. In the CS Bridge model, instructors and student-teachers from different countries come together to teach a short, stand-alone CS1 course to hundreds of local high school students. The corresponding open-source curriculum has been specifically designed to be easily adapted to a wide variety of local teaching practices, languages, and cultures.Over the past six years, the curriculum has been used to teach CS1 material to over 1,000 high school students in Colombia, the Czech Republic, Turkey, and Guinea. A large majority of our students continue on to study CS or CS-related fields in university. More importantly, many of our undergraduate student-teachers stay involved with teaching beyond the program. Joint teaching creates a positive, high-quality learning experience for students around the world and a powerful, high-impact professional development experience for the teaching team---instructors and student-teachers alike.","New York, NY, USA",,"Piech, Chris and Yan, Lisa and Einstein, Lisa and Saavedra, Ana and Bozkurt, Baris and Sestakova, Eliska and Guth, Ondrej and McKeown, Nick",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405915,9.78145E+12,"international education, course-in-a-box, cs for all, co-teaching","Virtual Event, USA",11,103?€?113,Association for Computing Machinery,L@S '20,Co-Teaching Computer Science Across Borders: Human-Centric Learning at Scale,https://doi.org/10.1145/3386527.3405915,2020
inproceedings,10.1145/3386527.3405912,"It has been shown in multiple studies that expert-created on-demand assistance, such as hint messages, improves student learning in online learning environments. However, there are also evident that certain types of assistance may be detrimental to student learning. In addition, creating and maintaining on-demand assistance are hard and time-consuming. In 2017-2018 academic year, 132,738 distinct problems were assigned inside ASSISTments, but only 38,194 of those problems had on-demand assistance. In order to take on-demand assistance to scale, we needed a system that is able to gather new on-demand assistance and allows us to test and measure its effectiveness. Thus, we designed and deployed TeacherASSIST inside ASSISTments. TeacherASSIST allowed teachers to create on-demand assistance for any problems as they assigned those problems to their students. TeacherASSIST then redistributed on-demand assistance by one teacher to students outside of their classrooms. We found that teachers inside ASSISTments had created 40,292 new instances of assistance for 25,957 different problems in three years. There were 14 teachers who created more than 1,000 instances of on-demand assistance. We also conducted two large-scale randomized controlled experiments to investigate how on-demand assistance created by one teacher affected students outside of their classes. Students who received on-demand assistance for one problem resulted in significant statistical improvement on the next problem performance. The students' improvement in this experiment confirmed our hypothesis that crowd-sourced on-demand assistance was sufficient in quality to improve student learning, allowing us to take on-demand assistance to scale.","New York, NY, USA",,"Patikorn, Thanaporn and Heffernan, Neil T.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405912,9.78145E+12,"crowd-sourcing, tutored problem solving, learning management system, assistments","Virtual Event, USA",10,115?€?124,Association for Computing Machinery,L@S '20,Effectiveness of Crowd-Sourcing On-Demand Assistance from Teachers in Online Learning Platforms,https://doi.org/10.1145/3386527.3405912,2020
inproceedings,10.1145/3386527.3405914,"As enrollment numbers in online courses increase, students, instructors, and teaching assistants have difficulty finding needed information in online forums because of the number of posts, resulting in duplicate posts that exacerbate the problem. We introduce PARQR, a recommendation tool that suggests relevant contributions as participants compose their posts. We investigate the use of PARQR in five online degree-seeking courses. We survey 74 students and interview five teaching assistants to understand their experience with online forums and PARQR. We compare the differences between using and not using PARQR for an online course assignment. PARQR users found the tool to be useful for navigating online forums, and PARQR was effective in reducing the number of posts (0.291 vs. 0.506 posts per active student) and duplicate posts (17.8% vs. 25.6%) in an online course. These results suggest that PARQR makes on-line forums more efficient for users to find needed information.","New York, NY, USA",,"Irish, India and Finkelberg, Roy and Nkemelu, Daniel and Gujrania, Swar and Padiyath, Aadarsh and Raman, Sumedha and Tailor, Chirag and Arriaga, Rosa and Starner, Thad",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405914,9.78145E+12,"distance learning, online forums, online degrees, recommender systems, computer-assisted instruction","Virtual Event, USA",10,125?€?134,Association for Computing Machinery,L@S '20,PARQR: Automatic Post Suggestion in the Piazza Online Forum to Support Degree Seeking Online Masters Students,https://doi.org/10.1145/3386527.3405914,2020
inproceedings,10.1145/3386527.3405919,"A goal of learning analytics is to inform and improve learning design. Previous studies have attempted to interpret learners' clickstream data based on learning science theories. Many of these interpretations are made without reference to the specific learning designs of the courses being analyzed. Here, we report on a learning design informed analytics exploration of an introductory MOOC on Computer Science and Python programming. The learning resources (videos) and practice resources (short exercises and problem sets) are analyzed according to the knowledge types and cognitive process levels respectively, both based on a revised Bloom's Taxonomy. A heat map visualization of the access intensity on a learner resource access transition matrix and social network analysis are used to analyze learners' behavior with respect to the different resource categories. The results show distinctively different patterns of access between groups of students with different course performance and different academic backgrounds.","New York, NY, USA",,"Shen, Hao and Liang, Leming and Law, Nancy and Hemberg, Erik and O'Reilly, Una-May",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405919,9.78145E+12,"learning behavior, moocs, social network analysis, learning design informed learning analytics, learner resource access transition matrix, learning trajectory","Virtual Event, USA",11,135?€?145,Association for Computing Machinery,L@S '20,Understanding Learner Behavior Through Learning Design Informed Learning Analytics,https://doi.org/10.1145/3386527.3405919,2020
inproceedings,10.1145/3386527.3405918,"Massive Open Online Courses (MOOCs) provide the opportunity to offer free and open education at scale. Thousands of students with different social and cultural backgrounds from all over the world can enroll for a course. This diverse audience comes with varying motivations and intentions from their personal or professional life. However, course instructors cannot offer individual support and guidance at this scale and therefore usually provide a one-size-fits-all approach. Students have to follow weekly-structured courses and their success is measured with the achievement of a certificate at the end. To better address the varying learning needs, technical support for goal-oriented and self-regulated learning is desired but very limited to date. Both learning strategies are proven to be key factors for students' achievement in large-scale online learning environments. Therefore, this paper presents a continuative study of personalized learning objectives in MOOCs to encourage goal-oriented and self-regulated learning. Based on the previously well-perceived acceptance and usefulness of the concept of personalized learning objectives, this study examines which learners select an objective and how successful they complete objectives. Concerning the learners' socio-demographic and geographical background, we could not identify any practical significant difference between students with selected learning objectives and the total course population. However, we have identified promising objective achievement rates, and we have observed a practical significant improvement of the certification rates comparing the total course population and students who selected an objective that included a graded certificate. This has also demonstrated a method for calculating more reasonable completion rates in MOOCs.","New York, NY, USA",,"Rohloff, Tobias and Sauer, Dominic and Meinel, Christoph",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405918,9.78145E+12,"moocs, self-regulated learning, learning objectives","Virtual Event, USA",10,147?€?156,Association for Computing Machinery,L@S '20,Students' Achievement of Personalized Learning Objectives in MOOCs,https://doi.org/10.1145/3386527.3405918,2020
inproceedings,10.1145/3386527.3405921,"Mobile learning is expanding rapidly due to its accessibility and affordability, especially in resource-poor parts of the world. Yet how students engage and learn with mobile learning has not been systematically analyzed at scale. This study examines how 93,819 Kenyan students in grades 6, 9, and 12 use a text message-based mobile learning platform that has millions of users across Sub-Saharan Africa. We investigate longitudinal variation in engagement over a one-year period for students in different age groups and check for evidence of learning gains using learning curve analysis. Student engagement is highest during school holidays and leading up to standardized exams, but persistence over time is low: under 25% of students return to the platform after joining. Clustering students into three groups based on their level of activity, we examine variation in their learning behaviors and quiz performance over their first ten days. Highly active students exhibit promising trends in terms of quiz completion, reattempts, and accuracy, but we do not see evidence of learning gains in this study. The findings suggest that students in Kenya use mobile learning either as an ad-hoc resource or a low-cost tutor to complement formal schooling and bridge gaps in instruction.","New York, NY, USA",,"Kizilcec, Ren\'{e} F. and Chen, Maximillian",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405921,9.78145E+12,"clustering, mobile learning, kenya, student engagement, learning curves","Virtual Event, USA",10,157?€?166,Association for Computing Machinery,L@S '20,Student Engagement in Mobile Learning via Text Message,https://doi.org/10.1145/3386527.3405921,2020
inproceedings,10.1145/3386527.3405916,"Computer science education has promised open access around the world, but access is largely determined by what human language you speak. As younger students learn computer science it is less appropriate to assume that they should learn English beforehand. To that end, we present CodeInternational, the first tool to translate code between human languages. To develop a theory of non-English code, and inform our translation decisions, we conduct a study of public code repositories on GitHub. The study is to the best of our knowledge the first on human-language in code and covers 2.9 million Java repositories. To demonstrate CodeInternational's educational utility, we build an interactive version of the popular English-language Karel reader and translate it into 100 spoken languages. Our translations have already been used in classrooms around the world, and represent a first step in an important open CS-education problem.","New York, NY, USA",,"Piech, Chris and Abu-El-Haija, Sami",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405916,9.78145E+12,"translation, human-language, source-code, github","Virtual Event, USA",8,167?€?174,Association for Computing Machinery,L@S '20,Human Languages in Source Code: Auto-Translation for Localized Instruction,https://doi.org/10.1145/3386527.3405916,2020
inproceedings,10.1145/3386527.3405920,"Advances in education technology are enabling tremendous advances in learning at scale. However, they typically assume resources taken for granted in developed countries, including reliable electricity, high-bandwidth Internet access, fast WiFi, powerful computers, sophisticated sensors, and expert technical support to keep it all working. This paper examines these assumptions in the context of a massive test of learning at scale in a developing country. We examine each assumption, how it was broken, and some workarounds used in a 15-month-long independent controlled evaluation of pre- to posttest learning and social-emotional gains by over 2,000 children in 168 villages in Tanzania. We analyze those gains to characterize who gained how much, using test score data, social-emotional measures, and detailed logs from RoboTutor. We quantify the relative impact of pretest scores, literate aspirations, treatment, and usage on learning gains.","New York, NY, USA",,"McReynolds, Andrew A. and Naderzad, Sheba P. and Goswami, Mononito and Mostow, Jack",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405920,9.78145E+12,"tablet tutors, global learning xprize, numeracy, developing countries, unesco., literacy, social-emotional","Virtual Event, USA",9,175?€?183,Association for Computing Machinery,L@S '20,Toward Learning at Scale in Developing Countries: Lessons from the Global Learning XPRIZE Field Study,https://doi.org/10.1145/3386527.3405920,2020
inproceedings,10.1145/3386527.3405913,"The use of the Internet for learning provides a unique and growing opportunity to revisit the task of quantifying how much people have learned about a given subject in different regions around the world. Google alone receives over 5 billion searches a day and its publicly available data provides insight into learning process that is otherwise unobservable on a global scale. In this paper we, introduce the Computer Science Literacy-Proxy Index via Search (CSLI-s), a measure that utilizes online search data to make an educated guess around trends in computer science education. This measure uses a statistical signal processing technique to compose search volumes from a spectrum of topics into a coherent score. We intentionally explore and mitigate the biases of search data and, in the process, develop CSLI-s scores that correlate with traditional, more expensive metrics of learning. We then use search-trend data to measure patterns in subject literacy across countries and over time. To the best of our knowledge, this is the first measure of learning via Internet search-trends. The Internet is becoming a standard tool for learners and, as such, we anticipate search-trend data will have growing relevance to the learning science community.","New York, NY, USA",,"Arslan, Serhat and Tiwari, Mo and Piech, Chris",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405913,9.78145E+12,"curricula patterns, informaleducation, google search trends, measuring quality education","Virtual Event, USA",11,185?€?195,Association for Computing Machinery,L@S '20,Using Google Search Trends to Estimate Global Patterns in Learning,https://doi.org/10.1145/3386527.3405913,2020
inproceedings,10.1145/3386527.3405925,"Proctoring educational assessments (e.g., quizzes and exams) has a cost, be it in faculty (and/or course staff) time or in money to pay for proctoring services. Previous estimates of the utility of proctoring (generally by estimating the score advantage of taking an exam without proctoring) vary widely and have mostly been implemented using an across subjects experimental designs and sometimes with low statistical power.We investigated the score advantage of unproctored exams versus proctored exams using a within-subjects design for N = 510 students in an on-campus introductory programming course with 5 proctored exams and 4 unproctored exams. We found that students scored 3.32 percentage points higher on questions on unproctored exams than on proctored exams (p &lt; 0.001).More interestingly, however, we discovered that this score advantage on unproctored exams grew steadily as the semester progressed, from around 0 percentage points at the start of semester to around 7 percentage points by the end. As the most obvious explanation for this advantage is cheating, we refer to this behavior as the student population ""learning to cheat"". The data suggests that both more individuals are cheating and the average benefit of cheating is increasing over the course of the semester. Furthermore, we observed that studying for unproctored exams decreased over the course of the semester while studying for proctored exams stayed constant. Lastly, we estimated the score advantage by question type and found that our long-form programming questions had the highest score advantage on unproctored exams, but there are multiple possible explanations for this finding.","New York, NY, USA",,"Chen, Binglin and Azad, Sushmita and Fowler, Max and West, Matthew and Zilles, Craig",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405925,9.78145E+12,"stem, cheating, proctoring, exams, assessment, cs1","Virtual Event, USA",10,197?€?206,Association for Computing Machinery,L@S '20,Learning to Cheat: Quantifying Changes in Score Advantage of Unproctored Assessments Over Time,https://doi.org/10.1145/3386527.3405925,2020
inproceedings,10.1145/3386527.3405931,"This half-day workshop aims at collecting experiences of MOOC designers and MOOC educators to discuss what has been done to support SRL and what can be done to scaffold learners in MOOCs, particularly MOOCs for language learning purposes (LMOOCs). For this purpose, it is planned to come together with academicians and researchers working on related subjects within the scope of this workshop to develop a student support framework in large-scale learning environments.In this workshop, the participants should actively participate and take part in both the virtual session and the discussions that may emerge on social media (via Twitter). In line with this process, the main problems faced by individuals learning a foreign language with the help of LMOOCs will be examined following the experiences of the participants and the organizers.","New York, NY, USA",,"Conde Gafaro, Barbara and Yildiz, Hilal Seda",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405931,9.78145E+12,"massive open online course, self-regulated learning support, language moocs","Virtual Event, USA",3,207?€?209,Association for Computing Machinery,L@S '20,Supporting Learners' Self-Regulation in LMOOCs: What Have We Done and How Far We Can Go?,https://doi.org/10.1145/3386527.3405931,2020
inproceedings,10.1145/3386527.3405936,"The goal of this workshop is to bring together the existing community of researchers working on Infrastructure Design for Data-Intensive Research in Computer Science Education and a community of Learning at Scale researchers focused on Computer Science Education. While both communities share many similar goals and could greatly benefit from each other work, the interaction between the communities is small. We hope that the proposed workshop will be instrumental in bringing together like-minded researchers from different communities, establishing collaboration, and expanding the scope of infrastructure project to address critical scaling issues.","New York, NY, USA",,"Brusilovsky, Peter and Koedinger, Ken and Joyner, David A. and Price, Thomas W.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405936,9.78145E+12,"interoperability. infrastructure, computer science education, learning data, learning content","Virtual Event, USA",3,211?€?213,Association for Computing Machinery,L@S '20,Building an Infrastructure for Computer Science Education Research and Practice at Scale,https://doi.org/10.1145/3386527.3405936,2020
inproceedings,10.1145/3386527.3405937,"Video-based learning (VBL) is widespread; however, there are numerous challenges when teaching and learning with video. For instructors, creating effective instructional videos takes considerable time and effort. For students, watching videos can be a passive learning activity. Artificial intelligence (AI) has the potential to improve the VBL experience for students and teachers. This half-day workshop will bring together multi-disciplinary researchers and practitioners to collaboratively envision the future of VBL enhanced by AI. This workshop will be comprised of a group discussion followed by a presentation session. The goal of the workshop is to facilitate the cross-pollination of design ideas and critical assessments of AI approaches to VBL.","New York, NY, USA",,"Seo, Kyoungwon and Fels, Sidney and Yoon, Dongwook and Roll, Ido and Dodson, Samuel and Fong, Matthew",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405937,9.78145E+12,"natural language processing, video-based learning, artificial intelligence, machine learning, computer vision","Virtual Event, USA",3,215?€?217,Association for Computing Machinery,L@S '20,Artificial Intelligence for Video-Based Learning at Scale,https://doi.org/10.1145/3386527.3405937,2020
inproceedings,10.1145/3386527.3405933,,"New York, NY, USA",,"Ritter, Steven and Heffernan, Neil and Williams, Joseph Jay and Settles, Burr and Grimaldi, Phillip and Lomas, Derek",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405933,9.78145E+12,"a/b testing, educational software","Virtual Event, USA",2,219?€?220,Association for Computing Machinery,L@S '20,Workshop Proposal: Educational A/B Testing at Scale,https://doi.org/10.1145/3386527.3405933,2020
inproceedings,10.1145/3386527.3405934,"Scaled learning requires a novel set of practices on the part of professionals developing and delivering systems of scaled learning. IEEE's Industry Connections Industry Consortium for Learning Engineering (ICICLE) defines learning engineering as ""a process and practice that applies the learning sciences, using human-centered engineering design methodologies, and data-informed decision-making to support learners and their development."" This event will bring together learning engineering experts and other interested conference participants to further define the discipline and strategies to establish learning engineering at scale. It will also serve as a gathering place for attendees with shared interests in learning engineering to build community around the advancement of learning engineering as a professional practice and academic field of study.Interdisciplinary research in the learning, computer and data sciences fields continue to discover techniques for developing increasingly effective technology-mediated learning solutions. However, these applied sciences discoveries have been slow to translate into wide-scale practice. This workshop will bring together conference participants to give input into models for scaling the profession of learning engineering and wide-scale use of learning engineering process and practice models.","New York, NY, USA",,"Czerwinski, Erin and Goodell, Jim and Sottilare, Robert and Wagner, Ellen",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405934,9.78145E+12,"learning, learning sciences, engineering design, human-centered, learning engineering, data-informed, multidisciplinary teams","Virtual Event, USA",3,221?€?223,Association for Computing Machinery,L@S '20,Learning Engineering @ Scale,https://doi.org/10.1145/3386527.3405934,2020
inproceedings,10.1145/3386527.3405935,"Large-scale online learning environments present new opportunities to address the need for greater inclusivity in education. Unlike residential environments, which have physical and logistic constraints (e.g., classroom configurations, sizes, and scheduling) that impede our ability to enact more inclusive pedagogy, online learning environments can be personalized and adapted to individual learner needs. As these environments are completely technology mediated, they offer an almost infinite design space for innovation. Social-scientific research on inclusivity in residential settings provides insight into how we might design for online learning environments, however evidence of efficacious digital implementations of these insights is limited. This workshop aims to advance our understanding of the ways in which adaptivity can be leveraged to buttress inclusivity in STEM learning. Through brief paper presentations and collaborative activities we intend to outline design opportunities in the scaled learning space for creating more inclusive environments.","New York, NY, USA",,"Brooks, Christopher and Kizilcec, Ren\'{e} F. and Dowell, Nia",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405935,9.78145E+12,"design, online learning, inclusion, equity, education","Virtual Event, USA",4,225?€?228,Association for Computing Machinery,L@S '20,Designing Inclusive Learning Environments,https://doi.org/10.1145/3386527.3405935,2020
inproceedings,10.1145/3386527.3405956,"This workshop proposes specifically soliciting contributions and presentations from initiatives, programs, and platforms around the world. While many of these may already be presented at the full conference, we are also interested in more casual experience reports, case studies, and background presentations from individuals more closely acquainted with how learning at scale initiatives-including MOOCs, for-credit degree programs, informal learning environments, government initiatives, and so on-have unique needs and opportunities based on their local context. We refer to this as Global Learning @ Scale. For the purposes of this workshop, we take two views of Global Learning @ Scale.","New York, NY, USA",,"Joyner, David A. and Carlon, May and Cross, Jeffrey and Corpe\~{n}o, Eduardo and Hern\'{a}ndez Rizzardini, Rocael and Rodas, Oscar and Shah, Dhawal and Cortes-Mendez, Manoel and Staubitz, Thomas and Ruip\'{e}rez-Valiente, Jos\'{e} A.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405956,9.78145E+12,"online learning, distance learning","Virtual Event, USA",4,229?€?232,Association for Computing Machinery,L@S '20,Global Learning @ Scale,https://doi.org/10.1145/3386527.3405956,2020
inproceedings,10.1145/3386527.3405932,"Advancement in technology and innovation in teaching such as chatbot and extended reality can be daunting for teachers but as an educator, we need to leverage on these advancements to respond to the changes and challenges in the teaching and learning landscape. There are a number of tools available for teachers to use to overcome the challenges, and one of them is the application of artificial intelligence (AI) but creating a chatbot requires complex computer programming skills, and it is usually built from scratch to fit the intended educational purpose. This practice makes it difficult for teachers to adapt existing systems or to attempt in creating a similar version. In this workshop, we will be sharing our experiences gained from developing various chatbots for higher education using a commercial platform that can jumpstart your chatbot.","New York, NY, USA",,"Luo, Crystal Jing and Wong, Victor Yiu Lun and Gonda, Donn Emmanuel",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405932,9.78145E+12,"ai in education, chatbot, educational technologies","Virtual Event, USA",3,233?€?235,Association for Computing Machinery,L@S '20,Code Free Chatbot Development: An Easy Way to Jumpstart Your Chatbot!,https://doi.org/10.1145/3386527.3405932,2020
inproceedings,10.1145/3386527.3406720,"We demonstrate the feasibility of Finite State Machine (FSM) logic to design adaptively scaffolded activities, presenting early work integrating adaptive learning into a learning tool in widespread use globally. We describe how integrating FSM logic with existing assessment architecture enables us to extend from direct measurement to scaffolding and feedback interventions on a spectrum of timescales from 1-second to several hours. Four prototypes are shared, demonstrating how this FSM logic affords design across differing learning contexts. Implications for design of efficiency and empowerment at scale, potential for content co-creation, and transformation of learning are discussed.","New York, NY, USA",,"Waterman, Muffie Wiebe and Frezzo, Dennis C. and Wang, Michael X.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406720,9.78145E+12,"networking, student agency, finite state machine, educational games, adaptive learning, simulations, scaffolding","Virtual Event, USA",4,237?€?240,Association for Computing Machinery,L@S '20,Adaptive Learning Using Finite State Machine Logic,https://doi.org/10.1145/3386527.3406720,2020
inproceedings,10.1145/3386527.3405939,"Students often experience confusion while learning, and if promptly resolved, it can promote engagement and deeper understanding. However, detecting student confusion and intervening in a timely and scalable manner challenges even seasoned instructors. To understand when and where students are most likely to be confused, we study the systematic occurrence of confusion in college classes among 29,511 students in twelve universities. We use a novel method for affect detection that allows students to self-report confusion on individual presentation slides during their classes. Across 1,366 class presentations, we find that confusion arises at different times during class and depends on class duration, class size, type of institution, and academic discipline. Confusion is most prevalent during short presentations, in small classes, low-tier institutions, and scientific disciplines.","New York, NY, USA",,"Chen, Youjie and Kizilcec, Ren\'{e} F.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405939,9.78145E+12,"instructional design, powerpoint, affect detection, confusion, higher education","Virtual Event, USA",4,241?€?244,Association for Computing Machinery,L@S '20,Examining Sources of Variation in Student Confusion in College Classes,https://doi.org/10.1145/3386527.3405939,2020
inproceedings,10.1145/3386527.3405940,"Assigning a set of hypothesized knowledge components (KCs) to assessment items within an ed-tech system enables us to better estimate student learning. However, creating and assigning these KCs is a time-consuming process that often requires domain expertise. In this study, we present the results of crowdsourcing KCs for problems in the domain of mathematics and English writing, as a first step in leveraging the crowd to expedite this task. Crowdworkers were presented with a problem and asked to provide the underlying skills required to solve it. Additionally, we investigated the effect of priming crowdworkers with related content before having them generate these KCs. We then analyzed their contributions through qualitative coding and found that across both the math and writing domains roughly 33% of the crowdsourced KCs directly matched those generated by domain experts for the same problems.","New York, NY, USA",,"Moore, Steven and Nguyen, Huy A. and Stamper, John",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405940,9.78145E+12,"knowledge component modeling, courseware improvement, knowledge component, priming, expertise, crowdsourcing","Virtual Event, USA",4,245?€?248,Association for Computing Machinery,L@S '20,Towards Crowdsourcing the Identification of Knowledge Components,https://doi.org/10.1145/3386527.3405940,2020
inproceedings,10.1145/3386527.3405941,"Increasingly many teachers are turning to online social media to supplement educational resources and meet students' needs in the classrooms. The diffusion of information from online social media to the classroom is significantly faster than traditional curriculum-based approaches. However, this is contingent upon how well teachers across an online social media network are connected. To understand this, we perform a thorough and large-scale investigation of teacher connections in online social media, which is lacking in the literature. To make this feasible, we construct a large dataset of teachers on Pinterest, an image-based popular online social media. Our dataset includes 540 teachers across 5 states and 48 districts, thousands of connections they have established (either with their peers or some other Pinterest users), and all the resources they have shared in their accounts. Then, taking into account some crucial teacher-related attributes (e.g., their districts, grade levels, etc), we characterize direct and indirect teacher connections. Moreover, we compare the physical (face to face) and virtual (Pinterest) network of our surveyed teachers using several graph-related metrics. The finding in this study can serve as a basis to investigate teachers on social media in a deeper manner.","New York, NY, USA",,"Karimi, Hamid and Torphy, Kaitlin T. and Derr, Tyler and Frank, Kenneth A. and Tang, Jiliang",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405941,9.78145E+12,"teachers, social media, pinterest","Virtual Event, USA",4,249?€?252,Association for Computing Machinery,L@S '20,Characterizing Teacher Connections in Online Social Media: A Case Study on Pinterest,https://doi.org/10.1145/3386527.3405941,2020
inproceedings,10.1145/3386527.3406721,"International Large-Scale Assessments (ILSA) have a critical role in shaping education systems around the world. They impact local and national education policy and receive much attention in the media and the public discourse. However, the public has limited access to the results and cannot learn from them. Subsequently, the media might frame the results incorrectly. The transparency of ILSA is essential to the advancement of the public discourse. It requires easy access to data together with simple analysis tools. However, the complexity of ILSA makes it hard to understand and to analyze. Open PISA tries to deal with this challenge by developing a dashboard for the Program for International Student Assessment (PISA). It aims to guide users in the analysis of the dataset. This paper describes the dashboard design and insight based on collected users' responses. It hypothesizes that full transparency of the PISA dataset might be not achievable to the entire public. Further research is needed to evaluate how dataset analysis affects users' knowledge and opinions.","New York, NY, USA",,"Kantor, Avner and Rafaeli, Sheizaf",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406721,9.78145E+12,"pisa, dashboards, citizen science, statistical literacy, international large-scale assessments, visualizations","Virtual Event, USA",4,253?€?256,Association for Computing Machinery,L@S '20,Open PISA: Dashboard for Large Educational Dataset,https://doi.org/10.1145/3386527.3406721,2020
inproceedings,10.1145/3386527.3406722,"This paper reviews the current developments in the use of nQuire (www.nquire.org.uk), an Open University platform supporting engagement of members of the public in large-scale interactive surveys and science investigations. The platform is designed to continue a series of mass online science investigations from BBC Lab UK linked to broadcast TV and radio programmes, alongside the citizen-led inquiries. This paper reports on progress with the development of the platform and its use in a variety of contexts","New York, NY, USA",,"Scanlon, Eileen and Herodotou, Christothea and Sharples, Mike and McLeod, Kevin",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406722,9.78145E+12,"distance learning, citizen science, inquiry learning","Virtual Event, USA",4,257?€?260,Association for Computing Machinery,L@S '20,NQuire: Citizens Acting as Scientists in Massive Open Online Learning,https://doi.org/10.1145/3386527.3406722,2020
inproceedings,10.1145/3386527.3406723,"Examinator compares pairs of take-home exams to select which should be manually checked for plagiarism. Examinator also generates a report with evidence for these cases using its metrics and those generated as a by-product of the commercial grading tool Gradescope. Examinator supports degree-seeking graduate programs (both online and on-campus) at a top computer science graduate institute in the United States. Since Spring 2019, Examinator has compared over 2 million pairs of exams from a popular Artificial Intelligence course, resulting in 56 cases being referred for discipline. Iterative development has improved the percentage of referrals of suggested cases from 15% to 25%.","New York, NY, USA",,"Apoorv, Raghav and Dahiya, Akshay and Sreeram, Uma and Patil, Bharat Rahuldhev and Irish, India and Graziano, Rocko and Starner, Thad",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406723,9.78145E+12,"online learning, take-home exams, academic integrity, plagiarism detection","Virtual Event, USA",4,261?€?264,Association for Computing Machinery,L@S '20,Examinator: A Plagiarism Detection Tool for Take-Home Exams,https://doi.org/10.1145/3386527.3406723,2020
inproceedings,10.1145/3386527.3406724,"As universities increasingly teach at scale, new challenges are introduced and compounded where students are offered greater choice. A key challenge is to maintain an understanding of the student experience within the huge increase in variations in student study path. This understanding is necessary to provide feedback to both faculty and students, and institutionally for the enhancement of quality. This is the first description of one fresh approach to this challenge. Whilst based on the experience within a large distance learning university, the findings are relevant to all institutions working at scale. Moving from a traditional relational structure to a multi-model database makes it possible to quickly design study path queries to explore the richness of available data. We provide an overview of this approach that could be applied by other universities and higher education institutions where data is not being fully utilised.","New York, NY, USA",,"Edwards, Chris and Gaved, Mark",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406724,9.78145E+12,"student experience, course sequences, quality enhancement, graph visualization, higher education, multi-model database, academic pathways","Virtual Event, USA",4,265?€?268,Association for Computing Machinery,L@S '20,Understanding Student Experience: A Pathways Model,https://doi.org/10.1145/3386527.3406724,2020
inproceedings,10.1145/3386527.3406725,"This paper explores the use of data analytics for identifying creativity in visual programming. Visual programming environments are increasingly included in the schools curriculum. Their potential for promoting creative thinking in students is an important factor in their adoption. However, there does not exist a standard approach for detecting creativity in students' programming behavior, and analyzing programs manually requires human expertise and is time consuming. This work provides a computational tool for measuring creativity in visual programming that combines theory from the literature with data mining approaches. It adapts classical dimensions of creative processes to our setting, and considers new aspects such as visual elements of the visual programming projects. We apply our approach to the Scratch programming environment, measuring the creativity score of hundreds of projects. We show a preliminary comparison between our metrics and teacher ratings.","New York, NY, USA",,"Kovalkov, Anastasia and Segal, Avi and Gal, Kobi",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406725,9.78145E+12,"creativity, visual programming environments, creativity tests","Virtual Event, USA",4,269?€?272,Association for Computing Machinery,L@S '20,Inferring Creativity in Visual Programming Environments,https://doi.org/10.1145/3386527.3406725,2020
inproceedings,10.1145/3386527.3406726,"In online programming classes, it is tricky to uphold academic honesty in the assessment process. A common approach, plagiarism detection, is not accurate for novice programmers and ineffective for detecting contract cheaters. We present a new approach, cheating detection with keystroke dynamics in programming classes, and evaluated the approach.","New York, NY, USA",,"Byun, Jeongmin and Park, Jungkook and Oh, Alice",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406726,9.78145E+12,"online education, contract cheating, keystroke dynamics, academic honesty","Virtual Event, USA",4,273?€?276,Association for Computing Machinery,L@S '20,Detecting Contract Cheaters in Online Programming Classes with Keystroke Dynamics,https://doi.org/10.1145/3386527.3406726,2020
inproceedings,10.1145/3386527.3406727,"As online educational programs scale, monitoring peer collaboration in platforms like BlueJeans for plagiarism becomes difficult. Recent studies indicate that students are less likely to cheat if presented with direct warning messages prior to engaging in online activities. In this work, we present Bluejeans codE Leak deTection (BELT), a system that monitors online BlueJeans meetings for shared code and sends timely warning messages to meeting participants. To test BELT's robustness as an online proctor, we evaluate its code-text disambiguation, code detection from images of varying quality, and code detection from videos of varying resolution. We conclude this work by pinpointing areas of improvement and briefly discuss possible extensions for future work.","New York, NY, USA",,"Khazane, Anish and Mao, Jia and Irish, India and Graziano, Rocko and Starner, Thad",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406727,9.78145E+12,"online learning, programming language detection, plagiarism, moocs, online meeting","Virtual Event, USA",4,277?€?280,Association for Computing Machinery,L@S '20,BELT: Bluejeans CodE Leak DeTection,https://doi.org/10.1145/3386527.3406727,2020
inproceedings,10.1145/3386527.3406728,"Massive Open Online Courses (MOOCs) are accessible to anyone with a device that can connect to the internet. MOOCs aim to increase the accessibility of higher-level knowledge and skills, such as programming. To understand how students are performing and struggling in the course, we investigate a popular MITx MOOC that teaches introductory programming. We look at problem set questions and examine students with different levels of pre-existing knowledge. Specifically, we study the number of attempts of each group per question and the mean final accuracy of each group per question. We find that for nearly all questions, students with no programming experience struggle more than students with prior programming experience. Moreover, we observe a potential turning point in the course where students of all experience levels begin to struggle. Our findings both show that two groups of MOOC students perform differently and inform question design in MOOCs by demonstrating which question types are particularly arduous.","New York, NY, USA",,"Burd, Hannah and Bell, Ana and Hemberg, Erik and O'Reilly, Una-May",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406728,9.78145E+12,"moocs, problem sets, edx, student background, learning analytics, question design","Virtual Event, USA",4,281?€?284,Association for Computing Machinery,L@S '20,Analyzing Pre-Existing Knowledge and Performance in a Programming MOOC,https://doi.org/10.1145/3386527.3406728,2020
inproceedings,10.1145/3386527.3406729,"Empirical results have shown that deep neural networks achieve superior performance in the application of Knowledge Tracing. However, the design of recurrent cells like long short term memory (LSTM) cells or gated recurrent units (GRU) is influenced largely by applications in natural language processing. They were proposed and evaluated in the context of sequence to sequence modeling, like machine translation. Even though the LSTM cell works well for knowledge tracing, it is unknown if its architecture is ideally suited for knowledge tracing. Despite the fact that there are several recurrent neural network based architectures proposed for knowledge tracing, the methodologies rely on empirical observations and trial and error, which may not be efficient or scalable. In this study, we investigate using reinforcement learning for the automatic design of recurrent neural network cells for knowledge tracing, showing improved performance compared to the LSTM cell. We also discuss a potential method for model regularization using neural architecture search.","New York, NY, USA",,"Ding, Xinyi and Larson, Eric C.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406729,9.78145E+12,"knowledge tracing, reinforcement learning, regularization, recurrent neural network, neural architecture search","Virtual Event, USA",4,285?€?288,Association for Computing Machinery,L@S '20,Automatic RNN Cell Design for Knowledge Tracing Using Reinforcement Learning,https://doi.org/10.1145/3386527.3406729,2020
inproceedings,10.1145/3386527.3406730,"While learning at scale has the potential to widen access to education, the accessibility of courses offered on Massive Open Online Course (MOOC) platforms has not been researched in depth. This paper begins to fill that gap. Data was gathered using the participatory 'Evidence Caf\'{e}' method. Thematic analysis identified characteristics of accessible courses on these platforms. These characteristics include elements of both technology and pedagogy. Capturing and analysing expert insights enables this paper to provide guidance on how online courses can be made more accessible. The findings suggest that course production teams need to work collaboratively with providers to address issues of accessibility and involve learners in design, testing and evaluation. Well-designed tutor-supported activities that follow web accessibility and usability guidelines are needed, as well as educator training on accessibility.","New York, NY, USA",,"Papathoma, Tina and Ferguson, Rebecca and Iniesto, Francisco and Rets, Irina and Vogiatzis, Dimitrios and Murphy, Victoria",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406730,9.78145E+12,"disability, MOOCs, evidence, accessibility, cafe","Virtual Event, USA",4,289?€?292,Association for Computing Machinery,L@S '20,Guidance on How Learning at Scale Can Be Made More Accessible,https://doi.org/10.1145/3386527.3406730,2020
inproceedings,10.1145/3386527.3406731,"Using five million responses to thousands of practice examination questions on an optional study service known as Problem Roulette, we explore subject-specific differences in assessment style, grade benefit from usage of the service, and differential features in study behavior and grade outcome by birth sex. Our study includes more than 20,000 students enrolled in eight terms of introductory courses in general chemistry, physics and statistics. Student responses in the space of accuracy and response time reveal domain differences; by these measures, physics problems are typically both more difficult and more complex. Grouping students by term-length practice volume, we find significant positive grade benefits to higher volumes of study in chemistry and statistics. Across all subjects, we find that females gain more grade benefit from high study volume than males. Female students also outwork males during prime study hours yet, on average, earn 0.13 ?? 0.03 lower grade points in chemistry than males with the same response accuracy in practice, with null results in statistics and physics.","New York, NY, USA",,"Weaverdyck, Noah and Anbajagane, Dhayaa and Evrard, August E.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406731,9.78145E+12,"educational equity and fairness, instructional technologies, computer applications: physical sciences and engineering","Virtual Event, USA",4,293?€?296,Association for Computing Machinery,L@S '20,"Differential Assessment, Differential Benefit: Four-Year Problem Roulette Analysis of STEM Practice Study",https://doi.org/10.1145/3386527.3406731,2020
inproceedings,10.1145/3386527.3406732,"Learning technologies are generating a vast quantity of data every day. This data is often presented to students through learning analytics dashboards (LADs) with a goal of improving learners' self-regulated learning. However, are students actually using these dashboards, and do they perceive that using dashboards lead to any changes in their behavior? In this paper we report on the development and implementation of several dashboard views, which we call My Learning Analytics (MyLA). This study found that students thought using the dashboard would have more of an effect on the way they planned their course activity at pre-use (after a demo) than post use. Low self-regulated learners believed so significantly less post-use and used the grade distribution view the least. Students made several suggestions for ways to improve the grade distribution view and rated MyLA's usability more positively at pre- than post-use. Given the low use and low perceived impact of the current dashboard, we suggest that researchers use participatory design to illicit students' needs and better incorporate student suggestions.","New York, NY, USA",,"Haynes, Carl C.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406732,9.78145E+12,"learning analytics, self-regulated learning, dashboards","Virtual Event, USA",4,297?€?300,Association for Computing Machinery,L@S '20,"The Role of Self-Regulated Learning in the Design, Implementation, and Evaluation of Learning Analytics Dashboards",https://doi.org/10.1145/3386527.3406732,2020
inproceedings,10.1145/3386527.3406733,"It is hard for experts to create good instructional resources due to a phenomenon known as the expert blind spot: They forget what it was like to be a novice, so they cannot pinpoint exactly where novices commonly struggle and how to best phrase their explanations. To help overcome these expert blind spots for computer programming topics, we created a learnersourcing system that elicits explanations of misconceptions directly from learners while they are coding. We have deployed this system for the past three years to the widely-used Python Tutor coding website (pythontutor.com) and collected 16,791 learner-written explanations. To our knowledge, this is the largest dataset of explanations for programming misconceptions. By inspecting this dataset, we found surprising insights that we did not originally think of due to our own expert blind spots as programming instructors. We are now using these insights to improve compiler and run-time error messages to explain common novice misconceptions.","New York, NY, USA",,"Guo, Philip J. and Markel, Julia M. and Zhang, Xiong",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406733,9.78145E+12,"programming, syntax errors, python tutor, learnersourcing","Virtual Event, USA",4,301?€?304,Association for Computing Machinery,L@S '20,Learnersourcing at Scale to Overcome Expert Blind Spots for Introductory Programming: A Three-Year Deployment Study on the Python Tutor Website,https://doi.org/10.1145/3386527.3406733,2020
inproceedings,10.1145/3386527.3406734,"Crowdsourcing has shown promise in education domains. For example, researchers have leveraged the wisdom of the crowd to process grading in MOOCs and develop learning resources. An untapped domain is harnessing the crowd to systematically process educational data in classrooms -- data that provide key instructional insights but take time to process, such as paper-based assessments. In this paper, we describe an experiment of a crowdsourcing task to effectively process classroom-based data and explore the potential of crowdsourcing as a learning opportunity for the crowdworkers. We discuss implications for designing crowdsourced assessment tasks to yield both high quality output and enriching learning experiences for those involved in the crowdsourcing task.","New York, NY, USA",,"Nguyen, Ha and Ahn, June and Young, William and Campos, Fabio",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406734,9.78145E+12,"k-12 education, data processing, crowdsourcing","Virtual Event, USA",4,305?€?308,Association for Computing Machinery,L@S '20,Where's the Learning in Education Crowdsourcing?,https://doi.org/10.1145/3386527.3406734,2020
inproceedings,10.1145/3386527.3406735,"This work reports on progress made towards building an equitable model to predict the success of an applicant to Georgia Tech's Online Master's in Analytics program. As a first step, we have collected and processed data on 9,044 applications and have trained a predictive model with a ROC-AUC score of 0.81, which predicts whether an applicant would be admitted to the program. Our next steps will include using applicant data to model the successful completion of the Analytics program's three core courses, graduation, and finally job placement. In addition, we plan to expand our feature processing and incorporate techniques to ensure that our models do not discriminate based on demographic factors. In the long run, we hope that the results of this study can be used to improve the course contents, selection of offered courses, and prerequisite training, and even give guidance toward the selection of the applicants.","New York, NY, USA",,"Staudaher, Shawn and Lee, Jeonghyun and Soleimani, Farahnaz",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406735,9.78145E+12,"applicant success, machine learning, predictive analytics","Virtual Event, USA",4,309?€?312,Association for Computing Machinery,L@S '20,Predicting Applicant Admission Status for Georgia Tech's Online Master's in Analytics Program,https://doi.org/10.1145/3386527.3406735,2020
inproceedings,10.1145/3386527.3406736,"Existing attempts to foster a greater sense of community in online education have largely focused on direct interactions among students in peer review, forums, and other mechanisms. In this paper, we pose a new design challenge for learning at scale: peripheral community. Peripheral community is the sense of community derived from peripheral interactions in which a student has visibility into others' behaviors without a direct, intentional interaction occurring between the students. We argue for the value of peripheral community by examining opportunities for such visibility in residential learning environments. We then explore possible ways to supply peripheral community, both in the form of new initiatives and in reinterpretations of existing interventions as fostering peripheral community.","New York, NY, USA",,"Joyner, David A.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406736,9.78145E+12,"online education, peripheral community, moocs","Virtual Event, USA",4,313?€?316,Association for Computing Machinery,L@S '20,Peripheral and Semi-Peripheral Community: A New Design Challenge for Learning at Scale,https://doi.org/10.1145/3386527.3406736,2020
inproceedings,10.1145/3386527.3406737,This paper presents two approaches using Simulated Annealing and a genetic algorithm to create optimal curricula. The method generates a customized course selection and schedule for individual students enrolled in a large online graduate program in computer science offered by a major public research institution in the United States.,"New York, NY, USA",,"Lefranc, Anneli and Joyner, David A.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406737,9.78145E+12,"curriculum, simulated annealing, genetic algorithm","Virtual Event, USA",4,317?€?320,Association for Computing Machinery,L@S '20,SAGA: Curricula Optimization,https://doi.org/10.1145/3386527.3406737,2020
inproceedings,10.1145/3386527.3406738,"Explanations are used to provide an understanding of a concept, procedure, or reasoning to others. Although explanations are present online ubiquitously within textbooks, discussion forums, and many more, there is no way to mine them automatically to assist learners in seeking an explanation. To address this problem, we propose the task of Explanation Mining. To mine explanations of educational concepts, we propose a baseline approach based on the Language Modeling approach of information retrieval. Preliminary results suggest that incorporating knowledge from a model trained on the ELI5 (Explain Like I'm Five) dataset in the form of a document prior helps increase the performance of a standard retrieval model. This is encouraging because our method requires minimal in-domain supervision, as a result, it can be deployed for multiple online courses. We also suggest some interesting future work in the computational analysis of explanations.","New York, NY, USA",,"Bhavya and Zhai, ChengXiang",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406738,9.78145E+12,"prior probability, explanations, language modeling for information retrieval","Virtual Event, USA",4,321?€?324,Association for Computing Machinery,L@S '20,Explanation Mining,https://doi.org/10.1145/3386527.3406738,2020
inproceedings,10.1145/3386527.3406739,"Online learning systems that provide actionable and personalized guidance can help learners make better decisions during learning. Bayesian Knowledge Tracing (BKT) extensions and deep learning based approaches have demonstrated improved mastery prediction accuracy compared to the basic BKT model; however, neither set of models provides actionable guidance on learning activities beyond mastery prediction. We propose a novel framework for personalized knowledge tracing with attention mechanism. Our proposed framework incorporates auxiliary learner attributes into knowledge tracing and interprets mastery prediction with the learning attributes. The proposed approach can also provide personalized next best learning activity recommendations. We demonstrate that the accuracy of the proposed approach in mastery prediction is slightly higher compared to deep learning based approaches and that the proposed approach can provide personalized next best learning activity recommendation.","New York, NY, USA",,"Zhao, Jinjin and Bhatt, Shreyansh and Thille, Candace and Zimmaro, Dawn and Gattani, Neelesh",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406739,9.78145E+12,"attention mechanism, knowledge tracing, personalized knowledge tracing, recommendation","Virtual Event, USA",4,325?€?328,Association for Computing Machinery,L@S '20,Interpretable Personalized Knowledge Tracing and Next Learning Activity Recommendation,https://doi.org/10.1145/3386527.3406739,2020
inproceedings,10.1145/3386527.3406740,"In this paper, we study a computerized exam system that allows students to attempt the same question multiple times. This system permits students either to receive feedback on their submitted answer immediately or to defer the feedback and grade questions in bulk. An analysis of student behavior in three courses across two semesters found similar student behaviors across courses and student groups. We found that only a small minority of students used the deferred feedback option. A clustering analysis that considered both when students chose to receive feedback and either to immediately retry incorrect problems or to attempt other unfinished problems identified four main student strategies. These strategies were correlated to statistically significant differences in exam scores, but it was not clear if some strategies improved outcomes or if stronger students tended to prefer certain strategies.","New York, NY, USA",,"Verma, Ashank and Bretl, Timothy and West, Matthew and Zilles, Craig",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406740,9.78145E+12,"assessment, agency, multiple attempts, computerized exams, computer-based testing","Virtual Event, USA",4,329?€?332,Association for Computing Machinery,L@S '20,A Quantitative Analysis of When Students Choose to Grade Questions on Computerized Exams with Multiple Attempts,https://doi.org/10.1145/3386527.3406740,2020
inproceedings,10.1145/3386527.3406741,"Deep learning based knowledge tracing approaches achieve high accuracy in mastery prediction with pattern extraction on a large learning behavior data set. However, when there is little training data available, these approaches either fail to extract the key patterns or result in over fitting. Ideally, we aim to provide a similar learning experience to both the first group of learners, who interact with a new course or a new activity with little learning behavior data to provide personalized guidance, and the learners who interact with the course later. We propose a novel architecture, Attentive Neural Turing Machine (ANTM), to solve the cold start knowledge tracing problem. The proposed ANTM comprises an attentive controller module and differential reading and writing processes with extra memory bank. Accuracy (ACC) and Area Under Curve (AUC) measures are used for model performance comparison. Results show the proposed approach can learn fast and generalize well to unseen data. It achieves around 95% ACC trained with only 3 learners, while conventional deep learning based approaches achieve only 65% ACC with over prediction issues.","New York, NY, USA",,"Zhao, Jinjin and Bhatt, Shreyansh and Thille, Candace and Gattani, Neelesh and Zimmaro, Dawn",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406741,9.78145E+12,"neural turing machine, attention mechanism, knowledge tracing","Virtual Event, USA",4,333?€?336,Association for Computing Machinery,L@S '20,Cold Start Knowledge Tracing with Attentive Neural Turing Machine,https://doi.org/10.1145/3386527.3406741,2020
inproceedings,10.1145/3386527.3406742,"College courses are often organized into hierarchical sequences, with foundational courses recommended or required as prerequisites for other offerings. While the wisdom of particular sequences is usually ascertained on the basis of faculty experience or student peer networks, machine learning techniques and ubiquitous transcript data make it possible to systematically identify the courses that best predict subsequent high achievement across entire curricula and student populations. We demonstrate the utility of this approach by analyzing five years of course sequences and earned grades for 13,218 undergraduates enrolled in courses with substantial quantitative content at a private research university. Findings indicate that prior completion of specific courses is positively associated with success in subsequent target courses, and suggest that academic planning could be enhanced through scaled observation of the revealed benefits of course sequences.","New York, NY, USA",,"Davis, Glenn M. and AbuHashem, Abdallah A. and Lang, David and Stevens, Mitchell L.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406742,9.78145E+12,"postsecondary education, predictive models, curriculum studies, academic course sequencing","Virtual Event, USA",4,337?€?340,Association for Computing Machinery,L@S '20,Identifying Preparatory Courses That Predict Student Success in Quantitative Subjects,https://doi.org/10.1145/3386527.3406742,2020
inproceedings,10.1145/3386527.3405945,"In this paper, we propose a novel Transformer-based model for knowledge tracing, SAINT: Separated Self-AttentIve Neural Knowledge Tracing. SAINT has an encoder-decoder structure where the exercise and response embedding sequences separately enter, respectively, the encoder and the decoder. The encoder applies self-attention layers to the sequence of exercise embeddings, and the decoder alternately applies self-attention layers and encoder-decoder attention layers to the sequence of response embeddings. This separation of input allows us to stack attention layers multiple times, resulting in an improvement in area under receiver operating characteristic curve (AUC). To the best of our knowledge, this is the first work to suggest an encoder-decoder model for knowledge tracing that applies deep self-attentive layers to exercises and responses separately. We empirically evaluate SAINT on a large-scale knowledge tracing dataset, EdNet, collected by an active mobile education application, Santa, which has 627,347 users, 72,907,005 response data points as well as a set of 16,175 exercises gathered since 2016. The results show that SAINT achieves state-of-the-art performance in knowledge tracing with an improvement of 1.8% in AUC compared to the current state-of-the-art model.","New York, NY, USA",,"Choi, Youngduck and Lee, Youngnam and Cho, Junghyun and Baek, Jineon and Kim, Byungsoo and Cha, Yeongmin and Shin, Dongmin and Bae, Chan and Heo, Jaewe",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405945,9.78145E+12,"knowledge tracing, education, deep learning, transformer, personalized learning","Virtual Event, USA",4,341?€?344,Association for Computing Machinery,L@S '20,"Towards an Appropriate Query, Key, and Value Computation for Knowledge Tracing",https://doi.org/10.1145/3386527.3405945,2020
inproceedings,10.1145/3386527.3406743,"We investigate student learning behaviors in a Massive Open Online Course with in-person components. Our goal is to improve the design of the course through learning analytics. The programming language taught, App Inventor, is a drag-and-drop language to create Android applications. We visualize and quantify student behaviors such as automatic and manual saving of code, video sections viewed, and the various forms of knowledge required to understand the course material. It appears students are less likely to go from course material that teaches procedures to other material that teaches procedures than we would expect, and rarely review previous topics covered in the course. We also find students tend to save marginally less at the beginning and end of sessions. However, since the data set is small, our conclusions are limited.","New York, NY, USA",,"Gold, Robert and Hemberg, Erik and O'Reilly, Una-May",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406743,9.78145E+12,"learning analytics, app inventor, learning design, knowledge type, resource usage, blended moocs","Virtual Event, USA",4,345?€?348,Association for Computing Machinery,L@S '20,Analyzing K-12 Blended MOOC Learning Behaviors,https://doi.org/10.1145/3386527.3406743,2020
inproceedings,10.1145/3386527.3406744,"Teamwork and graded team assignments in MOOCs are still largely under-researched. Nevertheless, the topic is enormously important as the ability to work and solve problems in teams is becoming increasingly common in modern work environments. The paper at hand discusses the reliability of a system to detect free-riders in peer assessed team tasks.","New York, NY, USA",,"Staubitz, Thomas and Traifeh, Hanadi and Chujfi, Salim and Meinel, Christoph",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406744,9.78145E+12,"mooc, collaborative learning, teamwork, peer assessment","Virtual Event, USA",4,349?€?352,Association for Computing Machinery,L@S '20,Have Your Tickets Ready! Impede Free Riding in Large Scale Team Assignments,https://doi.org/10.1145/3386527.3406744,2020
inproceedings,10.1145/3386527.3406745,"Online learning systems with open navigation allow learners to select the next learning activity in order to achieve desired mastery. To help learners make an informed choice regarding the next learning activity, we propose to represent and communicate the learner's knowledge state as the average success rate in the course for each skill, rather than as the probability of correctly answering the next question. We first show that we can accurately estimate the proposed knowledge state. We then show that the proposed attention-based model to estimate the knowledge state requires fewer parameters, provides actionable information to the learners, and achieves equivalent or better accuracy compared to RNN (Recurrent Neural Network) based models.","New York, NY, USA",,"Bhatt, Shreyansh and Zhao, Jinjin and Thille, Candace and Zimmaro, Dawn and Gattani, Neelesh",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406745,9.78145E+12,"knowledge tracing, attention based knowledge tracing., knowledge state","Virtual Event, USA",4,353?€?356,Association for Computing Machinery,L@S '20,A Novel Approach for Knowledge State Representation and Prediction,https://doi.org/10.1145/3386527.3406745,2020
inproceedings,10.1145/3386527.3406746,"Open navigation online learning systems allow learners to choose the next learning activity. These systems can be instrumented to provide learners with feedback to help them choose the next learning activity. One type of feedback is providing an estimate of the learner's current skill proficiency. A learner can then choose to skip the remaining learning activities for that skill after achieving proficiency in that skill. In this paper, we investigate whether predicting proficiency and communicating it to learners can save time for learners within a course. We evaluate the accuracy of the BKT based proficiency pre- diction framework for learner's proficiency prediction which considers one attempt per question. We extend the proficiency prediction framework to include multiple attempts at individual questions and show that it is more accurate in proficiency prediction than BKT based proficiency prediction framework. We discuss the potential implications of attempt enhanced framework on the learners' behavior for open navigation on- line learning systems.","New York, NY, USA",,"Bhatt, Shreyansh and Zhao, Jinjin and Thille, Candace and Zimmaro, Dawn and Gattani, Neelesh",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406746,9.78145E+12,"knowledge tracing, baysian knowledge tracing, mastery prediction, learner behavior analysis","Virtual Event, USA",4,357?€?360,Association for Computing Machinery,L@S '20,Evaluating Bayesian Knowledge Tracing for Estimating Learner Proficiency and Guiding Learner Behavior,https://doi.org/10.1145/3386527.3406746,2020
inproceedings,10.1145/3386527.3406747,"This paper describes an educational tool developed to teach coding and computational thinking to children. We designed and implemented an adaptive, interactive learning game application (mobile and web) called ""Pixasso"". In this application, children will write a simple program to color the 'pixels' of an image. Through the game application, they will learn programming commands, sequencing and debugging. This educational application was built using prevailing research on child centered design knowledge regarding child user interface and experience and aims to help scale initiatives dedicated towards introducing children to computer science at an early age.","New York, NY, USA",,"Nandan, Vrinda and Spittlemeister, Andrew and Brubacher, Federico",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406747,9.78145E+12,"computational thinking, coding, educational technology, child centered design","Virtual Event, USA",4,361?€?364,Association for Computing Machinery,L@S '20,Pixasso: A Development Stage-Based Learning Application for Children,https://doi.org/10.1145/3386527.3406747,2020
inproceedings,10.1145/3386527.3406748,"We present an analysis of factors correlated to grading speed in short answer questions from college level STEM courses using a novel dataset collected by an online education company. By analyzing timestamp data, we were able to estimate how long instructors grade individual student responses, which we typically found to be less than 10 seconds. This dataset provides us with a unique opportunity to determine which steps in the grading workflow could benefit from intervention. We found that sorting responses by rubric similarity has the potential to drastically reduce grading time by up to 50% per response. We plan to follow this work by implementing an intelligent agent to present responses in a sorted order to minimize grading time.","New York, NY, USA",,"Yen, Michael and Karayev, Sergey and Wang, Eric",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406748,9.78145E+12,"learning at scale, grading speed, short answer questions, examinations, grading time","Virtual Event, USA",4,365?€?368,Association for Computing Machinery,L@S '20,Analysis of Grading Times of Short Answer Questions,https://doi.org/10.1145/3386527.3406748,2020
inproceedings,10.1145/3386527.3405946,"Collaborative problem solving (CPS) is an important competency for life and career success. Promoting the development of CPS skills requires robust CPS assessment. This paper describes a gamified stealth CPS assessment used within a collaborative inquiry science curriculum. A pilot deployment included 196 middle school students from multiple schools in the United States. Results showed the sample was balanced in terms of measured skill performance and completion time. Future directions include the extension to teacher authoring and the deployment of this gamified assessment approach to additional contexts, such as workforce training and credentialing in large-scale online courses.","New York, NY, USA",,"Rosen, Yigal and Stoeffler, Kristin and Yudelson, Michael and Simmering, Vanessa",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405946,9.78145E+12,"formative assessment, collaborative problem solving, stealth assessment, gamified assessment, science learning, chatbot, human-agent collaboration","Virtual Event, USA",4,369?€?372,Association for Computing Machinery,L@S '20,Towards Scalable Gamified Assessment in Support of Collaborative Problem-Solving Competency Development in Online and Blended Learning,https://doi.org/10.1145/3386527.3405946,2020
inproceedings,10.1145/3386527.3405947,"Digital clinical simulations (DCSs) are a promising tool for professional learning on diversity, equity, and inclusion (DEI) issues across a variety of fields. Although digital clinical simulations can be integrated into large-scale learning environments, less is known about how to design these types of simulations so they can scale effectively. We describe the results of two studies of a digital clinical simulation tool called Jeremy's Journal. In Study 1, we implemented this simulation in an in-person workshop with a human facilitator. We found that participants described their learning experiences positively and reported changes in attitudes. In Study 2, we used the simulation within an online course but replaced the human facilitator with an asynchronous, text-based adaptation of the facilitation script. Although learners in Study 2 described the experience in the simulation positively, we did not observe changes in attitudes. We discuss the implications of these findings for the design of DCSs at scale","New York, NY, USA",,"Borneman, Elizabeth and Littenberg-Tobias, Joshua and Reich, Justin",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405947,9.78145E+12,"teaching, inclusion, equity, simulations, online learning","Virtual Event, USA",4,373?€?376,Association for Computing Machinery,L@S '20,"Developing Digital Clinical Simulations for Large-Scale Settings on Diversity, Equity, and Inclusion: Design Considerations for Effective Implementation at Scale",https://doi.org/10.1145/3386527.3405947,2020
inproceedings,10.1145/3386527.3406762,"Mixed reality creates exciting new opportunities for computer-aided language learning. By combining markerless tracking technology with a user's geolocation, software systems can dynamically locate and generate personalized interactive language practice exercises. The Locabulary mobile app uses a combination of markerless tracking and metadata from the user's location information to construct that utilize the learner's physical surroundings to provide unique and relevant content. Additionally, Locabulary employs context-aware spaced repetition to help language learners develop mastery over the material in the exercises it creates.","New York, NY, USA",,"Phillips-Gary, Zachary",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406762,9.78145E+12,"computer vision, language learning, mixed reality, situated learning, augmented reality","Virtual Event, USA",3,377?€?379,Association for Computing Machinery,L@S '20,Locabulary: A Context Sensitive Mixed Reality Flashcard Alternative for Second Language Learning,https://doi.org/10.1145/3386527.3406762,2020
inproceedings,10.1145/3386527.3406749,"Concepts are basic elements in any learning module and are thus very useful for modeling, summarizing, and previewing the content of any module. Automatic extraction of the major concepts from online education materials enables many useful applications. In this paper, we propose to leverage textbooks and their back-of-the-book indexes as training data to train a supervised machine learning algorithm for automatic extraction of concepts from text data in the education domain. We evaluate this idea by training neural networks on three textbooks and applying the trained neural networks to extract concepts from the lecture transcripts of two MOOCs. Our results suggest great promise for further exploration of this direction.","New York, NY, USA",,"Boughoula, Assma and San, Aidan and Zhai, ChengXiang",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406749,9.78145E+12,"back-of-the-book index, lstm, neural networks, concept extraction, mooc","Virtual Event, USA",4,381?€?384,Association for Computing Machinery,L@S '20,Leveraging Book Indexes for Automatic Extraction of Concepts in MOOCs,https://doi.org/10.1145/3386527.3406749,2020
inproceedings,10.1145/3386527.3405948,"Rich models of students' learning and problem-solving behaviors can support tailored interventions by instructors and scaffolding of complex learning activities. Our goal in this paper is to identify students' reading behaviors as they engage with instructional texts in domain-specific activities. In this work, we apply theory and methodology from the learning sciences to a large-scale middle school dataset within a digital literacy platform, Actively Learn. We compare students' reading behaviors both within and across domains for 12,566 science and 16,240 social studies students. Our findings show that higher-performing students in science engaged in more metacognitively-rich reading activities, such as text annotation; whereas lower-performing students relied more on simple highlighting and took longer to respond to embedded questions. Higher-performing students in social studies, by contrast, engaged more with the vocabulary and took longer to read before attempting question responses. Our finding may be used as recommendations to help both teachers and students engage in and support more effective behaviors.","New York, NY, USA",,"Farhana, Effat and Rutherford, Teomara and Lynch, Collin F.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405948,9.78145E+12,"learner behavior analysis, sequence mining","Virtual Event, USA",4,385?€?388,Association for Computing Machinery,L@S '20,Understanding Reading Behaviors of Middle School Students,https://doi.org/10.1145/3386527.3405948,2020
inproceedings,10.1145/3386527.3406750,"Planning a solution before writing code is essential in algorithmic problem-solving. However, novices often skip planning and jump straight into coding. Even if they set up a plan, some do not connect to their plan when writing code. Learners solving algorithmic problems often struggle with high-level components such as solution techniques and sub-problems, but existing representations that guide learners in planning, such as flowcharts, focus on presenting lower-level details. We use subgoal diagrams -- diagrams made of subgoal labels and the relationships between them -- as a representation that guides learners to focus on high-level plans when they develop solutions. We introduce AlgoPlan, an interface that enables learners to build their own subgoal diagram and use it to guide their problem-solving process. A preliminary study with seven students shows that subgoal diagrams help learners focus on high-level plans and connect these plans to their code.","New York, NY, USA",,"Choi, Kabdo and Chen, Sally and Shin, Hyungyu and Son, Jinho and Kim, Juho",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406750,9.78145E+12,"algorithmic problem-solving, subgoal diagram, planning","Virtual Event, USA",4,389?€?392,Association for Computing Machinery,L@S '20,AlgoPlan: Supporting Planning in Algorithmic Problem-Solving with Subgoal Diagrams,https://doi.org/10.1145/3386527.3406750,2020
inproceedings,10.1145/3386527.3406751,"This study examined two machine learning models for de- signing a learning analytics dashboard to assist teachers in facilitating problem-based learning. Specifically, we used BERT to automatically process a large amount of textual data to understand students' scientific argumentation. We then used Hidden Markov Model (HMM) to find students' cognitive state transition with time-series data. Preliminary results showed the models achieved high accuracy and were coherent with related theories, indicating the models can provide teachers with interpretable information to identify in-need students.","New York, NY, USA",,"Pan, Zilong and Li, Chenglu and Liu, Min",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406751,9.78145E+12,"learning analytics dashboard, machine learning, artificial intelligence, problem-based learning (pbl)","Virtual Event, USA",4,393?€?396,Association for Computing Machinery,L@S '20,Learning Analytics Dashboard for Problem-Based Learning,https://doi.org/10.1145/3386527.3406751,2020
inproceedings,10.1145/3386527.3406760,"Teaching robotics is an attractive way of motivating students to learn computer science. However, it is also a challenging topic for students of all ages and only one teacher in a classroom is too little to support approximately 30 students at the same time. Therefore, intelligent tutoring systems might be a meaningful way to support students and teachers. In this paper we describe an approach to support computer science lessons in secondary schools by using a learner model. We are explaining how the three phases of our learner model (data collection - profile construction - profile application) can be implemented for teaching robotics by using different types of implicit and explicit data to generate feedback for the teacher concerning competencies and knowledge of the students on the one hand and by supporting collaboration and group formation amongst the students on the other hand. The model is derived from literature and supported by data from different studies.","New York, NY, USA",,"Schulz, Sandra and Lingnau, Andreas",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406760,9.78145E+12,"robotics, computer science education, feedback, learner model","Virtual Event, USA",4,397?€?400,Association for Computing Machinery,L@S '20,An Evidence-Based Learner Model for Supporting Activities in Robotics,https://doi.org/10.1145/3386527.3406760,2020
inproceedings,10.1145/3386527.3405950,"Massive open online courses (MOOCs) provide a great opportunity to use multiple means of information representation through a mixture of various media such as text, graphics, and video, among others. However, most research on MOOCs focused on learning analytics and not much attention is given to content analysis. We gathered all text corpora and video transcripts of selected MOOCs using a web crawler and looked at word counts, clustered by distribution, and measured readability of the crawled data. Analyzing content distribution allows for a comparison of MOOCs regardless of topics, thus giving us an idea of what most course developers might think is ideal in terms of content distribution. This comparison along with readability analysis can be useful for course pre-run quality assessment and gauging content sufficiency.","New York, NY, USA",,"Carlon, May Kristine Jonson and Keerativoranan, Nopphon and Cross, Jeffrey S.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405950,9.78145E+12,"word counts, web crawler, readability, moocs, content types, clustering","Virtual Event, USA",4,401?€?404,Association for Computing Machinery,L@S '20,Content Type Distribution and Readability of MOOCs,https://doi.org/10.1145/3386527.3405950,2020
inproceedings,10.1145/3386527.3406753,"Mobile learning apps such as Duolingo have allowed millions of students to study new subjects that they might not otherwise be able to. One study mode utilized in mobile learning is a digital ""flashcard,"" a tool used by students for studying and memorizing content both in and out of the traditional classroom. Here I investigate whether a multiple-choice type flashcard, which asks the user to identify the picture from one of 4 options, performs better than a digital flashcard to help users identify pictures of fake, cartoon fish. The results of the study so far are inconclusive, not finding statistically significant differences in quiz scores between participants who use the standard flashcards and those who used the multiple-choice flashcard. However, the results may indicate that participants who studied using the multiple-choice flashcard achieved similar scores while studying less on average than those who studied using the standard flashcards.","New York, NY, USA",,"Kerman, Ian",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406753,9.78145E+12,"mobile learning, elearning, learning at scale, flashcards","Virtual Event, USA",4,405?€?408,Association for Computing Machinery,L@S '20,The Effectiveness of Multiple-Choice Type Flashcards for the Identification of Fish Species,https://doi.org/10.1145/3386527.3406753,2020
inproceedings,10.1145/3386527.3406754,"Content creation has long been regarded as one of the most challenging obstacles to personalized learning. In recent years, however, online platforms have managed to mobilize both audiences and content creators in large numbers, creating new opportunities to revisit the pursuit of personalization at scale. We describe initial results from a real-world implementation of a system for algorithmically generating learning paths at Udemy.com, a two-sided online educational marketplace with over 150,000 courses and over 50 million users. Our initial investigations suggest the potential effectiveness of automated approaches for guiding self-directed learners toward courses that help them achieve their desired learning outcomes.","New York, NY, USA",,"Jia, Julianna Z. and Kutluoglu, Gulsen and Do, Chuong B.",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406754,9.78145E+12,"learning paths, personalized learning, course sequences, online courses","Virtual Event, USA",4,409?€?412,Association for Computing Machinery,L@S '20,Automated Generation of Learning Paths at Scale,https://doi.org/10.1145/3386527.3406754,2020
inproceedings,10.1145/3386527.3406755,"The presence of ""big data"" in higher education has led to the increasing popularity of predictive analytics for guiding various stakeholders on appropriate actions to support student success. In developing such applications, model selection is a central issue. As such, this study presents a comprehensive examination of five commonly used machine learning models in student success prediction. Using administrative and learning management system (LMS) data for nearly 2,000 college students at a public university, we employ the models to predict short-term and long-term academic success. Beyond the tradeoff between model interpretability and accuracy, we also focus on the fairness of these models with regard to different student populations. Our findings suggest that more interpretable models such as logistic regression do not necessarily compromise predictive accuracy. Also, they lead to no more, if not less, prediction bias against disadvantaged student groups than complicated models. Moreover, prediction biases against certain groups persist even in the fairest model. These results thus recommend using simpler algorithms in conjunction with human evaluation in instructional and institutional applications of student success prediction when valid student features are in place.","New York, NY, USA",,"Kung, Catherine and Yu, Renzhe",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406755,9.78145E+12,"predictive analytics, machine learning, higher education, fairness","Virtual Event, USA",4,413?€?416,Association for Computing Machinery,L@S '20,Interpretable Models Do Not Compromise Accuracy or Fairness in Predicting College Success,https://doi.org/10.1145/3386527.3406755,2020
inproceedings,10.1145/3386527.3405953,"Education has traditionally been administered via physical interactions between teachers and students in classrooms. Through technological advancement in communications and digital devices, online education has been developed with the potential to scale education, making it affordable and accessible. With an internet connection and a laptop or mobile phone, learners can access massive open online courses (MOOCs) for free. Nonetheless, the opportunity to scale education and the advantages of online learning are not always fulfilled due to certain challenges. In this work, Socioeconomic, Sociocultural, and IT infrastructural factors are categorized as challenges hindering the adoption of online learning in Nigeria. Although some factors mitigating online learning have been identified in the past, there is relatively little empirical evidence indicating the reality and severity of these challenges. Since scaling education involves worldwide reach, local contexts such as found in Nigeria and other developing countries become critical. The objective of this work, therefore, is to understand these challenges, present empirical evidence through a questionnaire survey, rank these challenges in order of severity, and propose solutions.","New York, NY, USA",,"Abdulmajeed, Kabir and Joyner, David A. and McManus, Christine",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405953,9.78145E+12,"online learning, nigeria, moocs","Virtual Event, USA",4,417?€?420,Association for Computing Machinery,L@S '20,Challenges of Online Learning in Nigeria,https://doi.org/10.1145/3386527.3405953,2020
inproceedings,10.1145/3386527.3406756,"Effective driver education techniques can greatly benefit from the use of state-of-the-art technologies for driving training and tutoring in classroom environment. Such environment includes simulation systems that are designed based on the Intelligent Tutoring System concepts and framework. This research analyzed simulator data for both simulation and vehicle environments to identify factors for driver training guidelines. Based on the results of this study, one of the recommendations is that current ITS based driver training systems be calibrated to accurately measure the steering input which is found to be the most significant parameter influencing time headway (distances between simulated vehicles). The findings also support the modern intelligent tutoring system used at scale that leverages human feedback to improve their design.","New York, NY, USA",,"Ekram, Al-Ahad",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406756,9.78145E+12,"lkas, autonomous vehicle, acc, its, intelligent tutoring system, driving training","Virtual Event, USA",4,421?€?424,Association for Computing Machinery,L@S '20,Understanding the Implications of the Use of Intelligent Tutoring Systems in Driver Training,https://doi.org/10.1145/3386527.3406756,2020
inproceedings,10.1145/3386527.3405954,"This demo will present the implementation of an A.I. powered web application designed to assist students with creation of a homework and study schedule. The intent of this project is to use key principles from Self-Regulated Learning and Cognitive Load Theory to translate the large, abstract problem of ""creating a study and homework schedule from scratch"" into a structured, repeatable set of review tasks. The system then uses a constraint satisfaction AI agent to recommend a weekly schedule of activities that supports the student to achieve the specified goals.","New York, NY, USA",,"Schwabe, Andrew",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3405954,9.78145E+12,"self-regulated learning, agent design, scheduling, cognitive load theory, planning, assistive ai, constraint satisfaction, time management","Virtual Event, USA",2,425?€?426,Association for Computing Machinery,L@S '20,Demo of JARET: A.I. Powered Web App for Goal Review and Time Management,https://doi.org/10.1145/3386527.3405954,2020
inproceedings,10.1145/3386527.3406719,"E-learning is becoming popular as it provides learners the flexibility, targeted resources across the internet, personalized guidance, and immediate feedback during learning. However, lack of social interaction, an indispensable component in developing some skills, has been a pain point in e-learning. We propose using Alexa, a voice-controlled Intelligent Personal Assistants (IPA), in e-learning to provide in-person practice to achieve some desired learning goals. With Alexa enabled learning experiences, learners are able to practice with other students (one role of Alexa) or receive immediate feedback from teachers (another role of Alexa) in an e-learning environment. We propose a configuration driven conversation engine, which can support instructional designers to create diverse in-person practice opportunities in e-learning. We demonstrate that learning designers can create an Alexa activity with a few configuration steps. We also share results on the effectiveness of an Alexa activity with formative assessment evaluation in real world applications.","New York, NY, USA",,"Zhao, Jinjin and Bhatt, Shreyansh and Thille, Candace and Zimmaro, Dawn and Gattani, Neelesh and Walker, Josh",Proceedings of the Seventh ACM Conference on Learning @ Scale,10.1145/3386527.3406719,9.78145E+12,"social interaction, intelligent personal assistant","Virtual Event, USA",2,427?€?428,Association for Computing Machinery,L@S '20,Introducing Alexa for E-Learning,https://doi.org/10.1145/3386527.3406719,2020
inproceedings,10.1145/3330430.3333631,"The Learning at Scale (L@S) conference has brought together researchers from diverse scholarly communities to design and study technologies that are explicitly meant to scale to a large number and variety of learners. Over the last three years, the L@S community has published a thematic, methodological, and bibliometric analysis to reflect on its own interests, challenges, and foundations. This paper continues the wider reflection effort and complements these two prior analyses with an epistemological analysis of the way the papers employ learning theory, evaluate evidence, and deploy statistical models. The epistemological analysis uses two methodologies: coding the full papers from the first four years for epistemological markers of interest and analyzing the network of citations from all of the full papers for dominant institutional and epistemological traditions. By combining these two methods, the present analysis reveals that most papers explicitly show their theoretical commitments, target a narrow slice of available learning theory, draw on varied academic fields in different proportions, and showcase epistemological practices in line with what philosophers of computational science observe in communities using similar model-based methods. The paper then situates these claims in wider conversations occurring in the learning sciences and philosophy of science to provide theoretical insights as well as practical recommendations for how the community can more consciously conduct and communicate its scientific endeavor.","New York, NY, USA",1,"Johanes, Petr",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333631,9.78145E+12,"Citation Network Analysis, Online Learning, Bibliometrics, Epistemology, MOOCs, Knowledge Modeling, Philosophy of Science","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Start of a Science: An Epistemological Analysis of Learning at Scale,https://doi.org/10.1145/3330430.3333631,2019
inproceedings,10.1145/3330430.3333633,"Despite the fact that anyone can sign up for open online courses, their enrollment patterns reflect the historical underrepresentation of certain sociodemographic groups (e.g. women in STEM disciplines). We theorize that enrollment choices online are shaped by contextual cues that activate stereotypes about numeric representation and climate in brick-and-mortar institutions. A longitudinal matched-pairs experiment with 14 MOOCs (N=29,000) tested this theory by manipulating the presence of a diversity statement on course pages and measuring effects on who enrolls. We found a 3% increase in the proportion of students with lower socioeconomic status. The effect size varied across courses between -0.5 and 7 percentage points. No significant changes in enrollment patterns by gender, age, and national development level occurred. Implications for the use and content of diversity statements and their alternatives are discussed.","New York, NY, USA",2,"Kizilcec, Ren\'{e} F. and Saltarelli, Andrew J.",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333633,9.78145E+12,"Inclusion, Equality, Education, Social Psychology, Diversity","Chicago, IL, USA",8,,Association for Computing Machinery,L@S '19,Can a Diversity Statement Increase Diversity in MOOCs?,https://doi.org/10.1145/3330430.3333633,2019
inproceedings,10.1145/3330430.3333616,"While global massive open online course (MOOC) providers such as edX, Coursera, and FutureLearn have garnered the bulk of attention from researchers and the popular press, MOOCs are also provisioned by a series of regional providers, who are often using the Open edX platform. We leverage the data infrastructure shared by the main edX instance and one regional Open edX provider, Edraak in Jordan, to compare the experience of learners from Arab countries on both platforms. Comparing learners from Arab countries on edX to those on Edraak, the Edraak population has a more even gender balance, more learners with lower education levels, greater participation from more developing countries, higher levels of persistence and completion, and a larger total population of learners. This ""apples to apples"" comparison of MOOC learners is facilitated by an approach to multiplatform MOOC analytics, which employs parallel research processes to create joint aggregate datasets without sharing identifiable data across institutions. Our findings suggest that greater research attention should be paid towards regional MOOC providers, and regional providers may have an important role to play in expanding access to higher education.","New York, NY, USA",3,"Ruip\'{e}rez-Valiente, Jos\'{e} A. and Halawa, Sherif and Reich, Justin",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333616,9.78145E+12,"Cultural Factors, Cross-institutional Collaboration, MOOCs, Learning Analytics, Large-scale Analytics","Chicago, IL, USA",9,,Association for Computing Machinery,L@S '19,Multiplatform MOOC Analytics: Comparing Global and Regional Patterns in EdX and Edraak,https://doi.org/10.1145/3330430.3333616,2019
inproceedings,10.1145/3330430.3333624,"With Massive Open Online Courses (MOOCs) the number of people having access to higher education increased rapidly. The intentions to enroll for a specific course vary significantly and depend on one's professional or personal learning needs and interests. All learners have in common that they pursue their individual learning objectives. However, predominant MOOC platforms follow a one-size-fits-all approach and primarily aim for completion with certification. Specifically, technical support for goal-oriented and self-regulated learning to date is very limited in this context although both learning strategies are proven to be key factors for students' achievement in large-scale online learning environments. In this first investigation, a concept for the application and technical integration of personalized learning objectives in a MOOC platform is realized and assessed. It is evaluated with a mixed-method approach. First, the learners' acceptance is examined with a multivariate A/B test in two courses. Second, a survey was conducted to gather further feed-back about the perceived usefulness, next to the acceptance. The results show a positive perception by the learners, which paves the way for future research.","New York, NY, USA",4,"Rohloff, Tobias and Sauer, Dominic and Meinel, Christoph",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333624,9.78145E+12,"Learning Objectives, Goal-Oriented Learning, MOOCs, Self-Regulated Learning, E-Learning","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,On the Acceptance and Usefulness of Personalized Learning Objectives in MOOCs,https://doi.org/10.1145/3330430.3333624,2019
inproceedings,10.1145/3330430.3333619,"The ability to work in teams is an important skill in today's work environments. In MOOCs, however, team work, team tasks, and graded team-based assignments play only a marginal role. To close this gap, we have been exploring ways to integrate graded team-based assignments in MOOCs. Some goals of our work are to determine simple criteria to match teams in a volatile environment and to enable a frictionless online collaboration for the participants within our MOOC platform. The high dropout rates in MOOCs pose particular challenges for team work in this context. By now, we have conducted 15 MOOCs containing graded team-based assignments in a variety of topics. The paper at hand presents a study that aims to establish a solid understanding of the participants in the team tasks. Furthermore, we attempt to determine which team compositions are particularly successful. Finally, we examine how several modifications to our platform's collaborative toolset have affected the dropout rates and performance of the teams.","New York, NY, USA",5,"Staubitz, Thomas and Meinel, Christoph",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333619,9.78145E+12,"Peer Assessment, MOOCs, Teamwork, Project-based learning, Team-based Learning, Team Assessment","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Graded Team Assignments in MOOCs: Effects of Team Composition and Further Factors on Team Dropout Rates and Performance,https://doi.org/10.1145/3330430.3333619,2019
inproceedings,10.1145/3330430.3333621,"Learners increasingly refer to online videos for learning new technical concepts, but often overlook or forget key details. We investigated how retrieval practice, a learning strategy commonly used in education, could be designed to reinforce key concepts in online videos. We began with a formative study to understand users' perceptions of cued and free-recall retrieval techniques. We next designed a new in-context flashcard-based technique that provides expert-curated retrieval exercises in context of a video's playback. We evaluated this technique with 14 learners and investigated how learners engage with flashcards that are prompted automatically at predefined intervals or flashcards that appear on-demand. Our results overall showed that learners perceived automatically prompted flashcards to be less effortful and made the learners feel more confident about grasping key concepts in the video. However, learners found that on-demand flashcards gave them more control over their learning and allowed them to personalize their review of content. We discuss the implications of these findings for designing hybrid automatic and on-demand in-context retrieval exercises for online videos.","New York, NY, USA",6,"Chaudhury, Rimika and Chilana, Parmit K.",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333621,9.78145E+12,"retrieval practice, in-context exercises, video based learning","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,How Learners Engage with In-Context Retrieval Exercises in Online Informational Videos,https://doi.org/10.1145/3330430.3333621,2019
inproceedings,10.1145/3330430.3333618,"While video becomes increasingly prevalent in educational settings, current research has yet to investigate what feedback instructors need regarding their students' engagement and learning despite video technologies being equipped to provide viewing analytics and collect student feedback. In this paper we investigate instructors' requirements from video analytics. We used a Grounded Theory Approach and interviewed 16 instructors who teach using video to determine the advantages for using video in their teaching and the different requirements for analytics and feedback in their existing practice. Based on our analysis of the interviews, we found three categories of information that instructors want to inform their teaching. Instructors are looking to see if their students have watched their videos, how much they understood in those videos, and how useful the videos are to the students. These categories provide the foundations and design implications for instructor-centric educational video analytics interfaces.","New York, NY, USA",7,"Fong, Matthew and Dodson, Samuel and Harandi, Negar Mohaghegh and Seo, Kyoungwon and Yoon, Dongwook and Roll, Ido and Fels, Sidney",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333618,9.78145E+12,"teaching, video, learning, analytics, blended learning","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,"Instructors Desire Student Activity, Literacy, and Video Quality Analytics to Improve Video-Based Blended Courses",https://doi.org/10.1145/3330430.3333618,2019
inproceedings,10.1145/3330430.3333632,"Students' personal qualities other than cognitive ability are known to influence persistence and achievement in formal learning environments, but the extent of their influence in digital learning environments is unclear. This research investigates non-cognitive factors in mobile learning in a resource-poor context. We surveyed 1,000 Kenyan high school students who use a popular SMS-based learning platform that provides formative assessments aligned with the national curriculum. Combining survey responses with platform interaction logs, we find growth mindset to be one of the strongest predictors of assessment scores. We investigate theory-based behavioral mechanisms to explain this relationship. Although students who hold a growth mindset are not more likely to persist after facing adversity, they spend more time on each assessment, increasing their likelihood of answering correctly. Results suggest that cultivating a growth mindset can motivate students in a resource-poor context to excel in a mobile learning environment.","New York, NY, USA",8,"Kizilcec, Ren\'{e} F. and Goldfarb, Daniel",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333632,9.78145E+12,"Mobile Learning, Learning Analytics, Expectancy-value theory, Self-efficacy, Mindset, Africa","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Growth Mindset Predicts Student Achievement and Behavior in Mobile Learning,https://doi.org/10.1145/3330430.3333632,2019
inproceedings,10.1145/3330430.3333627,"Computer programming instructors frequently perform live coding in settings ranging from MOOC lecture videos to online livestreams. However, there is little tool support for this mode of teaching, so presenters must now either screen-share or use generic slideshow software. To overcome the limitations of these formats, we propose that programming environments should directly facilitate live coding for education. We prototyped this idea by creating Improv, an IDE extension for preparing and delivering code-based presentations informed by Mayer's principles of multimedia learning. Improv lets instructors synchronize blocks of code and output with slides and create preset waypoints to guide their presentations. A case study on 30 educational videos containing 28 hours of live coding showed that Improv was versatile enough to replicate approximately 96% of the content within those videos. In addition, a preliminary user study on four teaching assistants showed that Improv was expressive enough to allow them to make their own custom presentations in a variety of styles and improvise by live coding in response to simulated audience questions. Users mentioned that Improv lowered cognitive load by minimizing context switching and made it easier to fix errors on-the-fly than using slide-based presentations.","New York, NY, USA",9,"Chen, Charles H. and Guo, Philip J.",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333627,9.78145E+12,,"Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Improv: Teaching Programming at Scale via Live Coding,https://doi.org/10.1145/3330430.3333627,2019
inproceedings,10.1145/3330430.3333628,"Prior studies on scaffolding for investigative inquiry practices (i.e. forming a question/hypothesis, collecting data, and analyzing and interpreting data [21]) revealed that students who received scaffolding were better able to both learn practices and transfer these competencies to new topics than were students who did not receive scaffolding. Prior studies have also shown that after removing scaffolding, students continued to demonstrate improved inquiry performance on a variety of practices across new driving questions over time. However, studies have not examined the relationship between the amount of scaffolding received and transfer of inquiry performance; this is the focus of the present study. 107 middle school students completed four virtual lab activities (i.e. driving questions) in Inq-ITS. Students received scaffolding when needed from an animated pedagogical computer agent for the first three driving questions for the Animal Cell virtual lab. Then they completed the fourth driving question without access to scaffolding in a different topic, Plant Cell. Results showed that students' performances increased even with fewer scaffolds for the inquiry practices of hypothesizing, collecting data, interpreting data, and warranting claims; furthermore, these results were robust as evidenced by the finding that students required less scaffolding as they completed subsequent inquiry activities. These data provide evidence of near and far transfer as a result of adaptive scaffolding of science inquiry practices.","New York, NY, USA",10,"Li, Haiying and Gobert, Janice and Dickler, Rachel",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333628,9.78145E+12,"Scalability, science inquiry, inquiry practices, scaffolding","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Scaffolding during Science Inquiry,https://doi.org/10.1145/3330430.3333628,2019
inproceedings,10.1145/3330430.3333635,"Group projects are an essential component of teaching user interface (UI) design. We identified six challenges in transferring traditional group projects into the context of Massive Open Online Courses: managing dropout, avoiding free-riding, appropriate scaffolding, cultural and time zone differences, and establishing common ground. We present a case study of the design of a group project for a UI Design MOOC, in which we implemented technical tools and social structures to cope with the above challenges. Based on survey analysis, interviews, and team chat data from the students over a six-month period, we found that our socio-technical design addressed many of the obstacles that MOOC learners encountered during remote collaboration. We translate our findings into design implications for better group learning experiences at scale.","New York, NY, USA",11,"Cheng, Hao-Fei and Yu, Bowen and Fu, Siwei and Zhao, Jian and Hecht, Brent and Konstan, Joseph and Terveen, Loren and Yarosh, Svetlana and Zhu, Haiyi",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333635,9.78145E+12,"HCI Education, MOOCs, Collaborative Learning","Chicago, IL, USA",11,,Association for Computing Machinery,L@S '19,Teaching UI Design at Global Scales: A Case Study of the Design of Collaborative Capstone Projects for MOOCs,https://doi.org/10.1145/3330430.3333635,2019
inproceedings,10.1145/3330430.3333625,"Online learning in STEM subjects requires an easy way to enter and automatically mark mathematical equations. Existing solutions did not meet our requirements, and therefore we developed Inequality, a new open-source system which works across all major browsers, supports both mouse and touch-based entry, and is usable by high school children and teachers. Inequality has been in use for over 2 years by about 20000 students and nearly 900 teachers as part of the Isaac online learning platform. In this paper we evaluate Inequality as an entry method, assess the flexibility of our approach, and the effect the system has on student behaviour. We prepared 343 questions which could be answered using either Inequality or a traditional method. Looking across over 472000 question attempts, we found that students were equally proficient at answering questions correctly with both entry methods. Moreover, students using Inequality required fewer attempts to arrive at the correct answer 73% of the time. In a detailed analysis of equation construction, we found that Inequality provides significant flexibility in the construction of mathematical expressions, accommodating different working styles. We expected students who first worked on paper before entering their answers would require fewer attempts than those who did not, however this was not the case (p = 0.0109). While our system is clearly usable, a user survey highlighted a number of issues which we have addressed in a subsequent update.","New York, NY, USA",12,"Franceschini, Andrea and Sharkey, James P. and Beresford, Alastair R.",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333625,9.78145E+12,"Equation entry, symbolic manipulation, automated marking, Computed Aided Assessment, teaching physics, teaching mathematics","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Inequality: Multi-Modal Equation Entry on the Web,https://doi.org/10.1145/3330430.3333625,2019
inproceedings,10.1145/3330430.3333615,"Automated assessment of complex assignments is crucial for scaling up learning of complex skills such as critical thinking. To address this challenge, one previous work has applied supervised machine learning to automate the assessment by learning from examples of graded assignments by humans. However, in the previous work, only simple lexical features, such as words or n-grams, have been used. In this paper, we propose to use topics as features for this task, which are more interpretable than those simple lexical features and can also address polysemy and synonymy of lexical semantics. The topics can be learned automatically from the student assignment data by using a probabilistic topic model. We propose and study multiple approaches to construct topical features and to combine topical features with simple lexical features. We evaluate the proposed methods using clinical case assignments performed by veterinary medicine students. The experimental results show that topical features are generally very effective and can substantially improve performance when added on top of the lexical features. However, their effectiveness is highly sensitive to how the topics are constructed and a combination of topics constructed using multiple views of the text data works the best. Our results also show that combining the prediction results of using different types of topical features and of topical and lexical features is more effective than pooling all features together to form a larger feature space.","New York, NY, USA",13,"Kuzi, Saar and Cope, William and Ferguson, Duncan and Geigle, Chase and Zhai, ChengXiang",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333615,9.78145E+12,,"Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Automatic Assessment of Complex Assignments Using Topic Models,https://doi.org/10.1145/3330430.3333615,2019
inproceedings,10.1145/3330430.3333626,"In low-resource, over-burdened schools and learning centres, peer assessment systems promise significant practical and pedagogical benefits. Many of the these benefits have been realised in contexts like massive open online courses (MOOCs) and university classrooms which share a specific trait with low-resource schools: high learner-teacher ratios. However, the constraints and considerations for designing and deploying peer assessment systems in low-resource classrooms have not been well-researched and understood, especially for high school. In this paper, we present the design of a peer assessment system for second language learning (English as a Second Language) for high school learners in South Africa. We report findings from multiple studies investigating qualitative and quantitative aspects of peer review, as well as the contextual factors that influence the viability of peer assessment systems in these contexts.","New York, NY, USA",14,"Molapo, Maletsabisa and Moodley, Chane Simone and Akhalwaya, Ismail Yunus and Kurien, Toby and Kloppenberg, Jay and Young, Richard",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333626,9.78145E+12,"Low-Resource Learning, Qualitative Methods, Peer Assessment, Second Language Learning, Mobile Learning","Chicago, IL, USA",13,,Association for Computing Machinery,L@S '19,Designing Digital Peer Assessment for Second Language Learning in Low Resource Learning Settings,https://doi.org/10.1145/3330430.3333626,2019
inproceedings,10.1145/3330430.3333637,"In principle, learning can be increased by assessing the detailed state of student knowledge and mistaken knowledge with a pre-test and then optimizing instruction as measured by the post-test score. As a first step in this direction, we applied a Multidimensional Item Response Theory (MIRT) to 17,000 pre-instruction administrations of the Force Concept Inventory (FCI) to study students' initial knowledge in detail. Examination of Item Response Curves (IRCs) showed that even students scoring below chance are not randomly guessing, but instead preferentially select only one or two distractors. Two dimensional IRT applied to the entire set of 150 possible responses, rather than applied dichotomously to the thirty questions, revealed two skill dimensions of comparable variance. Perpendicular directions were identified within this space corresponding to Newtonian ability and propensity to select responses whose IRC's have a maximum at intermediate Newtonian ability rather than at the top of bottom of this dimension. These intermediate responses corresponded to known pre-Newtonian ideas, particularly the Medieval concept of impetus. The ability to measure the detailed misconceptions of individual students or classes will allow development and application of instructional interventions for such specific misunderstandings, which are typically unchanged by traditional instruction.","New York, NY, USA",15,"P\'{e}rez-Lemonche, \'{A}ngel and Stewart, John and Drury, Byron and Henderson, Rachel and Shvonski, Alex and Pritchard, David E.",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333637,9.78145E+12,"Response Curves, Multidimensional IRT, Assessing Learning, pre-post testing, Newtonian, Force Concept Inventory","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Mining Students Pre-Instruction Beliefs for Improved Learning,https://doi.org/10.1145/3330430.3333637,2019
inproceedings,10.1145/3330430.3333629,"Automated essay scoring (AES) allows writing to be assigned in large courses and can provide instant formative feedback to students. However, creating models for AES can be costly, requiring the collection and human scoring of hundreds of essays. We have developed and are piloting a web-based tool that allows instructors to incrementally score responses to enable AES scoring while minimizing the number of essays the instructors must score. Previous work has shown that techniques from the machine learning subfield of active learning can reduce the amount of training data required to create effective AES models. We extend those results to a less idealized scenario: one driven by the instructor's need to score sets of essays, in which the model is trained iteratively using batch mode active learning. We propose a novel approach inspired by a class of topological methods, but with reduced computational requirements, which we refer to as topological maxima. Using actual student data, we show that batch mode active learning is a practical approach to training AES models. Finally, we discuss implications of using this technology for automated customized scoring of writing across the curriculum.","New York, NY, USA",16,"Hellman, Scott and Rosenstein, Mark and Gorman, Andrew and Murray, William and Becker, Lee and Baikadi, Alok and Budden, Jill and Foltz, Peter W.",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333629,9.78145E+12,"Active learning, Automated Essay Scoring, Machine Learning, Topology","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Scaling Up Writing in the Curriculum: Batch Mode Active Learning for Automated Essay Scoring,https://doi.org/10.1145/3330430.3333629,2019
inproceedings,10.1145/3330430.3333614,"In schools and colleges around the world, open-ended home-work assignments are commonly used. However, such assignments require substantial instructor effort for grading, and tend not to support opportunities for repeated practice. We propose UpGrade, a novel learnersourcing approach that generates scalable learning opportunities using prior student solutions to open-ended problems. UpGrade creates interactive questions that offer automated and real-time feedback, while enabling repeated practice. In a two-week experiment in a college-level HCI course, students answering UpGrade-created questions instead of traditional open-ended assignments achieved indistinguishable learning outcomes in ~30% less time. Further, no manual grading effort is required. To enhance quality control, UpGrade incorporates a psychometric approach using crowd workers' answers to automatically prune out low quality questions, resulting in a question bank that exceeds reliability standards for classroom use.","New York, NY, USA",17,"Wang, Xu and Talluri, Srinivasa Teja and Rose, Carolyn and Koedinger, Kenneth",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333614,9.78145E+12,"deliberate practice, multiple-choice question, Crowdsourcing, open-ended assignment, online education","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,UpGrade: Sourcing Student Open-Ended Solutions to Create Scalable Learning Opportunities,https://doi.org/10.1145/3330430.3333614,2019
inproceedings,10.1145/3330430.3333620,"How do we design technology for learning at scale? Based on an examination of a large number of influential systems for learning at scale, I argue that designing for scale is not an amorphous design undertaking. Instead, it builds on two distinct perspectives on scale. Systems built with a scaling through efficiency perspective make learning more efficient and allow the same number of instructors to help a much larger set of learners. Systems with a scaling through empowerment perspective empower a larger number of people to assist learners effectively. I outline how these simple differences in design perspective lead to large differences in design concerns, techniques, and evaluation criteria. Articulating prevalent design perspectives should make overlooked design opportunities more salient, help systems designers design for scale more deliberately and understand their tradeoffs, and open up new opportunities to designers who shift their perspectives.","New York, NY, USA",18,"Kulkarni, Chinmay",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333620,9.78145E+12,"systems for scale, empowerment, efficiency, design perspectives","Chicago, IL, USA",11,,Association for Computing Machinery,L@S '19,Design Perspectives of Learning at Scale: Scaling Efficiency and Empowerment,https://doi.org/10.1145/3330430.3333620,2019
inproceedings,10.1145/3330430.3333617,"Numerous studies have concluded that viewer retention decreases as video length increases. However, we are not aware of any prior work in which a set of longer MOOC (Massive Open Online Course) videos are compared with the same content split into multiple shorter videos. We are fortunate to be in the unique position to have two separate MOOCs that teach essentially the same content using two different platforms (the LEGO Mindstorms NXT and EV3 robots). In our NXT MOOC, videos are quite long, with over 20% of the videos having a running time of more than ten minutes. The EV3 MOOC has very similar content; EV3 MOOC scripts were written by modifying NXT scripts as appropriate. However, many of the EV3 lessons were split into two or three shorter videos in place of a single longer one. NXT videos that are very close in terms of both content and duration to EV3 videos have similar average percentage viewed. This suggests that the two populations watching the videos are similar and that we have a promising setup for analyzing the relationship between NXT lessons whose EV3 counterparts consist of multiple shorter videos. We present an analysis of our data, along with various interpretations some, but not all, of which support the ""shorter videos are better"" hypothesis.","New York, NY, USA",19,"Kay, Jennifer S. and Lambe, Colin and Nolan, Tyler J. and Grello, Thomas M. and Breitzman, Anthony",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333617,9.78145E+12,"in-video dropout, online education, viewer engagement, Video analysis, MOOC","Chicago, IL, USA",7,,Association for Computing Machinery,L@S '19,Apples to Apples: Differences in Viewer Retention When Longer Content is Chopped into Smaller Bites,https://doi.org/10.1145/3330430.3333617,2019
inproceedings,10.1145/3330430.3333636,"Automatic question generation is a promising tool for developing the learning systems of the future. Research in this area has mostly relied on having answers (key phrases) identified beforehand and given as a feature, which is not practical for real-world, scalable applications of question generation. We describe and implement an end-to-end neural question generation system that generates question and answer pairs given a context paragraph only. We accomplish this by first generating answer candidates (key phrases) from the paragraph context, and then generating questions using the key phrases. We evaluate our method of key phrase extraction by comparing our output over the same paragraphs with question-answer pairs generated by crowdworkers and by educational experts. Results demonstrate that our system is able to generate educationally meaningful question and answer pairs with only context paragraphs as input, significantly increasing the potential scalability of automatic question generation.","New York, NY, USA",20,"Willis, Angelica and Davis, Glenn and Ruan, Sherry and Manoharan, Lakshmi and Landay, James and Brunskill, Emma",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333636,9.78145E+12,"Educational content generation, Educational question generation, Recurrent neural networks, Automatic answer extraction","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Key Phrase Extraction for Generating Educational Question-Answer Pairs,https://doi.org/10.1145/3330430.3333636,2019
inproceedings,10.1145/3330430.3333630,"In 2014, Georgia Tech launched the first for-credit MOOC-based graduate degree program. In the five years since, the program has proven generally successful, enrolling over 14,000 unique students, and several other similar programs have followed in its footsteps. Existing research on the program has focused largely on details of individual classes; program-level research, however, has been scarce. In this paper, we delve into the program-level details of an at-scale Master's degree, from the story of its creation through the data generated by the program, including the numbers of applications, admissions, matriculations, and graduations; enrollment details including demographic information and retention patterns; trends in student grades and experience as compared to the on-campus student body; and alumni perceptions. Among our findings, we note that the program has stabilized at a retention rate of around 70%; that the program's growth has not slowed; that the program has not cannibalized its on-campus counterpart; and that the program has seen an upward trend in the number of women enrolled as well as a persistently higher number of underrepresented minorities than the on-campus program. Throughout this analysis, we abstract out distinct lessons that should inform the development and growth of similar programs.","New York, NY, USA",21,"Joyner, David A. and Isbell, Charles",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333630,9.78145E+12,"online education, Affordable degrees at scale, retention, graduation","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Master's at Scale: Five Years in a Scalable Online Graduate Degree,https://doi.org/10.1145/3330430.3333630,2019
inproceedings,10.1145/3330430.3333622,"Higher education at scale, such as in the California public post-secondary system, has promoted upward socioeconomic mobility by supporting student transfer from 2-year community colleges to 4-year degree granting universities. Among the barriers to transfer is earning enough credit at 2-year institutions that qualify for the transfer credit required by 4-year degree programs. Defining which course at one institution will count as credit for an equivalent course at another institution is called course articulation, and it is an intractable task when attempting to manually articulate every set of courses at every institution with one another. In this paper, we present a methodology towards making tractable this process of defining and maintaining articulations by leveraging the information contained within historic enrollment patterns and course catalog descriptions. We provide a proof-of-concept analysis using data from a 4-year and 2-year institution to predict articulation pairs between them, produced from machine translation models and validated by a set of 65 institutionally pre-established course-to-course articulations. Finally, we create a report of proposed articulations for consumption by the institutions and close with a discussion of limitations and the challenges to adoption.","New York, NY, USA",22,"Pardos, Zachary A. and Chau, Hung and Zhao, Haocheng",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333622,9.78145E+12,"course-to-course articulation, Higher education, machine translation, enrollment data, credit mobility","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Data-Assistive Course-to-Course Articulation Using Machine Translation,https://doi.org/10.1145/3330430.3333622,2019
inproceedings,10.1145/3330430.3333623,"The processes through which course selections accumulate into college pathways in US higher education is poorly instrumented for observation at scale. We offer an analytic toolkit, called Via, which transforms commonly available enrollment data into formal graphs that are amenable to interactive visualizations and computational exploration. We explain the procedures required to project enrollment records onto graphs, and then demonstrate the toolkit utilizing eighteen years of enrollment data at a large private research university. Findings complement prior research on academic search and offer powerful new means for making pathway navigation more efficient.","New York, NY, USA",23,"Angus, Geoffrey and Martinez, Richard Diehl and Stevens, Mitchell L. and Paepcke, Andreas",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333623,9.78145E+12,"Course Sequences, Graph Visualization, Academic Pathways","Chicago, IL, USA",10,,Association for Computing Machinery,L@S '19,Via: Illuminating Academic Pathways at Scale,https://doi.org/10.1145/3330430.3333623,2019
inproceedings,10.1145/3330430.3333634,"Massive Open Online Courses (MOOCs) are an efficient way of delivering knowledge to thousands of learners. However, even among learners who show a clear intention to complete a MOOC, the dropout rate is substantial. This is particularly relevant in the context of MOOC-based educational programs where a funnel of participation can be observed and high dropout rates at early stages of the program significantly reduce the number of learners successfully completing it. In this paper, we propose an approach to identify learners at risk of dropping out from a course, and we design and test an intervention intended to mitigate that risk. We collect course clickstream data from MOOCs of the MITx MicroMasters?? in Supply Chain Management program and apply machine learning algorithms to predict potential dropouts. Our final model is able to predict 80% of actual dropouts. Based on these results, we design an intervention aimed to increase learners' motivation and engagement with a MOOC. The intervention consists on sending tailored encouragement emails to at-risk learners, but despite the high email opening rate, it shows no effect in dropout reduction.","New York, NY, USA",24,"Borrella, Inma and Caballero-Caballero, Sergio and Ponce-Cueto, Eva",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333634,9.78145E+12,"MOOC, Online education, Higher education, Machine learning, Dropout, Retention, Predictive model, Intervention","Chicago, IL, USA",9,,Association for Computing Machinery,L@S '19,Predict and Intervene: Addressing the Dropout Problem in a MOOC-Based Program,https://doi.org/10.1145/3330430.3333634,2019
inproceedings,10.1145/3330430.3333638,"Contemporary online learning systems are increasingly common elements of post-secondary, workplace, and lifelong education. These systems typically employ the transmission model of education to teach students, an approach ill-suited for fostering deeper learning. This paper presents our latest findings related to ongoing research developing a generalizable framework for supporting deeper learning in online learning systems. In this work, we focus on the self-debriefing component of our framework and its impact on deeper learning in online learning systems. To pursue this line of inquiry, we conducted an exploratory study evaluating the Chimeria:Grayscale MOOC, an online learning system that implements our framework. Our results suggest that self-debriefing is crucial for effectively supporting students' reflections.","New York, NY, USA",25,"Ortiz, Pablo and Harrell, D. Fox",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333638,9.78145E+12,"deeper learning, reflection, mooc, interactive narrative, roleplay","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Chimeria: Grayscale MOOC: Towards Critical Self-Reflection at Scale,https://doi.org/10.1145/3330430.3333638,2019
inproceedings,10.1145/3330430.3333639,"Large scale learning systems for introductory programming need to be able to automatically assess the quality of students' performance on programming tasks. This assessment is done using a performance measure, which provides feedback to students and teachers, and an input to the domain, student and tutor models. The choice of a good performance measure is nontrivial, since the performance of students can be measured in many ways, and the design of measure can interact with the adaptive features of a learning system or imperfections in the used domain model. We discuss the important design decisions and illustrate the process of an iterative design and evaluation of a performance measure in a case study.","New York, NY, USA",26,"Effenberger, Tom\'{a}\v{s} and Pel\'{a}nek, Radek",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333639,9.78145E+12,,"Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Measuring Students' Performance on Programming Tasks,https://doi.org/10.1145/3330430.3333639,2019
inproceedings,10.1145/3330430.3333640,"With the aim of supporting instructional designers in setting up collaborative learning activities in MOOCs, this paper derives prediction models for student participation in group discussions. The salient feature of these models is that they are built using only data prior to the learning activity, and can thus provide actionable predictions, as opposed to post-hoc approaches common in the MOOC literature. Some learning design scenarios that make use of this actionable information are illustrated.","New York, NY, USA",27,"Er, Erkan and G\'{o}mez-S\'{a}nchez, Eduardo and Bote-Lorenzo, Miguel L. and Asensio-P\'{e}rez, Juan I. and Dimitriadis, Yannis",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333640,9.78145E+12,"MOOC, actionable learning analytics, collaborative learning","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Informing the Design of Collaborative Activities in MOOCs Using Actionable Predictions,https://doi.org/10.1145/3330430.3333640,2019
inproceedings,10.1145/3330430.3333641,"Quantification of the difficulty of problem solving tasks has many applications in the development of adaptive learning systems, e.g., task sequencing, student modeling, and insight for content authors. There are, however, many potential conceptualizations and measures of problem difficulty and the computation of difficulty measures is influenced by biases in data collection. In this work, we explore difficulty measures for introductory programming tasks. The results provide insight into non-trivial behavior of even simple difficulty measures.","New York, NY, USA",28,"Effenberger, Tom\'{a}\v{s} and \v{C}ech\'{a}k, Jaroslav and Pel\'{a}nek, Radek",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333641,9.78145E+12,,"Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Measuring Difficulty of Introductory Programming Tasks,https://doi.org/10.1145/3330430.3333641,2019
inproceedings,10.1145/3330430.3333642,"This paper addresses the related issues of which pedagogies improve with scale and how to develop a novel platform for inquiry-led learning at scale. The paper begins by introducing pedagogy-informed design of platforms for learning at scale. It then summarizes previous work to develop a platform for open science investigations. Then, it introduces a new platform for inquiry-led learning at scale. The paper concludes with an evaluation of the effectiveness of the platform to: meet its design requirements; enable individuals, groups and institutions to design inquiry-led investigations; engage members of the public to participate; and enable learning activities on the platform to sustain and grow.","New York, NY, USA",29,"Sharples, Mike and Aristeidou, Maria and Herodotou, Christothea and McLeod, Kevin and Scanlon, Eileen",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333642,9.78145E+12,"innovative pedagogy, learning at scale, citizen inquiry, Inquiry-led learning","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Inquiry Learning at Scale: Pedagogy-Informed Design of a Platform for Citizen Inquiry,https://doi.org/10.1145/3330430.3333642,2019
inproceedings,10.1145/3330430.3333643,"Digitization of education has brought a tremendous amount of online materials that are potentially useful for language learners to practice their reading skills. However, these digital materials rarely help with conversational practice, a key component of foreign language learning. Leveraging recent advances in chatbot technologies, we developed BookBuddy, a scalable virtual reading companion that can turn any reading material into an interactive conversation-based English lesson. We piloted our virtual tutor with five 6-year-old native Chinese-speaking children currently learning English. Preliminary results suggest that children enjoyed speaking English with our virtual tutoring chatbot and were highly engaged during the interaction.","New York, NY, USA",30,"Ruan, Sherry and Willis, Angelica and Xu, Qianyao and Davis, Glenn M. and Jiang, Liwei and Brunskill, Emma and Landay, James A.",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333643,9.78145E+12,"pedagogical agent, foreign language learning, Educational chatbot","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,BookBuddy: Turning Digital Materials Into Interactive Foreign Language Lessons Through a Voice Chatbot,https://doi.org/10.1145/3330430.3333643,2019
inproceedings,10.1145/3330430.3333644,"We investigate how the technology acceptance and learning experience of the digital education platform HPI Schul-Cloud (HPI School Cloud) for German secondary school teachers can be improved by proposing a user-centered research and development framework. We highlight the importance of developing digital learning technologies in a user-centered way to take differences in the requirements of educators and students into account. We suggest applying qualitative and quantitative methods to build a solid understanding of a learning platform's users, their needs, requirements, and their context of use. After concept development and idea generation of features and areas of opportunity based on the user research, we emphasize on the application of a multi-attribute utility analysis decision-making framework to prioritize ideas rationally, taking results of user research into account. Afterward, we recommend applying the principle build-learn-iterate to build prototypes in different resolutions while learning from user tests and improving the selected opportunities. Last but not least, we propose an approach for continuous short- and long-term user experience controlling and monitoring, extending existing web- and learning analytics metrics.","New York, NY, USA",31,"Bruechner, Dominik and Renz, Jan and Klingbeil, Mandy",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333644,9.78145E+12,"learning platform, user-centered design, evaluation, HPI Schul-Cloud, user research framework, user experience","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Creating a Framework for User-Centered Development and Improvement of Digital Education,https://doi.org/10.1145/3330430.3333644,2019
inproceedings,10.1145/3330430.3333645,"In this paper, we are discussing the case of offering retired assessment items as practice problems for the purposes of learning in a system called ACT Academy. In contrast to computer-assisted learning platforms, where students consistently focus on small sets of skills they practice till mastery, in our case, students are free to explore the whole subject domain. As a result, they have significantly lower attempt counts per individual skill.We have developed and evaluated a student modeling approach that differs from traditional approaches to modeling skill acquisition by leveraging the hierarchical relations in the skill taxonomy used for indexing practice problems. Results show that when applied in systems like ACT Academy, this approach offers significant improvements in terms of predicting student performance.","New York, NY, USA",32,"Yudelson, Michael and Rosen, Yigal and Polyak, Steve and de la Torre, Jimmy",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333645,9.78145E+12,"assessment, Online learning, skill acquisition, multi-level modeling","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Leveraging Skill Hierarchy for Multi-Level Modeling with Elo Rating System,https://doi.org/10.1145/3330430.3333645,2019
inproceedings,10.1145/3330430.3333646,"In classrooms, instructors teaching students how to code have the ability to monitor progress and provide feedback through regular interaction. There is generally no analogous tracing of learning progression in programming MOOCs, hindering the ability of MOOC platforms to provide automated feedback at scale. We explore features for every certified student's history of code submissions to specific problems in a programming MOOC and measure similarity to sample solutions. We seek to understand whether students who succeed in the course reach solutions similar to these instructor-intended sample solutions, in terms of the concepts and mechanisms they contain. Furthermore, do students learn to conform to instructor expectations as the course progresses, and does prior experience have correlations with student behavior? We also explore what feature representations are sufficient for code submission history, since they are directly applicable to the development of automated tutors for progress tracking.","New York, NY, USA",33,"Bajwa, Ayesha and Hemberg, Erik and Bell, Ana and O'Reilly, Una-May",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333646,9.78145E+12,"Learning trajectories, program features, MOOCs","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Student Code Trajectories in an Introductory Programming MOOC,https://doi.org/10.1145/3330430.3333646,2019
inproceedings,10.1145/3330430.3333647,"To design good assessments, it is useful to have an estimate of the difficulty of a novel exam question before running an exam. In this paper, we study a collection of a few hundred automatic item generators (short computer programs that generate a variety of unique item instances) and show that their exam difficulty can be roughly predicted from student performance on the same generator during pre-exam practice. Specifically, we show that the rate that students correctly respond to a generator on an exam is on average within 5% of the correct rate for those students on their last practice attempt. This study is conducted with data from introductory undergraduate Computer Science and Mechanical Engineering courses.","New York, NY, USA",34,"Chen, Binglin and West, Matthew and Zilles, Craig",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333647,9.78145E+12,,"Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Predicting the Difficulty of Automatic Item Generators on Exams from Their Difficulty on Homeworks,https://doi.org/10.1145/3330430.3333647,2019
inproceedings,10.1145/3330430.3333648,"To improve designs of e-learning materials, it is necessary to know which word or figure a learner felt ""difficult"" in the materials. In this pilot study, we measured electroencephalography (EEG) and eye gaze data of learners and analyzed to estimate which area they had difficulty to learn. The developed system realized simultaneous measurements of physiological data and subjective evaluations during learning. Using this system, we observed specific EEG activity in difficult pages. Integrating of eye gaze and EEG measurements raised a possibility to determine where a learner felt ""difficult"" in a page of learning materials. From these results, we could suggest that the multimodal measurements of EEG and eye gaze would lead to effective improvement of learning materials. For future study, more data collection using various materials and learners with different backgrounds is necessary. This study could lead to establishing a method to improve e-learning materials based on learners' mental states.","New York, NY, USA",35,"Tamura, Kaori and Okamoto, Tsuyoshi and Oi, Misato and Shimada, Atsushi and Hatano, Kohei and Yamada, Masanori and Lu, Min and Konomi, Shin'ichi",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333648,9.78145E+12,"EEG, Learning materials, eye tracking, Multimodal sensing","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,"Pilot Study to Estimate ""Difficult"" Area in e-Learning Material by Physiological Measurements",https://doi.org/10.1145/3330430.3333648,2019
inproceedings,10.1145/3330430.3333649,"Relatedness between user input and an ideal response is a salient feature required for proper functioning of an Intelligent Tutoring System (ITS) using natural language processing. Improper assessment of text input causes maladaptation in ITSs. Meta-assessment of user responses in ITSs can improve instruction efficacy and user satisfaction. Therefore, this paper evaluates the quality of semantic matching between user input and the expected response in AutoTutor, an ITS which holds a conversation with the user in natural language. AutoTutor's dialogue is driven by the AutoTutor Conversation Engine (ACE), which uses a combination of Latent Semantic Analysis (LSA) and Regular Expressions (RegEx) to assess user input. We assessed ACE via responses from 219 Amazon Mechanical Turk users, who answered 118 electronics questions broken into 5202 response pairings (n = 5202). These analyses explore the relationship between RegEx and LSA, agreement between the two judges, and agreement between human judges and ACE. Additionally, we calculated precision and recall. As expected, regular expressions and LSA had a moderate, positive relationship, and the agreement between ACE and human was fair, but slightly lower than agreement between human.","New York, NY, USA",36,"Carmon, Colin M. and Hampton, Andrew J. and Morgan, Brent and Cai, Zhiqiang and Wang, Lijia and Graesser, Arthur C.",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333649,9.78145E+12,"AutoTutor, intelligent tutoring systems, computational linguistics, meta-assessment","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Semantic Matching Evaluation of User Responses to Electronics Questions in AutoTutor,https://doi.org/10.1145/3330430.3333649,2019
inproceedings,10.1145/3330430.3333650,"Extended learning support systems for all-age education requires inclusive user interface design, especially for elderly users. A dual-tablet user interface with simplified visual layers and more intuitive operations was proposed aiming to reduce the physical and mental loads of elderly learners. An initial prototype with basic functions of viewing learning material was developed based on a cross-platform framework. Two preliminary user experiments participated by elderly volunteers were carried out for formative evaluations, in order to improve the usability of the interface design iteratively. The prototype was modified based on the participants' comments and observation of their operations during the experiments. Additional findings of the elderly users' preference and tendency were discussed for further development.","New York, NY, USA",37,"Lu, Min and Tamura, Kaori and Okamoto, Tsuyoshi and Oi, Misato and Shimada, Atsushi and Hatano, Kohei and Yamada, Masanori and Konomi, Shin'ichi",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333650,9.78145E+12,"all-age learning, inclusive design, older adults, Learning support system, e-learning, user interface","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Proposal and Implementation of an Elderly-Oriented User Interface for Learning Support Systems,https://doi.org/10.1145/3330430.3333650,2019
inproceedings,10.1145/3330430.3333651,"To address the goal of increasing and broadening participation of youth in STEM fields, a learning ecosystem approach is a promising strategy. Learning analytics can play an important role in such efforts which aim to build learning supports across the diverse spaces in which learning and development occurs, including informal, formal, and online contexts. This paper introduces a city-level learning analytics implementation effort in a developing STEM ecosystem in one mid-sized city. We describe aspects of our design and research approach and challenges that emerge by taking a learning ecosystem perspective of learning and development.","New York, NY, USA",38,"Nacu, Denise and Upadhyay, Pooja and Skorepa, Evan and Everette, Tre and Flores, Evelyn and Jackson, Mighel and Pinkard, Nichole",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333651,9.78145E+12,"human-centered design, learning ecosystems, STEM learning, learning analytics, broadening participation","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Implementing Learning Analytics to Foster a STEM Learning Ecosystem at the City-Level: Emerging Research and Design Challenges,https://doi.org/10.1145/3330430.3333651,2019
inproceedings,10.1145/3330430.3333652,"MOOCs (Massive Open Online Courses) frequently use grades to calculate whether a student passes the course. To better understand how student behavior is influenced by grade feedback, we conduct a study on the changes of certified students' behavior before and after they have received their grade. We use observational student data from two MITx MOOCs to examine student behavior before and after a grade is released and calculate the difference (the delta-activity). We then analyze the changes in the delta-activity distributions across all graded assignments a we observe that the variation in delta-activity decreases as grade decreases, with students who have the lowest grade exhibiting little or no change in weekly activity. This trend persists throughout each course, in all course offerings, suggesting that a change in grade does not correlate with a change in the behavior of certified MOOC students.","New York, NY, USA",39,"Wang, Li and Hemberg, Erik and O'Reilly, Una-May",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333652,9.78145E+12,"MOOCs, Feedback, Statistics, Data Analysis","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,On the Influence of Grades on Learning Behavior of Students in MOOCs,https://doi.org/10.1145/3330430.3333652,2019
inproceedings,10.1145/3330430.3333653,"Online classes and degree programs continue to grow in popularity, in part due to the increased convenience and accessibility of education that technology has provided in recent years. As online education scales upwards and outwards, there is an increased need to provide students with an engaging and collaborative learning experience. In some online learning environments, student collaboration is perceived to be more difficult than it is in a physical classroom setting due to cultural or geographic distance between students. In particular, online class lectures often lack the collaborative spirit seen in most in-person classroom lectures. To improve upon the online classroom experience, this project first examines the benefits and drawbacks of several in-person and online lecture delivery techniques, then proposes an online lecture platform that allows students to facilitate their own collaborative classrooms on-demand through a semi-synchronous viewing area and chatroom.","New York, NY, USA",40,"Kutnick, Denise G. and Joyner, David A.",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333653,9.78145E+12,"Collaborative Learning, Engagement, Online Degrees, Distance, Education, Social Learning","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Synchronous at Scale: Investigation and Implementation of a Semi-Synchronous Online Lecture Platform,https://doi.org/10.1145/3330430.3333653,2019
inproceedings,10.1145/3330430.3333654,"The relationship between pricing and learning behavior is an increasingly important topic in MOOC (massive open online course) research. We report on two case studies where cohorts of learners were offered coupons for free-certificates to explore price reductions might influence user behavior in MOOC-based online learning settings. In Case Study #1, we compare participation and certification rates between courses with and without coupons for free-certificates. In the courses with a free-certificate track, participants signed up for the verified certificate track at higher rates and completion rates among verified students were higher than in the paid-certificate track courses. In Case Study #2, we compare the behaviors of learners within the same courses based on whether they received access to a free-certificate track. Access to free-certificates was associated with somewhat lower certification rates, but overall certification rates remained high particularly among those who viewed the courses. These findings suggests that some other incentives, other than simply the sunk-cost of paying for a verified certificate-track, may motivate learners to complete MOOC courses.","New York, NY, USA",41,"Littenberg-Tobias, Joshua and Ruip\'{e}rez-Valiente, Jos\'{e} A. and Reich, Justin",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333654,9.78145E+12,"Distance Learning, Free Coupons, Price Elasticity, SPOCs, MOOCs, Learning Analytics","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Impact of Free-Certificate Coupons on Learner Behavior in Online Courses: Results from Two Case Studies,https://doi.org/10.1145/3330430.3333654,2019
inproceedings,10.1145/3330430.3333655,"Test-yourself questions are effective examples of formative assessment, and have been shown to promote learners' active interaction with materials and knowledge mastery through frequent practice. However, the cost of developing and implementing engaging test-yourself activities can be problematic in large-scale web-based learning environments; a lack of built-in scaffolding to guide learners is also a challenge. We introduce Guided-KNOWLA, an improvement of KNOWLA -- a learning tool has learners assemble a given set of mixed-size scrambled fragments into a logical order using a web-based interface, accompanied by motivational step-by-step hint/guidance as enhancements. We conducted an exploratory study with graduate learners to examine their attitudes toward Guided-KNOWLA activities, measured by perceived usefulness and comparative formats for formative assessment. Preliminary results suggest that using the Guided-KNOWLA were useful in helping learners master online materials and were a preferred format of ""test-yourself"" practice to multiple-choice questions.","New York, NY, USA",42,"Braude, Eric and Liu, Ye",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333655,9.78145E+12,"Web-based learning, formative assessment, scaffolding, test-yourself practice, MOOC, Active Learning","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Guided-KNOWLA: The Use of Guided Unscrambling to Enhance Active Online Learning,https://doi.org/10.1145/3330430.3333655,2019
inproceedings,10.1145/3330430.3333657,"Formative feedback has long been recognized as a crucial scaffold for student learning. Due to the job demand of instructors, it is impossible for them to provide individual students with on-demand formative feedback based on individual students' performance. There is a growing interest in developing better approaches to provide students with automated formative feedback to assist their learning. In this research, we design and develop an automated formative feedback system to support student learning of conceptual knowledge in the course of writing assignments. In the proposed system, formative feedback can be generated automatically with the help of concept maps constructed from instructors' lecture slides and students' writing assignments. In this paper, we present the automatic approach to generate formative feedback, discuss the system architecture, and illustrate a prototype of the proposed system.","New York, NY, USA",43,"Xiong, Ye and Wu, Yi-Fang Brook",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333657,9.78145E+12,"Writing-to-Learn, Assessment, Automatic Feedback","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,An Automated Feedback System to Support Student Learning in Writing-to-Learn Activities,https://doi.org/10.1145/3330430.3333657,2019
inproceedings,10.1145/3330430.3333658,"When online learners have questions that are related to a specific task, they often use Q&amp;A boards instead of web search because they are looking for context-specific answers. While lecturers, teaching assistants, and other learners can provide context-specific answers on the Q&amp;A boards, there is often a high response latency which can impede their learning. We present automaTA, a prototype that suggests context-specific answers to online learners' questions by capturing the context of the questions. Our solution is to automate the response generation with a human-machine mixed approach, where humans generate high-quality answers, and the human-generated responses are used to train an automated algorithm to provide context-specific answers. automaTA adopts this approach as a prototype in which it generates automated answers for function-related questions in an online programming course. We conduct two user studies with undergraduate and graduate students with little or no experience with Python and found the potential that automaTA can automatically provide answers to context-specific questions without a human instructor, at scale.","New York, NY, USA",44,"Lee, Changyoon and Han, Donghoon and Jin, Hyoungwook and Oh, Alice",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333658,9.78145E+12,"human-machine interaction, programming learning, question answering, Context-specific learning","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,AutomaTA: Human-Machine Interaction for Answering Context-Specific Questions,https://doi.org/10.1145/3330430.3333658,2019
inproceedings,10.1145/3330430.3333659,"Algorithms, drawn from Artificial Intelligence (AI) technologies, are increasingly being used in distance education. However, currently little is known about the attitudes of distance education students to the benefits and risks associated with AI. For example, is AI broadly welcomed by distance education students, thought to be irrelevant, or disliked? Here, we present the initial findings of a survey of students from the UK's largest distance university as a first step towards addressing the question ""What do students at distance universities think about AI?"" Responses from the 222 contributors suggest that these students do expect AI to be beneficial for their future learning, with more respondents selecting potential benefits than selecting risks. Nonetheless, it is important to extend this exploratory study to students in other universities worldwide, and to other stakeholders.","New York, NY, USA",45,"Holmes, Wayne and Anastopoulou, Stamatina",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333659,9.78145E+12,"student attitudes, Artificial Intelligence, Algorithms, survey, distance education","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,What Do Students at Distance Universities Think about AI?,https://doi.org/10.1145/3330430.3333659,2019
inproceedings,10.1145/3330430.3333660,"Peer advising in education, which involves students providing fellow students with course advice, can be important in online student communities and can provide insights into potential course improvements. We examine reviews from a course review web site for online graduate programs. We develop a coding scheme to analyze the free text portion of the reviews and integrate those findings with students' quantitative ratings of each course's overall score, difficulty, and workload. While reviews focus on subjective evaluation of courses, students also provide feedback for instructors, personal context, advice for other students, and objective course descriptions. Additionally, the average review varies by course overall score, difficulty, and workload. Our research examines the importance of student communities in online education and peer advising at scale.","New York, NY, USA",46,"Duncan, Alex and Joyner, David",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333660,9.78145E+12,"CS education, online communities, graduate education, Peer advising","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Peer Advising at Scale: Content and Context of a Learner-Owned Course Evaluation System,https://doi.org/10.1145/3330430.3333660,2019
inproceedings,10.1145/3330430.3333661,"Going beyond mere forum posts categorization is key to understand why some students struggle and eventually fail in MOOCs. We propose here an extension of a coding scheme and present the design of the associated automatic annotation tools to tag students' questions in their forum posts. Working of four sessions of the same MOOC, we cluster students' questions and show how the obtained clusters are consistent across all sessions and can be sometimes correlated with students' success in the MOOC. Moreover, it helps us better understand the nature of questions asked by successful vs. unsuccessful students.","New York, NY, USA",47,"Harrak, Fatima and Luengo, Vanda and Bouchet, Fran\c{c}ois and Bachelet, R\'{e}mi",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333661,9.78145E+12,"MOOC, discussion forum, student's performance, clustering, coding scheme, Student's question","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Towards Improving Students' Forum Posts Categorization in MOOCs and Impact on Performance Prediction,https://doi.org/10.1145/3330430.3333661,2019
inproceedings,10.1145/3330430.3333662,"We introduce PARQR, a tool for online education forums that reduces duplicate posts by 40% in a degree seeking online masters program at a top university. Instead of performing a standard keyword search, PARQR monitors questions as students compose them and continuously suggests relevant posts. In testing, PARQR correctly recommends a relevant post, if one exists, 73.5% of the time. We discuss PARQR's design, initial experimental results comparing different semesters with and without PARQR, and interviews we conducted with teaching instructors regarding their experience with PARQR.","New York, NY, USA",48,"Bilgrien, Noah and Finkelberg, Roy and Tailor, Chirag and Irish, India and Murali, Girish and Mangal, Abhishek and Gustafsson, Niklas and Raman, Sumedha and Starner, Thad and Arriaga, Rosa",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333662,9.78145E+12,"Online Forums, Computer-Assisted Instruction, Recommender Systems, Distance Learning, Online Degrees","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,PARQR: Augmenting the Piazza Online Forum to Better Support Degree Seeking Online Masters Students,https://doi.org/10.1145/3330430.3333662,2019
inproceedings,10.1145/3330430.3333663,"Higher educational institutions constantly look for ways to meet students' needs and support them through graduation. However, even though institutions provide degree program curriculums and prerequisite courses to guide students, these often fail to capture some of the underlying skills and knowledge imparted by courses that may be necessary for a student.In our approach, we use methods of Causal Inference to study the relationships between courses using historical student performance data. Specifically, two methods were employed to obtain the Average Treatment Effect (ATE): matching methods and regression. The results from this study so far, show that we can make causal inferences from our data and that the methodology may be used to identify courses with a strong causal relationship - which can then be used to modify course curriculums and degree programs.","New York, NY, USA",49,"Kaur, Prableen and Polyzou, Agoritsa and Karypis, George",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333663,9.78145E+12,"Average Treatment Effect, Matching, Causal Inference, Learning Analytics","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Causal Inference in Higher Education: Building Better Curriculums,https://doi.org/10.1145/3330430.3333663,2019
inproceedings,10.1145/3330430.3333664,"We investigate learner efficiency by categorizing a computational MOOC and analyzing user behavior data from a learning design point of view. Learning design is important both when designing courses as well as studying them. Learning behavior can be observed from the MOOC platform data. For this study we ask two learning designer experts to categorize a course on MITx: ""6.00.1x Introduction to Computer Science and Programming Using Python"". We use these categorizations to investigate relationships with learning behavior by analyzing the MOOC platform data. Our study verifies that learning design can be correlated to learning behavior, e.g. students exhibit a pattern of behavior associated to a component's difficulty and category.","New York, NY, USA",50,"Biswas, Sagar and Law, Nancy and Hemberg, Erik and OReilly, Una-May",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333664,9.78145E+12,"Cognitive Demand, Pedagogy, Learning Design, Knowledge imparted, Learning Behaviour","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Investigating Learning Design Categorization and Learning Behaviour in Computational MOOCS,https://doi.org/10.1145/3330430.3333664,2019
inproceedings,10.1145/3330430.3333665,"We present LiveDataLab, a novel general cloud-based platform that facilitates data science education at scale by enabling instructors to offer hands-on data science assignments using large real-world datasets. Using real course assignments as examples, our demonstration will walk attendees through the process of an instructor deploying an assignment, students working on and submitting assignments, and leaderboard-based competition and automated grading to demonstrate the major functions and benefits of LiveDataLab.","New York, NY, USA",51,"Green, Aaron and Zhai, ChengXiang",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333665,9.78145E+12,"virtual lab, data science education, cloud computing","Chicago, IL, USA",2,,Association for Computing Machinery,L@S '19,LiveDataLab: A Cloud-Based Platform to Facilitate Hands-on Data Science Education at Scale,https://doi.org/10.1145/3330430.3333665,2019
inproceedings,10.1145/3330430.3333666,"Cheating has always been a problem for academic institutions, but the internet has increased access to a form of academic dishonesty known as contract cheating, or ""homework for hire."" When students purchase work online and submit it as their own, it cannot be detected by commonly-used plagiarism detection tools, and this troubling form of cheating seems to be increasing.We present an approach to addressing contract cheating: an AI agent that poses as a contractor to identify students attempting to purchase homework solutions. Our agent, Jack Watson, monitors auction sites, identifies posted homework assignments, and provides students with watermarked solutions that can be automatically identified upon submission of the assignment.Our work is ongoing, but we have proved the model, identifying nine cases of contract cheating through our techniques. We are continuing to improve Jack Watson and further automate the monitoring and identification of contract cheating on online marketplaces.","New York, NY, USA",52,"Graziano, Rocko and Benton, David and Wahal, Sarthak and Xue, Qiuyue and Miller, P. Tim and Larsen, Nick and Vacanti, Diego and Miller, Pepper and Mahajan, Khushhall Chandra and Srikanth, Deepak and Starner, Thad",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333666,9.78145E+12,"contract cheating, academic integrity, Plagiarism","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Jack Watson: Addressing Contract Cheating at Scale in Online Computer Science Education,https://doi.org/10.1145/3330430.3333666,2019
inproceedings,10.1145/3330430.3333667,"With the rise of technology advancements we witness every day in our contemporary life in general, and in the education field in specific, new ways of learning are emerging, such as Massive Open Online Courses (MOOCs). MOOCs have grown rapidly for the past few years, yet meeting the needs of massive and diverse learners and keeping them motivated to learn is still a challenge. To address this concern, we have developed an intervention to meet students' learning needs and keep them motivated to learn according to their capabilities. In this paper, we will discuss the intervention and report on the preliminary results drawing on the quantitative and qualitative data of the course survey to interpret learners experiences using this approach.","New York, NY, USA",53,"Haniya, Samaa",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333667,9.78145E+12,"e-Learning Ecologies, MOOCs, Learning at Scale, Participation","Chicago, IL, USA",3,,Association for Computing Machinery,L@S '19,Developing an Intervention to Advance Learning At Scale,https://doi.org/10.1145/3330430.3333667,2019
inproceedings,10.1145/3330430.3333668,"Lecture slides covering many topics are becoming increasingly available online, but they are scattered, making it a challenge for anyone to instantly access all slides relevant to a learning context. To address this challenge, we propose to create links between those scattered slides to form a Web of Slides (WOS). Using the sequential nature of slides, we present preliminary results of studying how to automatically create a basic link based on similarity of slides as an initial step toward the vision of WOS. We also explore interesting future research directions using different link types and the unique features of slides.","New York, NY, USA",54,"Labhishetty, Sahiti and Bhavya and Pei, Kevin and Boughoula, Assma and Zhai, Chengxiang",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333668,9.78145E+12,"MOOC, Slides, Link probabilities","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Web of Slides: Automatic Linking of Lecture Slides to Facilitate Navigation,https://doi.org/10.1145/3330430.3333668,2019
inproceedings,10.1145/3330430.3333669,"We will demonstrate a prototype system WOSView built based on the vision of the Web of Slides(WOS), which aims to link all the lectures slides so as to facilitate navigation over all the slides. The links can be created at the slide level or at the level of phrases inside a slide, and many types of links can be created. The prototype system we built implements the most basic type of links, which link slides that have similar content and integrates lectures from four different MOOCs. WOSView also supports keyword search, which generates virtual links dynamically. We will demonstrate how the graphical interface of the WOSView enables students to flexibly navigate into slides from different courses and explore related slides using both static and dynamic links and solicit feedback from the community about the vision of WOS.","New York, NY, USA",55,"Labhishetty, Sahiti and Bhavya and Pei, Kevin and Boughoula, Assma and Zhai, Chengxiang",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333669,9.78145E+12,"MOOC, Slides, Link probabilities","Chicago, IL, USA",3,,Association for Computing Machinery,L@S '19,WOSView Demo: A Tool to Explore the Web of Slides,https://doi.org/10.1145/3330430.3333669,2019
inproceedings,10.1145/3330430.3333670,"This demo paper introduces a tool and a method to provide a barriers-free, rich, interactive learning experience for students of all levels of preparation in programming courses. Taskgrader is an open-source autograding tool providing instant feedback in large-scale online programming classes. This in-browser tool offers extensive feedback to student code submissions right within any LMS and pass data back to the gradebook.","New York, NY, USA",56,"Sharrock, R\'{e}mi and Bonfert-Taylor, Petra and Hiron, Mathias and Blockelet, Michel and Miller, Chris and Goudzwaard, Mike and Hamonic, Ella",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333670,9.78145E+12,"large-scale learning environments, Automated grading tools, Automated feedback tools","Chicago, IL, USA",2,,Association for Computing Machinery,L@S '19,Teaching C Programming Interactively at Scale Using Taskgrader: An Open-Source Autograder Tool,https://doi.org/10.1145/3330430.3333670,2019
inproceedings,10.1145/3330430.3333671,"To help language learners achieve fluency, instructors often focus on teaching formulaic sequences (FS)--phrases such as idioms or phrasal verbs that are processed, stored, and retrieved holistically. Teaching FS effectively is challenging as it heavily involves instructors' intuition, prior knowledge, and manual efforts to identify a set of FSs with high utility. In this paper, we present FSIST, a tool that supports instructors for video-based instruction of FS. The core idea of FSIST is to utilize videos at scale to build a list of FSs along with videos that include example usages. To evaluate how FSIST can effectively support instructors, we conducted a user study with three English instructors. Results show that the browsing interactions provided in FSIST support instructors to efficiently find parts of videos that show example usages of FSs.-","New York, NY, USA",57,"Jo, Kyung Je and Yun, Hyeonggeun and Kim, Juho",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333671,9.78145E+12,"video learning, Formulaic sequence, language learning","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Supporting Instruction of Formulaic Sequences Using Videos at Scale,https://doi.org/10.1145/3330430.3333671,2019
inproceedings,10.1145/3330430.3333672,"Twice a year the National University of Singapore hosts computer programming events open to the nation's secondary, junior college, polytechnic and technical education students. To qualify for the live events, participants complete online programming activities during a month-long qualification phase open to all non-university students over the age of 12. The activities include game-based learning and traditional coding problems.During the past year, more than 1700 students participated in the two qualification phases and more than 200 students participated in the live events. At these events, students pair-program to test their programming abilities and showcase their coded creations in a tournament format.In the accompanying poster, we describe our work to build a community of intrinsically motivated learners and develop the technical infrastructure to support them both at scale during the qualification phase and live events. We conclude by detailing our plans for leveraging the community as a site for research on learning going forward.","New York, NY, USA",58,"Hartman, Kevin and Ng, Shun Geng and Lakshminarasimhan, Aishwarya and Ramasamy, Thangamani and Farahani, Melika and Boesch, Chris",Proceedings of the Sixth (2019) ACM Conference on Learning @ Scale,10.1145/3330430.3333672,9.78145E+12,"Community of practice, informal learning, computer-supported collaborative learning","Chicago, IL, USA",4,,Association for Computing Machinery,L@S '19,Achievements for Building a Learning Community,https://doi.org/10.1145/3330430.3333672,2019
inproceedings,10.1145/3231644.3231656,"We present a case study in predictive model replication for student dropout in Massive Open Online Courses (MOOCs) using a large and diverse dataset (133 sessions of 28 unique courses offered by two institutions). This experiment was run on the MOOC Replication Framework (MORF), which makes it feasible to fully replicate complex machine learned models, from raw data to model evaluation. We provide an overview of the MORF platform architecture and functionality, and demonstrate its use through a case study. In this replication of [41], we contextualize and evaluate the results of the previous work using statistical tests and a more effective model evaluation scheme. We find that only some of the original findings replicate across this larger and more diverse sample of MOOCs, with others replicating significantly in the opposite direction. Our analysis also reveals results which are highly relevant to the prediction task which were not reported in the original experiment. This work demonstrates the importance of replication of predictive modeling research in MOOCs using large and diverse datasets, illuminates the challenges of doing so, and describes our freely available, open-source software framework to overcome barriers to replication.","New York, NY, USA",1,"Gardner, Josh and Brooks, Christopher and Andres, Juan Miguel and Baker, Ryan",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231656,9.78145E+12,,"London, United Kingdom",10,,Association for Computing Machinery,L@S '18,Replicating MOOC Predictive Models at Scale,https://doi.org/10.1145/3231644.3231656,2018
inproceedings,10.1145/3231644.3231662,"We survey all four years of papers published so far at the Learning at Scale conference in order to reflect on the major research areas that have been investigated and to chart possible directions for future study. We classified all 69 full papers so far into three categories: Systems for Learning at Scale, Interactions with Sociotechnical Systems, and Understanding Online Students. Systems papers presented technologies that varied by how much they amplify human effort (e.g., one-to-one, one-to-many, many-to-many). Interaction papers studied both individual and group interactions with learning technologies. Finally, student-centric study papers focused on modeling knowledge and on promoting global access and equity. We conclude by charting future research directions related to topics such as going beyond the MOOC hype cycle, axes of scale for systems, more immersive course experiences, learning on mobile devices, diversity in student personas, students as co-creators, and fostering better social connections amongst students.","New York, NY, USA",2,"Kross, Sean and Guo, Philip J.",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231662,9.78145E+12,"meta-analysis, survey paper, context/synthesis paper","London, United Kingdom",10,,Association for Computing Machinery,L@S '18,"Students, Systems, and Interactions: Synthesizing the First Four Years of Learning@scale and Charting the Future",https://doi.org/10.1145/3231644.3231662,2018
inproceedings,10.1145/3231644.3231666,"The global reach of online experiments and their wide adoption in fields ranging from political science to computer science poses an underexplored opportunity for learning at scale: the possibility of participants learning about the research to which they contribute data. We conducted three experiments on Amazon's Mechanical Turk to evaluate whether participants of paid online experiments are interested in learning about research, what information they find most interesting, and whether providing them with such information actually leads to learning gains. Our findings show that 40% of our participants on Mechanical Turk actively sought out post-experiment learning opportunities despite having already received their financial compensation. Participants expressed high interest in a range of research topics, including previous research and experimental design. Finally, we find that participants comprehend and accurately recall facts from post-experiment learning opportunities. Our findings suggest that Mechanical Turk can be a valuable platform for learning at scale and scientific outreach.","New York, NY, USA",3,"Jun, Eunice and Arian, Morelle and Reinecke, Katharina",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231666,9.78145E+12,"learning, online experimentation, scientific outreach","London, United Kingdom",10,,Association for Computing Machinery,L@S '18,The Potential for Scientific Outreach and Learning in Mechanical Turk Experiments,https://doi.org/10.1145/3231644.3231666,2018
inproceedings,10.1145/3231644.3231663,"This paper applies theory and methodology from the learning design literature to large-scale learning environments through quantitative modeling of the structure and design of Massive Open Online Courses. For two institutions of higher education, we automate the task of encoding pedagogy and learning design principles for 177 courses (which accounted for for nearly 4 million enrollments). Course materials from these MOOCs are parsed and abstracted into sequences of components, such as videos and problems. Our key contributions are (i) describing the parsing and abstraction of courses for quantitative analyses, (ii) the automated categorization of similar course designs, and (iii) the identification of key structural components that show relationships between categories and learning design principles. We employ two methods to categorize similar course designs---one aimed at clustering courses using transition probabilities and another using trajectory mining. We then proceed with an exploratory analysis of relationships between our categorization and learning outcomes.","New York, NY, USA",4,"Davis, Dan and Seaton, Daniel and Hauff, Claudia and Houben, Geert-Jan",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231663,9.78145E+12,,"London, United Kingdom",10,,Association for Computing Machinery,L@S '18,Toward Large-Scale Learning Design: Categorizing Course Designs in Service of Supporting Learning Outcomes,https://doi.org/10.1145/3231644.3231663,2018
inproceedings,10.1145/3231644.3231647,"Knowledge tracing is one of the key research areas for empowering personalized education. It is a task to model students' mastery level of a knowledge component (KC) based on their historical learning trajectories. In recent years, a recurrent neural network model called deep knowledge tracing (DKT) has been proposed to handle the knowledge tracing task and literature has shown that DKT generally outperforms traditional methods. However, through our extensive experimentation, we have noticed two major problems in the DKT model. The first problem is that the model fails to reconstruct the observed input. As a result, even when a student performs well on a KC, the prediction of that KC's mastery level decreases instead, and vice versa. Second, the predicted performance for KCs across time-steps is not consistent. This is undesirable and unreasonable because student's performance is expected to transit gradually over time. To address these problems, we introduce regularization terms that correspond to reconstruction and waviness to the loss function of the original DKT model to enhance the consistency in prediction. Experiments show that the regularized loss function effectively alleviates the two problems without degrading the original task of DKT.1","New York, NY, USA",5,"Yeung, Chun-Kit and Yeung, Dit-Yan",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231647,9.78145E+12,"educational data mining, deep learning, knowledge tracing, personalized learning, regularization, sequence modeling","London, United Kingdom",10,,Association for Computing Machinery,L@S '18,Addressing Two Problems in Deep Knowledge Tracing via Prediction-Consistent Regularization,https://doi.org/10.1145/3231644.3231647,2018
inproceedings,10.1145/3231644.3231651,"We report an experimental implementation of adaptive learning functionality in a self-paced Microsoft MOOC (massive open online course) on edX. In a personalized adaptive system, the learner's progress toward clearly defined goals is continually assessed, the assessment occurs when a student is ready to demonstrate competency, and supporting materials are tailored to the needs of each learner. Despite the promise of adaptive personalized learning, there is a lack of evidence-based instructional design, transparency in many of the models and algorithms used to provide adaptive technology or a framework for rapid experimentation with different models. ALOSI (Adaptive Learning Open Source Initiative) provides open source adaptive learning technology and a common framework to measure learning gains and learner behavior. This study explored the effects of two different strategies for adaptive learning and assessment: Learners were randomly assigned to three groups. In the first adaptive group ALOSI prioritized a strategy of remediation - serving learners items on topics with the least evidence of mastery; in the second adaptive group ALOSI prioritized a strategy of continuity - that is learners would be more likely served items on similar topic in a sequence until mastery is demonstrated. The control group followed the pathways of the course as set out by the instructional designer, with no adaptive algorithms. We found that the implemented adaptivity in assessment, with emphasis on remediation is associated with a substantial increase in learning gains, while producing no big effect on the drop-out. Further research is needed to confirm these findings and explore additional possible effects and implications to course design.","New York, NY, USA",6,"Rosen, Yigal and Rushkin, Ilia and Rubin, Rob and Munson, Liberty and Ang, Andrew and Weber, Gregory and Lopez, Glenn and Tingley, Dustin",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231651,9.78145E+12,"MOOC, adaptivity, personalization, edX, assessment","London, United Kingdom",8,,Association for Computing Machinery,L@S '18,The Effects of Adaptive Learning in a Massive Open Online Course on Learners' Skill Development,https://doi.org/10.1145/3231644.3231651,2018
inproceedings,10.1145/3231644.3231654,"The ever growing amount of educational content renders it increasingly difficult to manually generate sufficient practice or quiz questions to accompany it. This paper introduces QG-Net, a recurrent neural network-based model specifically designed for automatically generating quiz questions from educational content such as textbooks. QG-Net, when trained on a publicly available, general-purpose question/answer dataset and without further fine-tuning, is capable of generating high quality questions from textbooks, where the content is significantly different from the training data. Indeed, QG-Net outperforms state-of-the-art neural network-based and rules-based systems for question generation, both when evaluated using standard benchmark datasets and when using human evaluators. QG-Net also scales favorably to applications with large amounts of educational content, since its performance improves with the amount of training data.","New York, NY, USA",7,"Wang, Zichao and Lan, Andrew S. and Nie, Weili and Waters, Andrew E. and Grimaldi, Phillip J. and Baraniuk, Richard G.",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231654,9.78145E+12,,"London, United Kingdom",10,,Association for Computing Machinery,L@S '18,QG-Net: A Data-Driven Question Generation Model for Educational Content,https://doi.org/10.1145/3231644.3231654,2018
inproceedings,10.1145/3231644.3231655,"Support of discussion based learning at scale benefits from automated analysis of discussion for enabling effective assignment of students to project teams, for triggering dynamic support of group learning processes, and for assessment of those learning processes. A major limitation of much past work in machine learning applied to automated analysis of discussion is the failure of the models to generalize to data outside of the parameters of the context in which the training data was collected. This limitation means that a separate training effort must be undertaken for each domain in which the models will be used. This paper focuses on a specific construct of discussion based learning referred to as Transactivity and provides a novel machine learning approach with performance that exceeds state-of-the-art performance within the same domain in which it was trained and a new domain, and does not suffer any reduction in performance when transferring to the new domain. These results stand as an advance over past work on automated detection of Transactivity and increase the value of trained models for supporting group learning at scale. Implications for practice in at-scale learning environments are discussed.","New York, NY, USA",8,"Fiacco, James and Ros\'{e}, Carolyn",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231655,9.78145E+12,"multitask learning, deep learning, limited dataset size, attention model, transfer learning, transactivity, natural language inference, entailment, neural network","London, United Kingdom",11,,Association for Computing Machinery,L@S '18,Towards Domain General Detection of Transactive Knowledge Building Behavior,https://doi.org/10.1145/3231644.3231655,2018
inproceedings,10.1145/3231644.3231646,"People's lived experiences provide intuitions about health. Can they transform these personal intuitions into testable hypotheses that could inform both science and their lives? This paper introduces an online learning architecture and provides system principles for people to brainstorm causal scientific theories. We describe the Learn-Train-Ask workflow that guides participants through learning domain-specific content, process training to frame their intuitions as hypotheses, and collaborating with anonymous peers to brainstorm related questions. 344 voluntary online participants from 27 countries created 399 personally-relevant questions about the human microbiome over 4 months, 75 (19%) of which microbiome experts found potentially scientifically novel. Participants with access to process training generated hypotheses of better quality. Access to learning materials improved the questions' microbiome-specific knowledge. These results highlight the promise of performing personally-meaningful scientific work using massive online learning systems.","New York, NY, USA",9,"Pandey, Vineet and Debelius, Justine and Hyde, Embriette R. and Kosciolek, Tomasz and Knight, Rob and Klemmer, Scott",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231646,9.78145E+12,"online learning, citizen science, social computing systems","London, United Kingdom",10,,Association for Computing Machinery,L@S '18,Docent: Transforming Personal Intuitions to Scientific Hypotheses through Content Learning and Process Training,https://doi.org/10.1145/3231644.3231646,2018
inproceedings,10.1145/3231644.3231653,"Prior research has examined the use of Social Question and Answer (Q&amp;A) websites for answer and help seeking. However, the potential for these websites to support domain learning has not yet been realized. Helping users write effective answers can be beneficial for subject area learning for both answerers and the recipients of answers. In this study, we examine the utility of crowdsourced, criteria-based feedback for answerers on a student-centered Q&amp;A website, Brainly.com. In an experiment with 55 users, we compared perceptions of the current rating system against two feedback designs with explicit criteria (Appropriate, Understandable, and Generalizable). Contrary to our hypotheses, answerers disagreed with and rejected the criteria-based feedback. Although the criteria aligned with answerers' goals, and crowdsourced ratings were found to be objectively accurate, the norms and expectations for answers on Brainly conflicted with our design. We conclude with implications for the design of feedback in social Q&amp;A.","New York, NY, USA",10,"Frens, John and Walker, Erin and Hsieh, Gary",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231653,9.78145E+12,"crowd assessment, feedback, peer help, informal learning","London, United Kingdom",10,,Association for Computing Machinery,L@S '18,Supporting Answerers with Feedback in Social Q&amp;A,https://doi.org/10.1145/3231644.3231653,2018
inproceedings,10.1145/3231644.3231658,"Massive open online courses (MOOCs) continue to see increasing enrollment and adoption by universities, although they are still not fully understood and could perhaps be significantly improved. For example, little is known about the relationships between the ways in which students choose to use MOOCs (e.g., sampling lecture videos, discussing topics with fellow students) and their overall level of engagement with the course, although these relationships are likely key to effective course implementation. In this paper we propose a multilevel definition of student engagement with MOOCs and explore the connections between engagement and students' behaviors across five unique courses. We modeled engagement using ordinal penalized logistic regression with the least absolute shrinkage and selection operator (LASSO), and found several predictors of engagement that were consistent across courses. In particular, we found that discussion activities (e.g., viewing forum posts) were positively related to engagement, whereas other types of student behaviors (e.g., attempting quizzes) were consistently related to less engagement with the course. Finally, we discuss implications of unexpected findings that replicated across courses, future work to explore these implications, and relevance of our findings for MOOC course design.","New York, NY, USA",11,"Crues, R. Wes and Bosch, Nigel and Perry, Michelle and Angrave, Lawrence and Shaik, Najmuddin and Bhat, Suma",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231658,9.78145E+12,"course persistence, engagement patterns, MOOCs","London, United Kingdom",10,,Association for Computing Machinery,L@S '18,Refocusing the Lens on Engagement in MOOCs,https://doi.org/10.1145/3231644.3231658,2018
inproceedings,10.1145/3231644.3231660,"Examining the interaction between content knowledge, inquiry proficiency, and writing proficiency is central to understanding the relative contribution of each proficiency on students' written communication about their science inquiry. Previous studies, however, have only analyzed one of these primary types of knowledge/proficiencies (i.e. content knowledge, inquiry proficiency, and writing proficiency) at a time. This study investigated the extent to which these proficiencies predicted students' written claims, evidence for their claims, and reasoning linking their claims to the evidence. Results showed that all three types of proficiencies significantly predicted students' claims, but only writing proficiency significantly predicted performance on evidence and reasoning statements. These findings indicate the challenges students face when constructing claim, evidence, and reasoning statements, and can inform scaffolding to support these challenges.","New York, NY, USA",12,"Li, Haiying and Gobert, Janice and Dickler, Rachel",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231660,9.78145E+12,"content knowledge, writing proficiency, scalability, science inquiry, scientific explanation","London, United Kingdom",10,,Association for Computing Machinery,L@S '18,"The Relationship between Scientific Explanations and the Proficiencies of Content, Inquiry, and Writing",https://doi.org/10.1145/3231644.3231660,2018
inproceedings,10.1145/3231644.3231670,"Block-based environments are today commonly used for introductory programming activities like those that are part of the Hour of Code campaign, which reaches millions of students. These activities typically consist of a static series of problems. Our aim is to make this type of activities more efficient by incorporating adaptive behavior. In this work, we discuss steps towards this goal, specifically a proposal and implementation of a programming game that supports both elementary problems and interesting programming challenges and thus provides an environment for meaningful adaptation. We also discuss methods of adaptivity and the issue of evaluating student performance while solving a problem.","New York, NY, USA",13,"Effenberger, Tom\'{a}\v{s} and Pel\'{a}nek, Radek",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231670,9.78145E+12,,"London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Towards Making Block-Based Programming Activities Adaptive,https://doi.org/10.1145/3231644.3231670,2018
inproceedings,10.1145/3231644.3231671,"Instruction that adapts to individual learner characteristics is often more effective than instruction that treats all learners as the same. A practical approach to making MOOCs adapt to learners may be by integrating frameworks for intelligent tutoring systems (ITSs). Using the Learning Tools Interoperability standard (LTI), we integrated two intelligent tutoring frameworks (GIFT and CTAT) into edX. We describe our initial explorations of four adaptive instructional patterns in the PennX MOOC ""Big Data and Education."" The work illustrates one route to adaptivity at scale.","New York, NY, USA",14,"Aleven, Vincent and Sewall, Jonathan and Andres, Juan Miguel and Sottilare, Robert and Long, Rodney and Baker, Ryan",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231671,9.78145E+12,"adaptive learning, MOOCs, adaptive instruction, intelligent tutoring systems","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Towards Adapting to Learners at Scale: Integrating MOOC and Intelligent Tutoring Frameworks,https://doi.org/10.1145/3231644.3231671,2018
inproceedings,10.1145/3231644.3231672,"Learning at scale (LAS) systems like Massive Open Online Classes (MOOCs) have hugely expanded access to high quality educational materials however, such material are frequently time and resource expensive to create. In this work we propose a new approach for automatically and adaptively sequencing practice activities for a particular learner and explore its application for foreign language learning. We evaluate our system through simulation and are in the process of running an experiment. Our simulation results suggest that such an approach may be significantly better than an expert system when there is high variability in the rate of learning among the students and if mastering prerequisites before advancing is important, and is likely to be no worse than an expert system if our generated curriculum approximately describes the necessary structure of learning in students.","New York, NY, USA",15,"Mu, Tong and Wang, Shuhan and Andersen, Erik and Brunskill, Emma",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231672,9.78145E+12,"adaptivity, multi-armed bandits, intelligent tutoring systems, language learning, student forgetting, education, curriculum design","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Combining Adaptivity with Progression Ordering for Intelligent Tutoring Systems,https://doi.org/10.1145/3231644.3231672,2018
inproceedings,10.1145/3231644.3231673,"This paper describes ClassDB, a free and open source system to enable large-scale learning of data management. ClassDB is different from existing solutions in that the same system supports a wide range of data-management topics from introductory SQL to advanced ""native analytics"" where code in SQL and non-SQL languages (Python and R) run inside a database management system. Each student/team maintains their own sandbox which instructors can read and provide feedback. Both students and instructors can review activity logs to analyze progress and determine future course of action. ClassDB is currently in its second pilot and is scheduled for a larger trial later this year. After the trials, ClassDB will be made available to about 4,000 students in the university system, which comprises four universities and 12 community colleges. ClassDB is built in collaboration with students employing modern DevOps processes. Its source code and documentation are available in a public GitHub repository. ClassDB is work in progress.","New York, NY, USA",16,"Murthy, Sean and Figueroa, Andrew and Rollo, Steven",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231673,9.78145E+12,"FOSS, scalability, classDB, data management, learning","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Toward a Large-Scale Open Learning System for Data Management,https://doi.org/10.1145/3231644.3231673,2018
inproceedings,10.1145/3231644.3231674,"Over two iterations of a Massive Open Online Course (MOOC) for school leaders, Launching Innovation in Schools, we developed and tested design elements to support the transfer of online learning into offline action. Effective professional learning is job-embedded: learners should employ new skills and knowledge at work. We aimed to get participants to both plan and actually launch new change efforts, and a subset of our most engaged participants were willing to do so during the course. Assessments, instructor calls to action, and exemplars supported student actions. We found that participants led change initiatives, held stakeholder meetings, collected new data about their contexts, and shared and used course materials collaboratively. Collecting data about participant learning and behavior outside the MOOC environment is essential for researchers and designers looking to create effective online environments for professional learning.","New York, NY, USA",17,"Napier, Alyssa and Huttner-Loan, Elizabeth and Reich, Justin",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231674,9.78145E+12,"professional learning, MOOCs, online learning","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,From Online Learning to Offline Action: Using MOOCs for Job-Embedded Teacher Professional Development,https://doi.org/10.1145/3231644.3231674,2018
inproceedings,10.1145/3231644.3231675,"Personalized educational systems adapt their behavior based on student performance. Most student modeling techniques, which are used for guiding the adaptation, utilize only the correctness of student's answers. However, other data about performance are typically available. In this work we focus on response times and wrong answers as these aspects of performance are available in most systems. We analyze data from several types of exercises and domains (mathematics, spelling, grammar). The results suggest that wrong answers are more informative than response times. Based on our results we propose a classification of student performance into several categories.","New York, NY, USA",18,"Pel\'{a}nek, Radek",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231675,9.78145E+12,,"London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Exploring the Utility of Response Times and Wrong Answers for Adaptive Learning,https://doi.org/10.1145/3231644.3231675,2018
inproceedings,10.1145/3231644.3231676,"A personalized learning system needs a large pool of items for learners to solve. When working with a large pool of items, it is useful to measure the similarity of items. We outline a general approach to measuring the similarity of items and discuss specific measures for items used in introductory programming. Evaluation of quality of similarity measures is difficult. To this end, we propose an evaluation approach utilizing three levels of abstraction. We illustrate our approach to measuring similarity and provide evaluation using items from three diverse programming environments.","New York, NY, USA",19,"Pel\'{a}nek, Radek and Effenberger, Tom\'{a}\v{s} and Van\v{e}k, Mat\v{e}j and Sassmann, Vojt\v{e}ch and Gmiterko, Dominik",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231676,9.78145E+12,,"London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Measuring Item Similarity in Introductory Programming,https://doi.org/10.1145/3231644.3231676,2018
inproceedings,10.1145/3231644.3231677,"Living in an information era where various online learning contents are rapidly available, students often learn with a combination of multiple learning tasks. In this work we explore the possibilities of using optimization theory to find the optimal trade-off between the time invested in two different completing learning tasks for each individual student. We show that the problem can be formulated as a linear programming problem, which can be efficiently solved to determine the optimal amount of time for each task. We also report our ongoing attempts to apply this theory to our Facebook Messenger chatbot software that can optimize the trade-off between learning and self-assessing in form of MCQs on the chatbot platform.","New York, NY, USA",20,"Ling, Lin and Tan, Chee Wei",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231677,9.78145E+12,"learning task scheduling, learning effectiveness, optimization theory, personalized learning, chatbot software","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Pilot Study on Optimal Task Scheduling in Learning,https://doi.org/10.1145/3231644.3231677,2018
inproceedings,10.1145/3231644.3231679,"In four years, the Georgia Tech Online MS in CS (OMSCS) program has grown from 200 students to over 6000. Despite early evidence of success, there is a need to evaluate the program's effectiveness. In this paper, we focus on trends from Fall 2014 to Fall 2017 in the on-campus and online sections of one OMSCS course, Knowledge-Based Artificial-Intelligence (KBAI). We leverage sentiment analysis and readability assessments to quantify the evolving quality of discourse on the online forum discussions of the various sections. The research was conducted as a longitudinal study, and aims to evaluate the success of the KBAI course by comparing trends between residential and online sections. Despite slight downward trends in online discourse quality and sentiment polarity, our results suggest that the growing OMSCS program has been successful in replicating the quality of learning experienced by on-campus students in the KBAI course.","New York, NY, USA",21,"Camacho, Ida and Goel, Ashok",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231679,9.78145E+12,"sentiment analysis, natural language processing, readability, online education, computer science","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Longitudinal Trends in Sentiment Polarity and Readability of an Online Masters of Computer Science Course,https://doi.org/10.1145/3231644.3231679,2018
inproceedings,10.1145/3231644.3231680,"Immediate, individualized feedback on their code helps students learning to program. However, even in short, focused exercises in active learning, teachers do not have much time to write feedback. In addition, only looking at a student's final code hides a lot of the students' learning and discovering process. We created a glanceable code history visualization that enables teachers to view a student's entire coding history quickly and efficiently. A preliminary user study shows that this visualization captures previously unseen information that allows teachers to give students better grades and give students longer feedback and better feedback that focuses not just on their final code, but all their code in between.","New York, NY, USA",22,"Cassidy, Caitlin and Goldman, Max and Miller, Robert C.",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231680,9.78145E+12,"visualizations, learning at scale, computer programming","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Glanceable Code History: Visualizing Student Code for Better Instructor Feedback,https://doi.org/10.1145/3231644.3231680,2018
inproceedings,10.1145/3231644.3231681,"Visual models of scientific concepts drawn by students afford expanded opportunities for showing their understanding beyond textual descriptions, but also introduce other elements characterized by artistic creativity and complexity. In this paper, we describe a standardized framework for evaluation of scientific visual models by human raters. This framework attempts to disentangle the interaction between the scientific modeling skills and artistic skills of representing real objects of students, and potentially provides a fair and valid way to assess understanding of scientific concepts e.g. structure and properties of Matter. Additionally, we report ongoing efforts to build automated assessment models based on the evaluation framework. Preliminary findings suggest the promise of such an automated approach.","New York, NY, USA",23,"Leong, Chee Wee and Liu, Lei and Ubale, Rutuja and Chen, Lei",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231681,9.78145E+12,"large-scale educational assessment, automated scoring, visual modeling","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Toward Large-Scale Automated Scoring of Scientific Visual Models,https://doi.org/10.1145/3231644.3231681,2018
inproceedings,10.1145/3231644.3231682,"Video-based learning is most effective when students are engaged with video content; however, the literature has yet to identify students' viewing behaviors and ground them in theory. This paper addresses this need by introducing a framework of active viewing, which is situated in an established model of active learning to describe students' behaviors while learning from video. We conducted a field study with 460 undergraduates in an Applied Science course using a video player designed for active viewing to evaluate how students engage in passive and active video-based learning. The concept of active viewing, and the role of interactive, constructive, active, and passive behaviors in video-based learning, can be implemented in the design and evaluation of video players.","New York, NY, USA",24,"Dodson, Samuel and Roll, Ido and Fong, Matthew and Yoon, Dongwook and Harandi, Negar M. and Fels, Sidney",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231682,9.78145E+12,"active viewing, annotation, video-based learning","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,An Active Viewing Framework for Video-Based Learning,https://doi.org/10.1145/3231644.3231682,2018
inproceedings,10.1145/3231644.3231683,"Engagement on online learning platforms is essential for user retention, learning, and performance. However, there is a paucity of research addressing latent engagement measurement using user activities. In this work in progress paper, we present a novel engagement score consisting of three sub-dimensions - cognitive engagement, emotional engagement, and behavioral engagement using a comprehensive set of user activities. We plan to evaluate our score on a large scale online learning platform and compare our score with measurements from a user survey-based engagement scale from the literature.","New York, NY, USA",25,"Singh, Vivek and Padmanabhan, Balaji and de Vreede, Triparna and de Vreede, Gert-Jan and Andel, Stephanie and Spector, Paul E. and Benfield, Steve and Aslami, Ahmad",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231683,9.78145E+12,"engagement, e-learning, online learning platform","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,A Content Engagement Score for Online Learning Platforms,https://doi.org/10.1145/3231644.3231683,2018
inproceedings,10.1145/3231644.3231684,"In tutoring software, targeting feedback to students' natural-language inputs is a promising avenue for making the software more effective. As a case study, we built such a system using Natural Language Processing (NLP) to provide adaptive feedback to students in an online learning task. We found that the NLP targeting mechanism, relative to more traditional multiple-choice targeting, was able to provide optimal feedback from fewer student interactions and generalize to previously unseen prompts.","New York, NY, USA",26,"Kolchinski, Y. Alex and Ruan, Sherry and Schwartz, Dan and Brunskill, Emma",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231684,9.78145E+12,"adaptive feedback, intelligent tutoring systems, natural language processing","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Adaptive Natural-Language Targeting for Student Feedback,https://doi.org/10.1145/3231644.3231684,2018
inproceedings,10.1145/3231644.3231685,"We present our implementation of a software system that facilitates teachers to create preview and review teaching materials before and after class, as well as enhance interactions between teachers and students for in-class activities. The software system is widely used in China's colleges and universities from 2016, covering more the 3 million teacher/student users. We plan to demonstrate the tool by presenting how it works in a teaching scenario and offering visitors the opportunity to interact with each other.","New York, NY, USA",27,"Wang, Shuaiguo and Chen, Youjie",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231685,9.78145E+12,"MOOCs, rain classroom, blended learning","London, United Kingdom",2,,Association for Computing Machinery,L@S '18,Rain Classroom: A Tool for Blended Learning with MOOCs,https://doi.org/10.1145/3231644.3231685,2018
inproceedings,10.1145/3231644.3231686,"We present a mobile game app (EUR Game) that has been designed to complement teaching and learning in higher education. The mobile game app can be used by teachers to gauge how well students are meeting the learning objectives. Teachers can use the information to provide 'just-in-time' support and adapt their lessons accordingly. For the students, the game app is a study tool that can be used to test their own understanding and monitor their study progress. This, in turn, supports students' self-regulated learning. Gamification elements are also included in the game app to enhance the learning experience. During the demonstration, participants will experience the features of the game app and be engaged in an interactive session to explore the possible ways to use the mobile game app to support teaching and learning.","New York, NY, USA",28,"Zafar, Farshida and Wong, Jacqueline and Khalil, Mohammad",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231686,9.78145E+12,"formative assessment, mobile application, motivation, blended learning, self-regulated learning, gamification","London, United Kingdom",2,,Association for Computing Machinery,L@S '18,Gamifying Higher Education: Enhancing Learning with Mobile Game App,https://doi.org/10.1145/3231644.3231686,2018
inproceedings,10.1145/3231644.3231687,"There are existing multi-MOOC level dropout prediction research in which many MOOCs' data are involved. This generated good results, but there are two potential problems. On one hand, it is inappropriate to use which week students are in to select training data because courses are with different durations. On the other hand, using all other existing data can be computationally expensive and inapplicable in practice.To solve these problems, we propose a model called WPSS (<u>WP</u>ercent and <u>S</u>ubset <u>S</u>election) which combines the course progress normalization parameter wpercent and subset selection. 10 MOOCs offered by The University of Hong Kong are involved and experiments are in the multi-MOOC level. The best performance of WPSS is obtained in neural network when 50% of training data is selected (average AUC of 0.9334). Average AUC is 0.8833 for traditional model without wpercent and subset selection in the same dataset.","New York, NY, USA",29,"Chai, Yuqian and Lei, Chi-Un and Hu, Xiao and Kwok, Yu-Kwong",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231687,9.78145E+12,"dropout prediction, multi-MOOC, data selection","London, United Kingdom",2,,Association for Computing Machinery,L@S '18,WPSS: Dropout Prediction for MOOCs Using Course Progress Normalization and Subset Selection,https://doi.org/10.1145/3231644.3231687,2018
inproceedings,10.1145/3231644.3231688,"Originally, online higher education was imagined to be a utopia for women because gender would be less salient when learners were not physically co-present and thus gender power issues would be lessened. Unfortunately, gender power is present in online classes, hindering women from experiencing the benefits of an equitable learning environment. One approach to eliminating gender power in online classes is to design courses with gender equity in mind. The existing best practices for designing online courses, however, were not developed for the specific purpose of upending gender power. In this poster, I synthesize the best practices for online course design and pose recommendations informed by feminist pedagogy. As more faculty are encouraged to teach online, an updated set of design recommendations that best supports women online learners is valuable both for practitioners and researchers.","New York, NY, USA",30,"Byrne, Virginia L.",Proceedings of the Fifth Annual ACM Conference on Learning at Scale,10.1145/3231644.3231688,9.78145E+12,"feminist pedagogy, online learning, distance learning","London, United Kingdom",4,,Association for Computing Machinery,L@S '18,Contemporary Online Course Design Recommendations to Support Women's Cognitive Development,https://doi.org/10.1145/3231644.3231688,2018
inproceedings,10.1145/3248685,,"New York, NY, USA",,"Urrea, Claudia",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3248685,9.78145E+12,,"Cambridge, Massachusetts, USA",,,Association for Computing Machinery,L@S '17,Session Details: Keynote Address,https://doi.org/10.1145/3248685,2017
inproceedings,10.1145/3051457.3054019,"There's a lot of excitement about how technology can transform education, and how the data created by all this technology can create a new era of amazingly motivating personalized instruction. However, the history of technology in education suggests we need to be skeptical: radio in the 1930's, film in the 1950's, on and on through the decades. -- all promised much, but never reached traction. What makes this time different?A key difference, if we choose to put it to work, is the availability of good, evidence-based principles about how learning seems to work, derived in many laboratories using randomized controlled trials over many years.Unfortunately, as with any set of deeply researched ideas, the narrowly specific conditions of most research studies don't answer the question, ""How do I build a better math/composition/history course"" in any direct way. What we need is an engineering approach -- a way to take evidence-based principles and ideas, and apply them at scale to solve (with plenty of uncertainties and iterative tweaking) real-world situations -- ""learning engineering.""Doing this in an organization that is itself at scale is non-trivial: you may have hundreds of people who should alter their thinking and practice around learning, making this a major change project on top of the series of new engineering challenges that evidence-based work creates.One approach involves taking a series of steps within the organization over time: ExposureEducationEffortEvaluation By drawing from the evidence that exists already, showing examples within the organization of how these principles make a difference, training developers to use the principles for design and managers to use a version of the principles to evaluate resource priorities, and building continuous evaluation into the whole operation, we can move down the path to becoming a ""learning engineering"" organization.","New York, NY, USA",,"Saxberg, Bror",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054019,9.78145E+12,"applied cognitive science, learning engineering, evidence-based instructional design, education technology, e-learning","Cambridge, Massachusetts, USA",1,1,Association for Computing Machinery,L@S '17,Learning Engineering: The Art of Applying Learning Science at Scale,https://doi.org/10.1145/3051457.3054019,2017
inproceedings,10.1145/3248686,,"New York, NY, USA",,"Wiltrout, Mary Ellen",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3248686,9.78145E+12,,"Cambridge, Massachusetts, USA",,,Association for Computing Machinery,L@S '17,Session Details: Engineering Learning Environments,https://doi.org/10.1145/3248686,2017
inproceedings,10.1145/3051457.3051463,"The gold standard for identifying more effective pedagogical approaches is to perform an experiment. Unfortunately, frequently a hypothesized alternate way of teaching does not yield an improved effect. Given the expense and logistics of each experiment, and the enormous space of potential ways to improve teaching, it would be highly preferable if it were possible to estimate in advance of running a study whether an alternative teaching strategy would improve learning. This is true even in learning at scale situations, since even if it is logistically easier to recruit a large number of subjects, it remains a high stakes environment because the experiment is impacting many real students. For certain classes of alternate teaching approaches, such as new ways to sequence existing material, it is possible to build student models that can be used as simulators to estimate the performance of learners under new proposed teaching methods. However, existing methods for doing so can overestimate the performance of new teaching methods. We instead propose the Robust Evaluation Matrix (REM) method which explicitly considers model mismatch between the student model used to derive the teaching strategy and that used as a simulator to evaluate the teaching strategy effectiveness. We then present two case studies from a fractions intelligent tutoring system and from a concept learning task from prior work that show how REM could be used both to detect when a new instructional policy may not be effective on actual students and to detect when it may be effective in improving student learning.","New York, NY, USA",,"Doroudi, Shayan and Aleven, Vincent and Brunskill, Emma",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051463,9.78145E+12,"policy selection, instructional policies, policy estimation, reinforcement learning, off-policy","Cambridge, Massachusetts, USA",10,3?€?12,Association for Computing Machinery,L@S '17,Robust Evaluation Matrix: Towards a More Principled Offline Exploration of Instructional Policies,https://doi.org/10.1145/3051457.3051463,2017
inproceedings,10.1145/3051457.3051468,"Exploratory learning environments, such as virtual labs, support divergent learning pathways. However, due to their complexity, building computational models of learning is challenging as it is difficult to identify features that (i) are informative with respect to common learning strategies, (ii) abstract similar actions beyond surface differences, and (iii) differentiate groups of learners. In this paper, we present a visualization tool that addresses these challenges by facilitating a novel analytic approach to aid in the knowledge engineering process, focusing on five main capabilities: data-driven hypotheses raising, visualizing behavior over time, easily grouping related actions, contrasting learners' behaviors on these actions, and comparing the behaviors of groups of learners. We apply this analytic approach to better understand how students work with a popular interactive physics virtual lab. By splitting learners by learning gains, we found that productive learners performed more active testing and adapted more quickly to the task at hand by focusing on more relevant testing instruments. Implications for online virtual labs and a broader class of complex learning environments are discussed throughout.","New York, NY, USA",,"Fratamico, Lauren and Perez, Sarah and Roll, Ido",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051468,9.78145E+12,"visual analytics, exploratory data analysis, temporal data, educational data mining, interactive virtual labs, learning strategies, exploratory learning environments, learning analytics","Cambridge, Massachusetts, USA",10,13?€?22,Association for Computing Machinery,L@S '17,A Visual Approach towards Knowledge Engineering and Understanding How Students Learn in Complex Environments,https://doi.org/10.1145/3051457.3051468,2017
inproceedings,10.1145/3051457.3051471,"In this paper, we demonstrate a first-of-its-kind adaptive intervention in a MOOC utilizing real-time clickstream data and a novel machine learned model of behavior. We detail how we augmented the edX platform with the capabilities necessary to support this type of intervention which required both tracking learners' behaviors in real-time and dynamically adapting content based on each learner's individual clickstream history. Our chosen pilot intervention was in the category of adaptive pathways and courseware and took the form of a navigational suggestion appearing at the bottom of every non-forum content page in the course. We designed our pilot intervention to help students more efficiently navigate their way through a MOOC by predicting the next page they were likely to spend significant time on and allowing them to jump directly to that page. While interventions which attempt to optimize for learner achievement are candidates for this adaptive framework, behavior prediction has the benefit of not requiring causal assumptions to be made in its suggestions. We present a novel extension of a behavioral model that takes into account students' time spent on pages and forecasts the same. Several approaches to representing time using Recurrent Neural Networks are evaluated and compared to baselines without time, including a basic n-gram model. Finally, we discuss design considerations and handling of edge cases for real-time deployment, including considerations for training a machine learned model on a previous offering of a course for use in a subsequent offering where courseware may have changed. This work opens the door to broad experimentation with adaptivity and serves as a first example of delivering a data-driven personalized learning experience in a MOOC.","New York, NY, USA",,"Pardos, Zachary A. and Tang, Steven and Davis, Daniel and Le, Christopher Vu",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051471,9.78145E+12,"adaptivity, rnn, personalization, real-time intervention, mooc, navigational efficiency, behavioral modeling, edx","Cambridge, Massachusetts, USA",10,23?€?32,Association for Computing Machinery,L@S '17,Enabling Real-Time Adaptivity in MOOCs with a Personalized Next-Step Recommendation Framework,https://doi.org/10.1145/3051457.3051471,2017
inproceedings,10.1145/3248687,,"New York, NY, USA",,"Singer, Susan",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3248687,9.78145E+12,,"Cambridge, Massachusetts, USA",,,Association for Computing Machinery,L@S '17,Session Details: Learn to Code,https://doi.org/10.1145/3248687,2017
inproceedings,10.1145/3051457.3051464,"Education research suggests that learning in one's local language can have a positive impact on learning outcomes. We offer a quantitative test of the association between local language use and the rate at which youth learn to program. Using longitudinal data drawn from five countries and over 15,000 users of Scratch, a large informal learning community, we find that novice users who code with their programming language keywords and environment localized into their home countries' primary language demonstrate new programming concepts at a faster rate than users from the same countries whose interface is in English. We conclude with a discussion of the implications of our findings for designers of online learning systems.","New York, NY, USA",,"Dasgupta, Sayamindu and Hill, Benjamin Mako",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051464,9.78145E+12,"scratch, programming language education, learning in local languages, learning, localization, linguistic accessibility","Cambridge, Massachusetts, USA",7,33?€?39,Association for Computing Machinery,L@S '17,Learning to Code in Localized Programming Languages,https://doi.org/10.1145/3051457.3051464,2017
inproceedings,10.1145/3051457.3051469,"Teaching students to write code with good style is important but difficult: in-depth feedback currently requires a human. AutoStyle, a style tutor that scales, offers adaptive, real-time holistic style feedback and hints as students improve their code. An in-situ study with 103 undergraduate students in a CS class compared AutoStyle to a control tutor which only offered ABC score. While students improved the style of their code in both cases, students working with AutoStyle were more likely to use an appropriate language idiom and to improve their recognition of good style. However, students struggled to implement style improvements, even when hints recommended specific functions.","New York, NY, USA",,"Wiese, Eliane S. and Yen, Michael and Chen, Antares and Santos, Lucas A. and Fox, Armando",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051469,9.78145E+12,"computer science education, in-situ experiments, programming style tutor","Cambridge, Massachusetts, USA",10,41?€?50,Association for Computing Machinery,L@S '17,Teaching Students to Recognize and Implement Good Coding Style,https://doi.org/10.1145/3051457.3051469,2017
inproceedings,10.1145/3248688,,"New York, NY, USA",,"Thille, Candace",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3248688,9.78145E+12,,"Cambridge, Massachusetts, USA",,,Association for Computing Machinery,L@S '17,Session Details: Predicting and Explaining Learning,https://doi.org/10.1145/3248688,2017
inproceedings,10.1145/3051457.3051470,"The current study introduces a model for measuring student diligence using online behaviors during intelligent tutoring system use. This model is validated using a full academic year dataset to test its predictive validity against long-term academic outcomes including end-of-year grades and total work completed by the end of the year. The model is additionally validated for robustness to time-sample length as well as data sampling frequency. While the model is shown to be predictive and robust to time-sample length, the results are inconclusive for robustness in data sampling frequency. Implications for research on interventions, and understanding the influence of self-control, motivation, metacognition, and cognition are discussed.","New York, NY, USA",,"Dang, Steven and Yudelson, Michael and Koedinger, Kenneth R.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051470,9.78145E+12,"diligence, learning analytics, self-regulated learning, noncognitive factors, measurement, online behaviors, intelligent tutoring systems, self-control, motivation","Cambridge, Massachusetts, USA",9,51?€?59,Association for Computing Machinery,L@S '17,Detecting Diligence with Online Behaviors on Intelligent Tutoring Systems,https://doi.org/10.1145/3051457.3051470,2017
inproceedings,10.1145/3051457.3051462,"Epistemic cognition refers to the process of thinking about one's forms of knowledge and ways of knowing. Epistemic cognition becomes especially critical when learners need to, assess the validity, certainty, reliability, source, and limits of their knowledge, as when working through ill-structured problems or evaluating contradictory knowledge claims. This psychological construct is relevant to Massively Open Online Courses (MOOCs), for instance, in that researchers are modeling learner behavior and performance (i.e., how learners handle knowledge) based on inferred learner knowledge states. In this synthesis paper, I provide a brief account of epistemic cognition research, summarize the field's key findings and theories, and outline the affordances that epistemic cognition offers to online learning researchers. I also show that, without knowing it, online learning researchers have already engaged with epistemic cognition concepts and provide recommendations for future, more theoretically and practically enriching work.","New York, NY, USA",,"Johanes, Petr",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051462,9.78145E+12,"knowledge modeling, epistemology, online learning, mooc, epistemic cognition","Cambridge, Massachusetts, USA",9,61?€?69,Association for Computing Machinery,L@S '17,Epistemic Cognition: A Promising and Necessary Construct for Enriching Large-Scale Online Learning Analysis,https://doi.org/10.1145/3051457.3051462,2017
inproceedings,10.1145/3248689,,"New York, NY, USA",,"Ogan, Amy",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3248689,9.78145E+12,,"Cambridge, Massachusetts, USA",,,Association for Computing Machinery,L@S '17,Session Details: Feedback for Improving Learning,https://doi.org/10.1145/3248689,2017
inproceedings,10.1145/3051457.3051459,"Traditionally, education relies on a linear relationship between enrollment and staff; rising enrollment dictates increases to staff with some expertise (such as teaching assistants, TAs) for evaluation. This relationship is expensive, so learning at scale has largely deemphasized expert evaluation and feedback. Two organizations, though, have used different models to scale up class size online while retaining this expert evaluation and feedback. In this paper, we analyze the methods these two organizations have used to increase enrollment while preserving scalability and feedback. We observe an academic program has scaled feedback with traditional TAs by relying on unique characteristics of its student body, while a commercial program has done so with a novel, network-based model. These successes show the potential of learning from experts at scale.","New York, NY, USA",,"Joyner, David A.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051459,9.78145E+12,"online higher education, expert feedback, microcredentials.","Cambridge, Massachusetts, USA",10,71?€?80,Association for Computing Machinery,L@S '17,Scaling Expert Feedback: Two Case Studies,https://doi.org/10.1145/3051457.3051459,2017
inproceedings,10.1145/3051457.3051466,"We present a system for online assessment of handwritten homework assignments and exams. First, either instructors or students scan and upload handwritten work. Instructors then grade the work and distribute the results using a web-based platform. Our system optimizes for three key dimensions: speed, consistency, and flexibility. The primary innovation enabling improvements in all three dimensions is a dynamically evolving rubric for each question on an assessment. We also describe how the system minimizes the overhead incurred in the digitization process. Our system has been in use for four years, with instructors at 200 institutions having graded over 10 million pages of student work. We present results as user-reported data and feedback regarding time saved grading, enjoyment, and student experience. Two-thirds of responders report saving 30% or more time relative to their traditional workflow. We also find that the time spent grading an individual response to a question rapidly decays with the number of responses to that question that the grader has already graded.","New York, NY, USA",,"Singh, Arjun and Karayev, Sergey and Gutowski, Kevin and Abbeel, Pieter",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051466,9.78145E+12,"education, rubric-based grading, learning assessment, computer-assisted instruction, scaling large courses","Cambridge, Massachusetts, USA",8,81?€?88,Association for Computing Machinery,L@S '17,"Gradescope: A Fast, Flexible, and Fair System for Scalable Assessment of Handwritten Work",https://doi.org/10.1145/3051457.3051466,2017
inproceedings,10.1145/3051457.3051467,"In large introductory programming classes, teacher feedback on individual incorrect student submissions is often infeasible. Program synthesis techniques are capable of fixing student bugs and generating hints automatically, but they lack the deep domain knowledge of a teacher and can generate functionally correct but stylistically poor fixes. We introduce a mixed-initiative approach which combines teacher expertise with data-driven program synthesis techniques. We demonstrate our novel approach in two systems that use different interaction mechanisms. Our systems use program synthesis to learn bug-fixing code transformations and then cluster incorrect submissions by the transformations that correct them. The MistakeBrowser system learns transformations from examples of students fixing bugs in their own submissions. The FixPropagator system learns transformations from teachers fixing bugs in incorrect student submissions. Teachers can write feedback about a single submission or a cluster of submissions and propagate the feedback to all other submissions that can be fixed by the same transformation. Two studies suggest this approach helps teachers better understand student bugs and write reusable feedback that scales to a massive introductory programming classroom.","New York, NY, USA",,"Head, Andrew and Glassman, Elena and Soares, Gustavo and Suzuki, Ryo and Figueredo, Lucas and D'Antoni, Loris and Hartmann, Bj\""{o}rn",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051467,9.78145E+12,"programming education, program synthesis","Cambridge, Massachusetts, USA",10,89?€?98,Association for Computing Machinery,L@S '17,Writing Reusable Code Feedback at Scale with Mixed-Initiative Program Synthesis,https://doi.org/10.1145/3051457.3051467,2017
inproceedings,10.1145/3248690,,"New York, NY, USA",,"Urrea, Claudia",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3248690,9.78145E+12,,"Cambridge, Massachusetts, USA",,,Association for Computing Machinery,L@S '17,Session Details: Plenary Panel,https://doi.org/10.1145/3248690,2017
inproceedings,10.1145/3051457.3054034,"In today's fast-changing world, the ability to think and act creatively is more important than ever before. This panel will discuss tools, activities, and strategies for helping people develop as creative thinkers -- and how to scale those efforts to engage learners around the world. The panel will draw on examples involving learners of many different ages, in many different places, both in school and out.","New York, NY, USA",,"Resnick, Mitchel and Brennan, Karen and Cobo, Crist\'{o}bal and Schmidt, Philipp",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054034,9.78145E+12,"scratch, creative thinking","Cambridge, Massachusetts, USA",2,99?€?100,Association for Computing Machinery,L@S '17,Creative Learning @ Scale,https://doi.org/10.1145/3051457.3054034,2017
inproceedings,10.1145/3248691,,"New York, NY, USA",,"Scanlon, Eileen",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3248691,9.78145E+12,,"Cambridge, Massachusetts, USA",,,Association for Computing Machinery,L@S '17,Session Details: Integrity of Courses and Learners,https://doi.org/10.1145/3248691,2017
inproceedings,10.1145/3051457.3051458,"Large-scale courses such as Massive Online Open Courses (MOOCs) can be a great data source for researchers. Ideally, the data gathered on such courses should be openly available to all researchers. Studies could be easily replicated and novel studies on existing data could be conducted. However, very fine-grained data such as source code snapshots can contain hidden identifiers. For example, distinct typing patterns that identify individuals can be extracted from such data. Hence, simply removing explicit identifiers such as names and student numbers is not sufficient to protect the privacy of the users who have supplied the data. At the same time, removing all keystroke information would decrease the value of the shared data significantly.In this work, we study how keystroke data from a programming context could be modified to prevent keystroke latency based identification whilst still retaining information that can be used to e.g. infer programming experience. We investigate the degree of anonymization required to render identification of students based on their typing patterns unreliable. Then, we study whether the modified keystroke data can still be used to infer the programming experience of the students as a case study of whether the anonymized typing patterns have retained at least some informative value.We show that it is possible to modify data so that keystroke latency based identification is no longer accurate, but the programming experience of the students can still be inferred, i.e. the data still has value to researchers. In a broader context, our results indicate that information and anonymity are not necessarily mutually exclusive.","New York, NY, USA",,"Leinonen, Juho and Ihantola, Petri and Hellas, Arto",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051458,9.78145E+12,"programming experience inference, data anonymization, source code snapshots, keystroke dynamics, data privacy","Cambridge, Massachusetts, USA",9,101?€?109,Association for Computing Machinery,L@S '17,Preventing Keystroke Based Identification in Open Data Sets,https://doi.org/10.1145/3051457.3051458,2017
inproceedings,10.1145/3051457.3051465,"Using a data set from 29,492 asynchronous exams in an on-campus proctored computer-based testing facility (CBTF), we observed correlations between when a student chooses to take their exam within the exam period and their score on the exam. Somewhat surprisingly, instead of increasing throughout the exam period, which might be indicative of widespread collaborative cheating, we find that exam scores decrease throughout the exam period. While this could be attributed to weaker students putting off exams, this effect holds even when accounting for student ability as measured by a synchronous exam taken during the same semester. This suggests that precautions can be taken by a CBTF to maintain cheating at a low level (e.g., the level of proctored synchronous exams), in spite of the fact that students are taking their exams over a multi-day period.","New York, NY, USA",,"Chen, Binglin and West, Matthew and Zilles, Craig",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051465,9.78145E+12,"computerized testing, student performance, asynchronous exams, cheating","Cambridge, Massachusetts, USA",10,111?€?120,Association for Computing Machinery,L@S '17,Do Performance Trends Suggest Wide-Spread Collaborative Cheating on Asynchronous Exams?,https://doi.org/10.1145/3051457.3051465,2017
inproceedings,10.1145/3248692,,"New York, NY, USA",,"Glassman, Elena",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3248692,9.78145E+12,,"Cambridge, Massachusetts, USA",,,Association for Computing Machinery,L@S '17,Session Details: Experimentation,https://doi.org/10.1145/3248692,2017
inproceedings,10.1145/3051457.3051460,"The presence of achievement gaps in Massive Open Online Courses (MOOCs) implies that not everyone who can gain access to a course shares the same opportunities to succeed. This study advances research on a social psychological barrier to achievement that exists alongside important structural barriers (e.g., Internet access, insufficient prior knowledge). Learners who experience social identity threat (SIT) - a fear of being judged negatively in light of a social group they identify with - are at risk of underperforming. An initial survey identified lower-class men as an at-risk group in an English language learning MOOC for Chinese learners (N = 1,664). In a subsequent randomized experiment, an interdependent value relevance affirmation intervention raised grades, persistence, and completion rates exclusively among lower-class men - the lowest performing group in the course (N = 1,990). Efforts to establish equal opportunities in online learning should go beyond initiatives that increase access through technology to incorporate strategies that lower psychological barriers to create safe and inclusive learning environments.","New York, NY, USA",,"Kizilcec, Ren\'{e} F. and Davis, Glenn M. and Cohen, Geoffrey L.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3051460,9.78145E+12,"randomized experiment, achievement gaps, massive open online course., social psychology","Cambridge, Massachusetts, USA",10,121?€?130,Association for Computing Machinery,L@S '17,Towards Equal Opportunities in MOOCs: Affirmation Reduces Gender &amp; Social-Class Achievement Gaps in China,https://doi.org/10.1145/3051457.3051460,2017
inbook,10.1145/3051457.3051461,"Learning at scale opens up a new frontier to learn about learning. MOOCs and similar large-scale online learning platforms give an unprecedented view of learners' behavior whilst learning. In this paper, we argue that the abundance of data that results from such platforms not only brings novel opportunities to the study of learning, but also bears novel methodological challenges. We show that the resulting data comes with various challenges with respect to the granular, observational, and large nature of these data. Additionally, we discuss a series of potential solutions, such as sharing validated models and performing pre-registered confirmatory research. With these contributions, this paper aims to increase awareness and understanding of both the strengths and challenges of research on learning at scale.","New York, NY, USA",,"van der Sluis, Frans and van der Zee, Tim and Ginn, Jasper",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,,9.78145E+12,,,10,131?€?140,Association for Computing Machinery,,Learning about Learning at Scale: Methodological Challenges and Recommendations,https://doi.org/10.1145/3051457.3051461,2017
inproceedings,10.1145/3051457.3053967,"We present Discourse, a tool for coding and annotating MOOC discussion forum data. Despite the centrality of discussion forums to learning in online courses, few tools are available for analyzing these discussions in a context-aware way. Discourse scaffolds the process of coding forum data by enabling multiple coders to work with large amounts of forum data. Our demonstration will enable attendees to experience, explore, and critique key features of the app.","New York, NY, USA",,"Kindel, Alexander and Yeomans, Michael and Reich, Justin and Stewart, Brandon and Tingley, Dustin",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053967,9.78145E+12,"reply mapping, content analysis, discussions, moocs","Cambridge, Massachusetts, USA",2,141?€?142,Association for Computing Machinery,L@S '17,Discourse: MOOC Discussion Forum Analysis at Scale,https://doi.org/10.1145/3051457.3053967,2017
inproceedings,10.1145/3051457.3053968,"This demo submission is associated with the Work-in-Progress submission ""Orchestration Graphs: enabling rich social pedagogical scenarios in MOOCs"". We present our implementation of a web application for designing, running and orchestrating social pedagogical scenarios. The application is based on Orchestration Graphs, an educational modeling language. We plan to demonstrate our technology by automatically simulating user activity, and offering visitors the opportunity to interact with the graph editor.","New York, NY, USA",,"Faucon, Louis and H\r{a}klev, Stian and Hadzilacos, Thanasis and Dillenbourg, Pierre",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053968,9.78145E+12,"scripting, moocs, orchestration","Cambridge, Massachusetts, USA",2,143?€?144,Association for Computing Machinery,L@S '17,Demo of Orchestration Graph Engine: Enabling Rich Social Pedagogical Scenarios in MOOCs,https://doi.org/10.1145/3051457.3053968,2017
inproceedings,10.1145/3051457.3053969,"This work presents an innovative framework with the aim to create full engagement for the learners on massive open online learning environments. The proposed framework was prepared with the aim to increase the engagement and motivation of the student from the enrollment step to the start of the course, but the most important objective is to extend the interaction beyond the end of the course, the post-MOOC phase. This work explores the experience from two ""MicroMaster"" specializations in the edX platform: ""Professional Android Developer"" and one specialization taught in Spanish: ""E-Learning for teachers: create innovative activities and content"".","New York, NY, USA",,"Rizzardini, Rocael Hern\'{a}ndez and Amado-Salvatierra, Hector R.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053969,9.78145E+12,"engagement, mooc, motivation, community","Cambridge, Massachusetts, USA",2,145?€?146,Association for Computing Machinery,L@S '17,Full Engagement Educational Framework: A Practical Experience for a MicroMaster,https://doi.org/10.1145/3051457.3053969,2017
inproceedings,10.1145/3051457.3053970,"This paper introduces the CODECAST tool: an in-browser C language interpreter, paired with an event and voice recorder and player that facilitates teaching and learning to program by synchronizing audio with source code edition, visualization, step by step execution and testing.","New York, NY, USA",,"Sharrock, R\'{e}mi and Hamonic, Ella and Hiron, Mathias and Carlier, Sebastien",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053970,9.78145E+12,"online learning, teaching, code editor, code execution, code test, code visualization, mooc, programming, audio, code edition","Cambridge, Massachusetts, USA",2,147?€?148,Association for Computing Machinery,L@S '17,CODECAST: An Innovative Technology to Facilitate Teaching and Learning Computer Programming in a C Language Online Course,https://doi.org/10.1145/3051457.3053970,2017
inproceedings,10.1145/3051457.3053971,"This paper presents a novel approach to understand specific student behavior in MOOCs. Instructors currently perceive participants only as one homogeneous group. In order to improve learning outcomes, they encourage students to get active in the discussion forum and remind them of approaching deadlines. While these actions are most likely helpful, their actual impact is often not measured. Additionally, it is uncertain whether such generic approaches sometimes cause the opposite effect, as some participants are bothered with irrelevant information. On the basis of fine granular events emitted by our learning platform, we derive metrics and enable teachers to employ clustering, in order to divide the vast field of participants into meaningful subgroups to be addressed individually.","New York, NY, USA",,"Teusner, Ralf and Rollmann, Kai-Adrian and Renz, Jan",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053971,9.78145E+12,"cluster, mooc, metrics, learning analytics, survey","Cambridge, Massachusetts, USA",4,149?€?152,Association for Computing Machinery,L@S '17,Taking Informed Action on Student Activity in MOOCs,https://doi.org/10.1145/3051457.3053971,2017
inproceedings,10.1145/3051457.3053972,"In MOOCs, both instructors and students invest substantial effort into discussion forums. However, those discussions are abandoned when instructors start a new session in session-based courses. In an observational field study through a popular online Coursera course, we evaluate an approach that directly embeds high-value past discussion threads into future lecture videos to reuse them. Survey feedback shows that this approach can be useful to a large proportion of learners. We find that instructor involvement increases learners' chance of reading the threads, reduces learners' negative reactions, but is not associated with more perceived usefulness. Learners perceive enhancing threads embedded in the middle of videos less enhancing but more explanatory compared with at the end. Embedding explanatory threads at the end is rated less distracting and more helpful to understand the video compared with in the middle, right after the related content is lectured.","New York, NY, USA",,"Zhao, Qian and Varma, Sashank and Konstan, Joseph A.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053972,9.78145E+12,"moocs, computer supported collaborative learning","Cambridge, Massachusetts, USA",4,153?€?156,Association for Computing Machinery,L@S '17,In-Video Reuse of Discussion Threads in MOOCs,https://doi.org/10.1145/3051457.3053972,2017
inproceedings,10.1145/3051457.3053973,"We investigated the feasibility of crowdsourcing full- fledged tutorial videos from ordinary people on the Web on how to solve math problems related to logarithms. This kind of approach (a form of learnersourcing [9, 11]) to efficiently collecting tutorial videos and other learning resources could be useful for realizing personalized learning-at-scale, whereby students receive specific learning resources -- drawn from a large and diverse set -- that are tailored to their individual and time-varying needs. Results of our study, in which we collected 399 videos from 66 unique ""teachers"" on Mechanical Turk, suggest that (1) approximately 100 videos -- over 80% of which are mathematically fully correct -- can be crowdsourced per week for $5/video; (2) the average learning gains (posttest minus pretest score) associated with watching the videos was stat. sig. higher than for a control video (0.105 versus 0.045); and (3) the average learning gains (0.1416) from watching the best tested crowdsourced videos was comparable to the learning gains (0.1506) from watching a popular Khan Academy video on logarithms.","New York, NY, USA",,"Whitehill, Jacob and Seltzer, Margo",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053973,9.78145E+12,"crowdsourcing, personalized learning","Cambridge, Massachusetts, USA",4,157?€?160,Association for Computing Machinery,L@S '17,A Crowdsourcing Approach to Collecting Tutorial Videos -- Toward Personalized Learning-at-Scale,https://doi.org/10.1145/3051457.3053973,2017
inproceedings,10.1145/3051457.3053974,"In order to obtain reliable accuracy estimates for automatic MOOC dropout predictors, it is important to train and test them in a manner consistent with how they will be used in practice. Yet most prior research on MOOC dropout prediction has measured test accuracy on the same course used for training, which can lead to overly optimistic accuracy estimates. In order to understand better how accuracy is affected by the training+testing regime, we compared the accuracy of a standard dropout prediction architecture (clickstream features + logistic regression) across 4 different training paradigms. Results suggest that (1) training and testing on the same course (""post-hoc"") can significantly overestimate accuracy. Moreover, (2) training dropout classifiers using proxy labels based on students' persistence -- which are available before a MOOC finishes -- is surprisingly competitive with post-hoc training (87.33% v.~90.20% AUC averaged over 8 weeks of 40 HarvardX MOOCs) and can support real-time MOOC interventions.","New York, NY, USA",,"Whitehill, Jacob and Mohan, Kiran and Seaton, Daniel and Rosen, Yigal and Tingley, Dustin",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053974,9.78145E+12,"dropout prediction, massive open online courses, accuracy estimation","Cambridge, Massachusetts, USA",4,161?€?164,Association for Computing Machinery,L@S '17,MOOC Dropout Prediction: How to Measure Accuracy?,https://doi.org/10.1145/3051457.3053974,2017
inproceedings,10.1145/3051457.3053975,"Teamwork is an an important topic in education. It fosters deep learning and allows educators to assign interesting tasks, which would be too complex to be solved by single participants due to the time restrictions defined by the context of a course.Furthermore, today's jobs require an increasing amount of team skills. On the other hand, teamwork comes with a variety of issues of its own. Particularly in large scale settings, such as MOOCs, teamwork is challenging. Courses often end with dysfunctional teams due to drop-outs or insufficient matching. The paper at hand presents a set of three tools that we have recently added to our system to enable teamwork in our courses. This toolset consists of the TeamBuilder, a tool to match successful teams based on a variable set of parameters, CollabSpaces, providing teams with a secluded area to communicate and collaborate within the course context, and a TeamPeerAssessment tool, which allows to provide teams with complex tasks and which allows assessment that suffiiently scales for the MOOC context. The presented tools are evaluated in terms of success rates of the created teams and workload reduction for the courses' teaching teams.","New York, NY, USA",,"Staubitz, Thomas and Meinel, Christoph",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053975,9.78145E+12,"massive open online courses, mooc, collaboration, peerassessment, teamwork","Cambridge, Massachusetts, USA",4,165?€?168,Association for Computing Machinery,L@S '17,Collaboration and Teamwork on a MOOC Platform: A Toolset,https://doi.org/10.1145/3051457.3053975,2017
inproceedings,10.1145/3051457.3053976,"Knowledge Tracing aims to model student knowledge by predicting the correctness of each next item as students work through an assignment. Through recent developments in deep learning, Deep Knowledge Tracing (DKT) was explored as a method to improve upon traditional methods. Thus far, the DKT model has only considered the knowledge components and correctness as input, neglecting the other important features collected by computer-based learning platforms. This paper seeks to further improve upon DKT by incorporating more problem-level features. With this higher dimensional input, an adaption to the original DKT model structure is also proposed to convert the input into a low dimensional feature vector. Our results show that this adapted DKT model can effectively improve accuracy.","New York, NY, USA",,"Zhang, Liang and Xiong, Xiaolu and Zhao, Siyuan and Botelho, Anthony and Heffernan, Neil T.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053976,9.78145E+12,"deep knowledge tracing (dkt), knowledge tracing, auto encoder, recurrent neural networks (rnn)","Cambridge, Massachusetts, USA",4,169?€?172,Association for Computing Machinery,L@S '17,Incorporating Rich Features into Deep Knowledge Tracing,https://doi.org/10.1145/3051457.3053976,2017
inproceedings,10.1145/3051457.3053977,"It can be difficult for educators with limited resources to decide which queries need immediate attention when a high volume of questions arises on the discussion forum. This becomes increasingly complex as the educator aims to obtain the best outcome across all threads in a timely fashion. Existing approaches to automated forum analysis provide a useful grouping of messages and identify common discussions, but require additional attention towards effective intervention. Research has shown that the timing of messages relative to associated deadlines is a key indicator of priority. In this paper, we propose the formal representation of events within a discussion forum to facilitate the definition of potential and existing intervention strategies. We enhance forum events with information about teaching activities, such as assignment deadlines, and discuss intervention strategies.","New York, NY, USA",,"Falkner, Nickolas and Szabo, Claudia and Falkner, Katrina",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053977,9.78145E+12,"discussion forums, mathematical models, teacher intervention, on-line communication, intervention strategies","Cambridge, Massachusetts, USA",4,173?€?176,Association for Computing Machinery,L@S '17,Formal Forum Triage: Towards the Strategic Selection of Responses to Student Discussion Forums,https://doi.org/10.1145/3051457.3053977,2017
inproceedings,10.1145/3051457.3053978,"The Self-Paced Learning Increases Retention and Capacity (SPARC) project is responding to the well-documented surge in CS enrollment by creating a self-paced learning environment that blends online learning, automated assessment, collaborative practice, and peer-supported learning. SPARC delivers educational material online, encourages students to practice programming in groups, frees them to learn material at their own pace, and allows them to demonstrate proficiency at any time. This model contrasts with traditional course offerings, which impose a single schedule of due dates and exams for all students. SPARC allows students to complete courses faster or slower at a pace tailored to the individual, thereby allowing universities to teach more students with the same or fewer resources. This paper describes the goals and elements of the SPARC model as applied to CS1. We present results so far and discuss the future of the project.","New York, NY, USA",,"Offutt, Jeff and Ammann, Paul and Dobolyi, Kinga and Kauffmann, Chris and Lester, Jaime and Praphamontripong, Upsorn and Rangwala, Huzefa and Setia, Sanjeev and Wang, Pearl and White, Liz",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053978,9.78145E+12,"gender and diversity, collaboration, peer learning, online learning, scaling cs1, active learning, self-pacing","Cambridge, Massachusetts, USA",4,177?€?180,Association for Computing Machinery,L@S '17,A Novel Self-Paced Model for Teaching Programming,https://doi.org/10.1145/3051457.3053978,2017
inproceedings,10.1145/3051457.3053980,"The size and complexity of MOOC data present overwhelming challenges to many institutions. This paper details the functionality of edx2bigquery -- an open source Python package developed by Harvard and MIT to ingest and report on hundreds of MITx and HarvardX course datasets from edX, making use of Google BigQuery to handle multiple terabytes of learner data. For this application, we find that Google BigQuery provides ease of use in loading the multi-faceted MOOC datasets and near real-time interactive querying of data, including large clickstream datasets; moreover, we are able to provide flexible research and reporting dashboards, visualizing and aggregating data, by interfacing services associated with BigQuery. This framework makes it feasible for edx2bigquery to be open source, following standards which emphasize the importance of data products that transcend a particular data science platform and allow teams with diverse backgrounds to interact with data. edx2bigquery is being adopted by other institutions with an aim toward future collaboration.","New York, NY, USA",,"Lopez, Glenn and Seaton, Daniel T. and Ang, Andrew and Tingley, Dustin and Chuang, Isaac",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053980,9.78145E+12,"big data, mooc, bigquery, educational data mining., learning analytics","Cambridge, Massachusetts, USA",4,181?€?184,Association for Computing Machinery,L@S '17,Google BigQuery for Education: Framework for Parsing and Analyzing EdX MOOC Data,https://doi.org/10.1145/3051457.3053980,2017
inproceedings,10.1145/3051457.3053981,"Making MOOCs accessible to English Language Learners (ELLs) requires that students understand the language of instruction, and that instructional strategies address their unique learning challenges. Through the analysis of clickstream log data gathered from two MOOC courses deployed on Coursera, Introduction to Psychology and Statistical Thermodynamics, we show that ELL students exhibit distinct struggle behaviors in video portions without visual aids e.g., narrations without slides. Our findings challenge widely accepted multimedia design principles such as the split attention effect, provide insights into designing MOOC videos, and emphasize the need for adaptivity to increase MOOC access for ELLs.","New York, NY, USA",,"Uchidiuno, Judith and Hammer, Jessica and Yarzebinski, Evelyn and Koedinger, Kenneth R. and Ogan, Amy",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053981,9.78145E+12,"moocs, english language learners, ell student identification, mooc behavioral analysis, language support interventions","Cambridge, Massachusetts, USA",4,185?€?188,Association for Computing Machinery,L@S '17,Characterizing ELL Students' Behavior During MOOC Videos Using Content Type,https://doi.org/10.1145/3051457.3053981,2017
inproceedings,10.1145/3051457.3053982,"The need for automated grading tools for essay writing and open-ended assignments has received increasing attention due to the unprecedented scale of Massive Online Courses (MOOCs) and the fact that more and more students are relying on computers to complete and submit their school work. In this paper, we propose an efficient memory networks-powered automated grading model. The idea of our model stems from the philosophy that with enough graded samples for each score in the rubric, such samples can be used to grade future work that is found to be similar. For each possible score in the rubric, a student response graded with the same score is collected. These selected responses represent the grading criteria specified in the rubric and are stored in the memory component. Our model learns to predict a score for an ungraded response by computing the relevance between the ungraded response and each selected response in memory. The evaluation was conducted on the Kaggle Automated Student Assessment Prize (ASAP) dataset. The results show that our model achieves state-of-the-art performance in 7 out of 8 essay sets.","New York, NY, USA",,"Zhao, Siyuan and Zhang, Yaqiong and Xiong, Xiaolu and Botelho, Anthony and Heffernan, Neil",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053982,9.78145E+12,"automated essay grading, neural networks, memory networks, word embeddings, natural language processing","Cambridge, Massachusetts, USA",4,189?€?192,Association for Computing Machinery,L@S '17,A Memory-Augmented Neural Model for Automated Grading,https://doi.org/10.1145/3051457.3053982,2017
inproceedings,10.1145/3051457.3053983,"The ability to customize instruction to individuals is a great potential for adaptive educational software. Unfortunately, beyond mastery learning and learner control, there has not been much work with adapting instruction to individuals. This paper provides an approach to determine what type of learner does best with a different intervention. We focused on constructing a decision tree that discriminated difference between tutoring interventions, and thus to make customization for each student. We evaluated our model on simulated and on real data. In the simulated data set, it outperformed other methods and the constructed models captured a pre-defined customization structure. With the real data, the customized learning approach achieved stronger learning gains than simply picking the best overall teaching option. Surprisingly, it was difficult to outperform a decision tree that simply used how quickly students tended to learn a skill. That is, more features and more complex models did not result in a more effective system.","New York, NY, USA",,"Wan, Hao and Beck, Joseph E.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053983,9.78145E+12,"customization, decision tree, treatment effect","Cambridge, Massachusetts, USA",4,193?€?196,Association for Computing Machinery,L@S '17,One Decision Tree is Enough to Make Customization,https://doi.org/10.1145/3051457.3053983,2017
inproceedings,10.1145/3051457.3053984,"The Mechanics Reasoning Inventory (MRI) is an assessment instrument specifically designed to assess strategic reasoning skills involving core concepts in introductory Newtonian mechanics. Being an assessment of higher order thinking (as opposed to declarative or rule-based procedural thinking), it is necessary to check whether or not the mental constructs underlying actual student responses correlate with the authors' domain classification, which is the subject of this paper. The instrument consists of three types of problems: whether momentum or energy is conserved in a given situation and why, (partly inspired by the paired what/why questions in Lawson's Classroom Test of Scientific Reasoning), application of Newton's 2nd and 3rd law, and decomposing problems into parts (inspired by Van Domelen's Problem Decomposition Diagnostic). It has been administered 183 times in two MIT courses since 2009. Exploratory Factor Analysis (EFA) revealed that each Lawson pair of questions should be considered as one item, after which it identified four factors among the 21 questions that correspond reasonably well with the intended physics topics, and a fifth factor correlated with the concept of circular motion, a difficult topic for students (even though not viewed as a core principle by the designers). We discuss why 6 of the items classified under factors that differed from the expert assignments. There was no strong indication that the students answered each of different problem types similarly, which is a hallmark of students using novice heuristics rather than reasoning based on physical principles to answer the questions.","New York, NY, USA",,"Lee, Sunbok and Chen, Zhongzhou and Pritchard, David and Kimn, Alex and Paul, Andrew",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053984,9.78145E+12,"exploratory factor analysis, mechanical reasoning inventory","Cambridge, Massachusetts, USA",4,197?€?200,Association for Computing Machinery,L@S '17,Factor Analysis Reveals Student Thinking Using the Mechanics Reasoning Inventory,https://doi.org/10.1145/3051457.3053984,2017
inproceedings,10.1145/3051457.3053985,"Modeling a student's knowledge state while she is solving exercises is a crucial stepping stone towards providing better personalized learning experiences at scale. This task, also referred to as ""knowledge tracing"", has been explored extensively on exercises where student submissions fall into a finite discrete solution space, e.g. a multiple-choice answer. However, we believe that rich information about a student's learning is captured within their responses to open-ended problems with unbounded solution spaces, such as programming exercises. In addition, sequential snapshots of a student's progress while she is solving a single exercise can provide valuable insights into her learning behavior. In this setting, creating representations for a student's knowledge state is a challenging task, but with recent advances in machine learning, there are more promising techniques to learn representations for complex entities. In our work, we feed the embedded program submissions into a recurrent neural network and train it on the task of predicting the student's success on the subsequent programming exercise. By training on this task, the model learns nuanced representations of a student's knowledge, and reliably predicts future student performance.","New York, NY, USA",,"Wang, Lisa and Sy, Angela and Liu, Larry and Piech, Chris",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053985,9.78145E+12,"sequential modeling., knowledge tracing, online education, educational data mining, representation learning, machine learning, deep learning, personalized learning","Cambridge, Massachusetts, USA",4,201?€?204,Association for Computing Machinery,L@S '17,Deep Knowledge Tracing On Programming Exercises,https://doi.org/10.1145/3051457.3053985,2017
inproceedings,10.1145/3051457.3053986,"Massive open online courses (MOOCs) provide educators with an abundance of data describing how students interact with the platform, but this data is highly underutilized today. This is in part due to the lack of sophisticated tools to provide interpretable and actionable summaries of huge amounts of MOOC activity present in log data. In this paper, we propose a method for automatically discovering student behavior patterns by leveraging the click log data that can be obtained from the MOOC platform itself in a completely unsupervised manner.","New York, NY, USA",,"Geigle, Chase and Zhai, ChengXiang",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053986,9.78145E+12,"student behavior modeling, hidden markov models, markov models, mooc log analysis","Cambridge, Massachusetts, USA",4,205?€?208,Association for Computing Machinery,L@S '17,Modeling MOOC Student Behavior With Two-Layer Hidden Markov Models,https://doi.org/10.1145/3051457.3053986,2017
inproceedings,10.1145/3051457.3053987,"Massive Open Online Courses (MOOCs) promise to engage a global audience and emphasize the democratic achievement of free, university-level education. While such open access enables participation, it is unclear how learners who are not fluent in English (ELLs) engage with MOOC content. After all, the language of MOOCs is English. In order to improve accessibility for ELLs in digital learning environments, we must first have a clear understanding of the educational landscape: who are the non-native English speakers enrolled in MOOCs? Where are they located geographically? What are their current online learning behaviors, motivations and outcomes? In this paper we start answering some of these questions by analyzing data from 100 HarvardX courses, using self-report and log data. Preliminary analysis show evidence that ELLs are motivated by more utilitarian goals compared to non-ELLs.","New York, NY, USA",,"T\""{u}rkay, Selen and Eidelman, Hadas and Rosen, Yigal and Seaton, Daniel and Lopez, Glenn and Whitehill, Jacob",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053987,9.78145E+12,,"Cambridge, Massachusetts, USA",4,209?€?212,Association for Computing Machinery,L@S '17,"Getting to Know English Language Learners in MOOCs: Their Motivations, Behaviors, and Outcomes",https://doi.org/10.1145/3051457.3053987,2017
inproceedings,10.1145/3051457.3053988,"K-12 education standards in the U.S. require all students to read complex texts across many subject areas. The Language Muse??? Activity Palette is a web-based language-instruction application that uses NLP algorithms and lexical resources to automatically generate language activities and support English language learners' content comprehension and language skills development. The system's online platform for activity generation, scoring, and feedback is scalable for MOOCs, as well as for other online learning settings.","New York, NY, USA",,"Burstein, Jill and Madnani, Nitin and Sabatini, John and McCaffrey, Dan and Biggers, Kietha and Dreier, Kelsey",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053988,9.78145E+12,"natural language processing, artificial intelligence, computer-assisted language learning","Cambridge, Massachusetts, USA",3,213?€?215,Association for Computing Machinery,L@S '17,Generating Language Activities in Real-Time for English Learners Using Language Muse,https://doi.org/10.1145/3051457.3053988,2017
inproceedings,10.1145/3051457.3053989,"This paper presents a thread characterization method that compares categorization results for thread starters and replies made by a previously-developed natural language model, using human judgment to resolve discrepancies. In an example application using the complete discussion forum data from a MOOC on medical statistics, the method increased the estimation of classification accuracy from .81 to .88 with the addition of a minimal number of human hours.","New York, NY, USA",,"Cui, Yi and Jin, Wan Qi and Wise, Alyssa Friend",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053989,9.78145E+12,"discussion forum, massive open online courses, thread categorization.","Cambridge, Massachusetts, USA",3,217?€?219,Association for Computing Machinery,L@S '17,Humans and Machines Together: Improving Characterization of Large Scale Online Discussions through Dynamic Interrelated Post and Thread Categorization (DIPTiC),https://doi.org/10.1145/3051457.3053989,2017
inproceedings,10.1145/3051457.3053990,"This paper presents a new pedagogical paradigm ``Crowdlearning'', where students experience deeper learning through collaboratively creating learning materials for each other. Crowdlearning practice is envisioned to produce large ``banks'' of subject matter problems generated by students themselves, in a crowdsourced way, as the students learn new subjects; these problems can then serve as learning and assessment materials usable at scale. This paper overviews the motivation for the development of Crowdlearning as a teaching practice and the theoretical drivers behind it. The paper then reports on preliminary field studies and experiences suggesting that Crowdlearning has a solid potential for adoption in STEM.","New York, NY, USA",,"Farasat, Alireza and Nikolaev, Alexander and Miller, Suzanne and Gopalsamy, Rahul",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053990,9.78145E+12,"massive open online courses., crowdlearning, problem posing, intelligent tutoring systems, learning technologies, collaborative learning","Cambridge, Massachusetts, USA",4,221?€?224,Association for Computing Machinery,L@S '17,CROWDLEARNING: Towards Collaborative Problem-Posing at Scale,https://doi.org/10.1145/3051457.3053990,2017
inproceedings,10.1145/3051457.3053991,"Massive Online Open Courses (MOOCs) are making low cost learning opportunities available at large scale to diverse groups of learners. For that reason, MOOCs need to be accessible so that they can offer flexibility of learning and benefits to all. In order to direct efforts towards developing accessible MOOCs, it is important to understand the current expectations of disabled learners. Analysis of data from MOOC surveys that support disclosure of disability provide quantitative information such as the proportions participating in MOOCs; their reasons for participating, and the types of MOOCs they prefer. This paper presents analysis of pre- and post-study survey data from eight MOOCs offered by the UK's Open University on the FutureLearn platform. Results from disabled learners are compared with those of other learners and preliminary findings are used to frame an agenda for our further work.","New York, NY, USA",,"Iniesto, Francisco and McAndrew, Patrick and Minocha, Shailey and Coughlan, Tim",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053991,9.78145E+12,"instructional design, accessibility, mooc, elearning, universal design","Cambridge, Massachusetts, USA",4,225?€?228,Association for Computing Machinery,L@S '17,What Are the Expectations of Disabled Learners When Participating in a MOOC?,https://doi.org/10.1145/3051457.3053991,2017
inproceedings,10.1145/3051457.3053992,"This paper demonstrates the viability of using Bayesian hypothesis testing for statistical analysis of experiments run in online learning systems. An empirical Bayesian method for learning a genuine prior from past historical experiment data is applied to a dataset consisting of twenty-two randomized controlled A/B experiments collected from the ASSISTments online learning platform. We show that using only twenty-two experiments results in a learned genuine prior with poor confidence interval estimates, and that roughly 200 experiments are required for a reasonable estimate of the true probability of an experiment having differences between experiment groups. We also conducted a leave-one-experiment-out cross-validation experiment, where a genuine prior is learned from twenty-one of the randomized controlled experiments provided in the dataset and then used to evaluate the remaining experiment. From this experiment we show that Bayesian hypothesis testing performs similar to Frequentist hypothesis testing and both methods were in agreement.","New York, NY, USA",,"Dommeti, Vijaya and Selent, Douglas",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053992,9.78145E+12,"bayesian hypothesis testing, assistments, randomized controlled trials, large scale experimentation","Cambridge, Massachusetts, USA",4,229?€?232,Association for Computing Machinery,L@S '17,Applying and Exploring Bayesian Hypothesis Testing for Large Scale Experimentation in Online Tutoring Systems,https://doi.org/10.1145/3051457.3053992,2017
inproceedings,10.1145/3051457.3053993,"There is an indisputable need for evidence-based instructional designs that create the optimal conditions for learners with different knowledge, skills and motivations to succeed in MOOCs. The study explores the technological feasibility and implications of adaptive functionality to course (re)design in the edX platform. Additionally, the study aims to establish the foundation for future study of adaptive functionality in MOOCs on learning outcomes, engagement and course drop-out rates. Preliminary findings suggest that the adaptivity of this kind leads to a higher efficiency of learning: students go through the course faster and attempt fewer problems, since the problems are served to them in a targeted way. And yet there is no evidence that the students' overall performance in the course suffers. Further research is needed to explore additional facets of adaptive assessment in different contexts of MOOCs and the effects on learning outcomes.","New York, NY, USA",,"Rosen, Yigal and Rushkin, Ilia and Ang, Andrew and Federicks, Colin and Tingley, Dustin and Blink, Mary Jean",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053993,9.78145E+12,"moocs, adaptive learning, assessment, adaptive assessment","Cambridge, Massachusetts, USA",4,233?€?236,Association for Computing Machinery,L@S '17,Designing Adaptive Assessments in MOOCs,https://doi.org/10.1145/3051457.3053993,2017
inproceedings,10.1145/3051457.3053994,"National guidelines advocate for a more sophisticated STEM education that integrates complex and authentic scientific practices, e.g., experimentation, data collection, data analysis, and modeling. How to achieve that is currently unclear for both presential and distance education. We recently developed a scalable cloud lab that enables many online users to perform phototaxis experiment with real, living Euglena cells (opposed to just simulations). Here we iteratively designed and deployed an open course on the edX platform including suitable user interfaces that facilitates inquiry-based learning on this cloud lab: Online students (&gt;300) run real experiments (&gt;2,300), performed data analysis, explored models, and even formulated and experimentally tested their own hypotheses. Platform and course content are now suited for global adaptation in formal K-16 education. We will demo our cloud lab at the conference.","New York, NY, USA",,"Hossain, Zahid and Bumbacher, Engin and Blikstein, Paulo and Riedel-Kruse, Ingmar",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053994,9.78145E+12,"data analysis, edx, learning analytics, cloud lab, life science, interactive biotechnology, biology, user studies, mooc, user interface, modeling, inquiry-based learning, remote experimentation, euglena, phototaxis, education","Cambridge, Massachusetts, USA",4,237?€?240,Association for Computing Machinery,L@S '17,Authentic Science Inquiry Learning at Scale Enabled by an Interactive Biology Cloud Experimentation Lab,https://doi.org/10.1145/3051457.3053994,2017
inproceedings,10.1145/3051457.3053995,"Mathematical word problems (or story problems) allow students to apply their mathematical problem solving ability to other subjects and real-world situations. Word problems build higher-order thinking, critical problem-solving, and reasoning skills. Generally solving a word problem is associated with mathematical modeling of a real word situation or a concept of another subject which is embedded in the problem. Manually creating word problems require knowledge of other topics a student is learning in parallel. Besides this, modeling mathematics with some other dissociated concept is a time-consuming and labor-intensive task. Due to lack of this integrated knowledge of other topics being taught, the substantive breadth of word problems is often very narrow and is limited to very few concepts. To address this limitation, we built a tool called Intelligent Math Tutor (IMT), which automatically generates mathematical word problems such that teachings from other subjects from a given curriculum can also be incorporated. Our tool thus widens the scope of word problems and uses this problem-solving based approach to indirectly create cognizance in its students. To the best of our knowledge, our tool is the first of its kind tool which explicitly blends knowledge from multiple dissociated subjects and uses it to enhance the cognizance of its learners.","New York, NY, USA",,"Gupta, Monika and Gantayat, Neelamadhav and Sindhgatta, Renuka",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053995,9.78145E+12,"concept mapping, mathematical word problems, integrated curriculum, intelligent math tutor","Cambridge, Massachusetts, USA",4,241?€?244,Association for Computing Machinery,L@S '17,Intelligent Math Tutor: Problem-Based Approach to Create Cognizance,https://doi.org/10.1145/3051457.3053995,2017
inproceedings,10.1145/3051457.3053996,"An important, yet largely unstudied, problem in student data analysis is to detect misconceptions from students' responses to open-response questions. Misconception detection enables instructors to deliver more targeted feedback on the misconceptions exhibited by many students in their class, thus improving the quality of instruction. In this paper, we propose a new natural language processing (NLP) framework to detect the common misconceptions among students' textual responses to open-response, short-answer questions. We introduce a probabilistic model for students' textual responses involving misconceptions and experimentally validate it on a real-world student-response dataset. Preliminary experimental results show that our proposed framework excels at classifying whether a response exhibits one or more misconceptions. More importantly, it can also automatically detect the common misconceptions exhibited across responses from multiple students to multiple questions; this is especially important at large scale, since instructors will no longer need to manually specify all possible misconceptions that students might exhibit.","New York, NY, USA",,"Michalenko, Joshua J. and Lan, Andrew S. and Baraniuk, Richard G.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053996,9.78145E+12,"markov chain monte carlo, natural language processing, learning analytics","Cambridge, Massachusetts, USA",4,245?€?248,Association for Computing Machinery,L@S '17,Data-Mining Textual Responses to Uncover Misconception Patterns,https://doi.org/10.1145/3051457.3053996,2017
inproceedings,10.1145/3051457.3053997,"Teaching software development teams can be difficult to scale. Based on various cloud-based software development tools, Teamscope provides automated or semi-automated metrics to improve the scalability of a course with team projects. Metrics developed in Teamscope provide a synthesized view of a student team. Our preliminary results have shown the validity of these metrics. We also present a case study of applying metrics to teaching software development course in this paper.","New York, NY, USA",,"Ju, An and Glassman, Elena and Fox, Armando",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053997,9.78145E+12,"massive courses, education, process conformance, software engineering","Cambridge, Massachusetts, USA",4,249?€?252,Association for Computing Machinery,L@S '17,"Teamscope: Scalable Team Evaluation via Automated Metric Mining for Communication, Organization, Execution, and Evolution",https://doi.org/10.1145/3051457.3053997,2017
inproceedings,10.1145/3051457.3053998,"Team project, which emphasizes collaborative learning in a project-based context, is one of the most commonly-used teaching and learning methods in higher education classrooms, but is not well-supported on existing Massive Open Online Course (MOOC) platforms. In this paper, we present ProjectLens, a MOOC supplement tool that supports team projects building and collaborative learning on MOOC platforms like Coursera and edX. In addition, ProjectLens is a research tool that provides opportunities to conduct large-scale field experiments to study how different factors influence the effectiveness of collaborative learning. We illustrate how ProjectLens can achieve these two goals in a case example.","New York, NY, USA",,"Cheng, Hao Fei and Yu, Bowen and Park, Yeong Hoon and Zhu, Haiyi",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053998,9.78145E+12,"massive open online courses, collaborative learning, moocs, group collaboration","Cambridge, Massachusetts, USA",4,253?€?256,Association for Computing Machinery,L@S '17,ProjectLens: Supporting Project-Based Collaborative Learning on MOOCs,https://doi.org/10.1145/3051457.3053998,2017
inproceedings,10.1145/3051457.3053999,"Manually providing feedback for programming assignments is a tedious task in traditional classroom education. The challenge increases drastically in Massive open online courses (MOOCs), where the student-teacher ratio can reach thousands to one or even millions to one. Despite the necessity, the current automated feedback approaches suffer from significant weaknesses: inability to scale to larger programs, manual involvement of teacher effort, and lack of precision for pin-pointing errors. We present a technique to tackle these challenges by developing a data-driven automated grader, iGrader, capable of generating instant and precise feedback for programming assignments.","New York, NY, USA",,"Wang, Ke and Lin, Benjamin and Rettig, Bjorn and Pardi, Paul and Singh, Rishabh",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3053999,9.78145E+12,"abstract syntax tree, education, automated program repair, edx, massive open online courses, control flow matching, c#","Cambridge, Massachusetts, USA",4,257?€?260,Association for Computing Machinery,L@S '17,Data-Driven Feedback Generator for Online Programing Courses,https://doi.org/10.1145/3051457.3053999,2017
inproceedings,10.1145/3051457.3054000,"One of the initial promises of MOOCs was to enable participants from around the world to learn and build knowledge together, however existing MOOC platforms are very limited in their collaborative functionality. Using a recent educational modeling language which can express a broad diversity of educational scenarios, we present a technical infrastructure design and prototype which enables instructors to design and run pedagogically rich and therefore complex scenarios. We present this as a theoretical and technical contribution to support a broad program of research and innovation related to collaborative learning at scale.","New York, NY, USA",,"H\r{a}klev, Stian and Faucon, Louis and Hadzilacos, Thanasis and Dillenbourg, Pierre",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054000,9.78145E+12,"moocs, orchestration., scripting","Cambridge, Massachusetts, USA",4,261?€?264,Association for Computing Machinery,L@S '17,Orchestration Graphs: Enabling Rich Social Pedagogical Scenarios in MOOCs,https://doi.org/10.1145/3051457.3054000,2017
inproceedings,10.1145/3051457.3054001,"This paper describes methods for enhancing the experience application program interface (xAPI) to improve the assessment of domain competency modeling for adaptive instruction. xAPI is an e-learning software specification which allows individual learning experiences and achievements to be amassed in a Learning Record Store (LRS). Adaptive instruction includes tailored training or educational experiences usually delivered and guided by Intelligent Tutoring Systems (ITSs). ITSs can more effectively tailor or adapt instruction when they have more accurate models of the learner's prior knowledge or competency. This paper examines the potential effect of methods to more accurately model learner experiences and domain competency in an LRS. Specifically, we recommend five methods to improve xAPI statements by documenting: 1) achievement types; 2) experience duration; 3) experience source information; 4) domain learning and forgetting; and 5) assessment within learning experiences.","New York, NY, USA",,"Sottilare, Robert A. and Long, Rodney A. and Goldberg, Benjamin S.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054001,9.78145E+12,"distance learning, experience application program interface (xapi), mobile learning, intelligent tutoring system (its), competency modeling, adaptive instruction, learning record store (lrs), distributed learning","Cambridge, Massachusetts, USA",4,265?€?268,Association for Computing Machinery,L@S '17,Enhancing the Experience Application Program Interface (XAPI) to Improve Domain Competency Modeling for Adaptive Instruction,https://doi.org/10.1145/3051457.3054001,2017
inproceedings,10.1145/3051457.3054002,"Feature extraction and model selection are two essential processes when building predictive models of student success. In this work we describe and demonstrate a statistical approach to both tasks, comparing five modeling techniques (a lasso penalized logistic regression model, na\""{\i}ve Bayes, random forest, SVM, and classification tree) across three sets of features (week-only, summed, and appended). We conduct this comparison on a dataset compiled from 30 total offerings of five different MOOCs run on the Coursera platform. Through the use of the Friedman test with a corresponding post-hoc Nemenyi test, we present comparative performance results for several classifiers across the three different feature extraction methods, demonstrating a rigorous inferential process intended to guide future analyses of student success systems.","New York, NY, USA",,"Gardner, Josh and Brooks, Christopher",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054002,9.78145E+12,"model evaluation, mooc, predictive modeling, machine learning","Cambridge, Massachusetts, USA",4,269?€?272,Association for Computing Machinery,L@S '17,A Statistical Framework for Predictive Model Evaluation in MOOCs,https://doi.org/10.1145/3051457.3054002,2017
inproceedings,10.1145/3051457.3054003,"Creativity has long been suggested as an important factor in learning. In this paper, we present a preliminary study of creativity in an online programming learning environment. We operationalize creativity using an existing scheme for scoring it, and then measure it automatically based on the system log files. We analyze the data in order to explore the associations between creativity and personal/contextual variables. Creativity is associated with contextual variables and is not associated with personal variables. Directions for continuing this research are discussed.","New York, NY, USA",,"Gal, Lilach and Hershkovitz, Arnon and Mor\'{a}n, Andoni Egu\'{\i}luz and Guenaga, Mariluz and Garaizar, Pablo",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054003,9.78145E+12,"learning analytics., log-based measurement, creativity, programming learning","Cambridge, Massachusetts, USA",5,273?€?277,Association for Computing Machinery,L@S '17,Suggesting a Log-Based Creativity Measurement for Online Programming Learning Environment,https://doi.org/10.1145/3051457.3054003,2017
inproceedings,10.1145/3051457.3054004,"Many studies demonstrate that peer reviewing provides pedagogical benefits such as inspiration and developing expert vision, and changes classroom culture by encouraging reciprocity. However, much large-scale research in peer assessment has focused on MOOCs, where students have short tenures, and is unable to describe how reciprocity-oriented classroom cultures evolve over time. This short paper presents the first long-term analysis of peer reviewing with 304 students, conducted in three large physical classes in a year-long undergraduate series. Surprisingly, this analysis reveals that when students receive better reviews on their work, they write worse reviews in the future. This suggests that while students believe in the reciprocal nature of peer review, they act anti-reciprocally. Therefore, battling the emergent norm of anti-reciprocity is crucial both for system designers and practitioners who use peer assessment.","New York, NY, USA",,"Kotturi, Yasmine and Du, Andrew and Klemmer, Scott and Kulkarni, Chinmay",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054004,9.78145E+12,"peer review, peer assessment, reciprocity","Cambridge, Massachusetts, USA",4,279?€?282,Association for Computing Machinery,L@S '17,Long-Term Peer Reviewing Effort is Anti-Reciprocal,https://doi.org/10.1145/3051457.3054004,2017
inproceedings,10.1145/3051457.3054005,"There is an emerging trend in higher education for the adoption of massive open online courses (MOOCs). However, despite this interest in learning at scale, there has been limited work investigating how MOOC participants have changed over time. In this study, we explore the temporal changes in MOOC learners' language and discourse characteristics. In particular, we demonstrate that there is a clear trend within a course for language in discussion forums to be of both more on-topic and reflective of deep learning in subsequent offerings of a course. We measure this in two ways, and demonstrate this trend through several repeated analyses of different courses in different domains. While not all courses show an increase beyond statistical significance, the majority do, providing evidence that MOOC learner populations are changing as the educational phenomena matures.","New York, NY, USA",,"Dowell, Nia M.M. and Brooks, Christopher and Kovanovi\'{c}, Vitomir and Joksimovi\'{c}, Sre\'{c}ko and Ga\v{s}evi\'{c}, Dragan",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054005,9.78145E+12,"learning at scale, discussion forums, discourse complexity, on-topic discussion, moocs","Cambridge, Massachusetts, USA",4,283?€?286,Association for Computing Machinery,L@S '17,The Changing Patterns of MOOC Discourse,https://doi.org/10.1145/3051457.3054005,2017
inproceedings,10.1145/3051457.3054006,"Randomized experiments in online educational environments are ubiquitous as a scientific method for investigating learning and motivation, but too rarely improve educational resources and produce practical benefits for learners. We suggest that software and tools for experimentally comparing resources are designed primarily through the lens of experiments as a scientific methodology, and therefore miss a tremendous opportunity for online experiments to serve as engines for dynamic improvement and personalization. We present the MOOClet requirements specification to guide the implementation of software or tools for experiments to ensure that whenever alternative versions of a resource can be experimentally compared (by randomly assigning versions), the resource can also be dynamically improved (by changing which versions are presented), and personalized (by presenting different versions to different people). The MOOClet specification was used to implement DEXPER, a proof-of-concept web service backend that enables dynamic experimentation and personalization of resources embedded in front-end educational platforms. We describe three use cases of MOOClets for dynamic experimentation and personalization of motivational emails, explanations, and problems.","New York, NY, USA",,"Williams, Joseph Jay and Rafferty, Anna N. and Maldonado, Samuel and Ang, Andrew and Tingley, Dustin and Kim, Juho",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054006,9.78145E+12,"personalization, reinforcement learning, mooclet, multi-armed bandit, dynamic experimentation, a/b experiment, statistical machine learning, adaptive learning","Cambridge, Massachusetts, USA",4,287?€?290,Association for Computing Machinery,L@S '17,MOOClets: A Framework for Dynamic Experimentation and Personalization,https://doi.org/10.1145/3051457.3054006,2017
inproceedings,10.1145/3051457.3054007,"We have designed a Molecular Biology massive open online course (MOOC) for a global audience. Among the learning aids offered are two types of short video segments: lecture videos (delivered unscripted by a professor) and deep dives (fully scripted and animated). While the engaged learners overwhelmingly watched the lecture video segments through to completion, some watched only a portion of each deep dive. As the deep dives take pains to follow evidence-based best practices and are more labor-intensive to make, further study of this difference in viewer retention would inform future course development decisions. Notably, course organization, length of video, lack of on-screen narrator, and identity of narrator show no correlation with this trend. Interestingly, learners who complete lecture videos but not deep dives have slightly higher overall course grades on average. Thus, our model is that learners with a higher degree of knowledge about the subject matter may feel that they do not need to complete the deep dive videos, while they feel the lecture videos are valuable. Future research will test this model.","New York, NY, USA",,"Thornton, Sera and Riley, Ceri and Wiltrout, Mary Ellen",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054007,9.78145E+12,"online education, video engagement, biology, mooc","Cambridge, Massachusetts, USA",4,291?€?294,Association for Computing Machinery,L@S '17,Criteria for Video Engagement in a Biology MOOC,https://doi.org/10.1145/3051457.3054007,2017
inproceedings,10.1145/3051457.3054008,"Extant research suggests that learner engagement in discussion forums is positively correlated with learner performance. In this paper we investigate which types of forum engagement are most strongly associated with final performance in MOOC courses. In particular, we compare the correlation between course final grade and two types of learner engagement: direct measures, which count the number of interactions, and indirect measures, which capture learners position in a social network. We found that direct measures have stronger correlations with final grade. However, in preliminary analyses, we also found that course instructors score higher than learners on some indirect measures. We discuss the implications of these findings and our plans for developing the work further in the future.","New York, NY, USA",,"Houston, Stacey L. and Brady, Katherine and Narasimham, Gayathri and Fisher, Douglas",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054008,9.78145E+12,"course performance, social network analysis, moocs","Cambridge, Massachusetts, USA",4,295?€?298,Association for Computing Machinery,L@S '17,"Pass the Idea Please: The Relationship between Network Position, Direct Engagement, and Course Performance in MOOCs",https://doi.org/10.1145/3051457.3054008,2017
inproceedings,10.1145/3051457.3054009,"The incorporation of computer-based platforms in the classroom has introduced the ability to conduct numerous randomized control trials at scale with student-level randomization. Such systems are able to collect vast amounts of data on each student while completing work in the classroom and at home. It is often the case, however, that the effects of these trials are reported across all students, ignoring the potential for personalized learning. Personalized learning, or the observation of heterogeneous treatment effects, considers that the effects of a studied learning intervention may differ for individual students; while an intervention may work well for low-performing students, for example, it may have no effect for higher performing students. Personalized learning can lead to better instructional practices that maximizes the learning benefits for each individual student, and with the use of computer-based platforms, such individualized instruction is made feasible at scale. In this work we use a causal decision tree to observe treatment effects in 9 experiments run in the ASSISTments online learning platform.","New York, NY, USA",,"Yin, Biao and Patikorn, Thanaporn and Botelho, Anthony F. and Heffernan, Neil T.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054009,9.78145E+12,"causal tree, heterogeneous treatment effects, personalization, randomized controlled trials","Cambridge, Massachusetts, USA",4,299?€?302,Association for Computing Machinery,L@S '17,Observing Personalizations in Learning: Identifying Heterogeneous Treatment Effects Using Causal Trees,https://doi.org/10.1145/3051457.3054009,2017
inproceedings,10.1145/3051457.3054010,"One of the main factors affecting the success and effectiveness of Massive Open Online Courses is the ability of the instructor to acquire and incorporate student feedback in a timely manner, and preferably before assigning grades to student assessments. This research uses raw clickstream data from video watching sessions of the Coursera MOOC: ""Text Retrieval and Search Engines"" to discover which topics are difficult for the students. We introduce a measure for topic difficulty based on these clickstream events, and rank the topics according to this measure. The validity of our ranking is evaluated by comparing it with the ranking of topics based on student votes and find that our method agrees with the ranking based on student votes with &gt; 63% accuracy.","New York, NY, USA",,"Boughoula, Assma and Geigle, Chase and Zhai, ChengXiang",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054010,9.78145E+12,"probabilistic clustering, student feedback, topic difficulty","Cambridge, Massachusetts, USA",4,303?€?306,Association for Computing Machinery,L@S '17,A Probabilistic Approach for Discovering Difficult Course Topics Using Clickstream Data,https://doi.org/10.1145/3051457.3054010,2017
inproceedings,10.1145/3051457.3054011,"In January 2017, Georgia Tech launched a new online section of its CS1301: Introduction to Computing class. The course, offered both as a for-credit course to on-ground students and as an open MOOC, built on four unique design principles: congruency, adaptivity, modularity, and personalization. In this short paper, we describe the background of the course, the definitions of these design principles, and their application to the course design.","New York, NY, USA",,"Joyner, David A.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054011,9.78145E+12,"personalized learning, moocs., computing education","Cambridge, Massachusetts, USA",4,307?€?310,Association for Computing Machinery,L@S '17,"Congruency, Adaptivity, Modularity, and Personalization: Four Experiments in Teaching Introduction to Computing",https://doi.org/10.1145/3051457.3054011,2017
inproceedings,10.1145/3051457.3054012,"While most existing research knowledge is distributed in the form of papers, there has been a shift towards learning and consuming information through video. Limited time and resources, however, prevent individual researchers from making their work available in this format. Crowdsourcing this task is a promising alternative, but it requires solving complex coordination and collaborative video production problems. In this paper, we propose an end-to-end solution to crowdsource the creation of research videos. To assist coordination, we designed a structured workflow that enables efficient delegation of tasks, while also providing a collaborative learning environment to the crowd for motivation. To facilitate video production, we developed an online system through which groups can make micro audio recordings that are automatically stitched together to create a complete talk. We tested this approach with a group of volunteers recruited from 24 countries through an open call. This distributed crowd produced five video talks based on the best paper winners and nominees from WWW 2016. Evaluations from the authors of the papers and outside reviewers rated the talks ""very good"" (giving a median score of 4 out of 5). We further applied this method to translate these talks and produce 11 additional videos in Spanish, Romanian, and Catalan. These results suggest that our crowdsourcing approach has the potential to significantly increase learning and the accessibility of the scientific knowledge.","New York, NY, USA",,"Vaish, Rajan and Goel, Sharad and Saberi, Amin",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054012,9.78145E+12,"peer video production, scientific knowledge/learning at scale., crowdsourcing, online creative collaboration","Cambridge, Massachusetts, USA",4,311?€?314,Association for Computing Machinery,L@S '17,Mobilizing the Crowd to Create an Open Repository of Research Talks,https://doi.org/10.1145/3051457.3054012,2017
inproceedings,10.1145/3051457.3054013,"Massive Open Online Courses (MOOCs) use peer assessment to grade open ended questions at scale, allowing students to provide feedback. Relative to teacher based grading, peer assessment on MOOCs traditionally delivers lower quality feedback and fewer learner interactions. We present the identified peer review (IPR) framework, which provides non-blind peer assessment and incentives driving high quality feedback. We show that, compared to traditional peer assessment methods, IPR leads to significantly longer and more useful feedback as well as more discussion between peers.","New York, NY, USA",,"Gamage, Dilrukshi and Whiting, Mark E. and Rajapakshe, Thejan and Thilakarathne, Haritha and Perera, Indika and Fernando, Shantha",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054013,9.78145E+12,"peer assessment, massive open online courses, peer review, mooc","Cambridge, Massachusetts, USA",4,315?€?318,Association for Computing Machinery,L@S '17,Improving Assessment on MOOCs Through Peer Identification and Aligned Incentives,https://doi.org/10.1145/3051457.3054013,2017
inproceedings,10.1145/3051457.3054014,"Determining affective states such as confusion from students' participation in online discussion forums can be useful for instructors of a large classroom. However, manual annotation of forum posts by instructors or paid crowd workers is both time-consuming and expensive. In this work, we harness affordances prevalent in social media to allow students to self-annotate their discussion posts with a set of hashtags and emojis, a process that is fast and cheap. For students, self-annotation with hashtags and emojis provides another channel for self-expression, as well as a way to signal to instructors and other students on the lookout for certain types of messages. This method also provides an easy way to acquire a labeled dataset of affective states, allowing us distinguish between more nuanced emotions such as confusion and curiosity. From a dataset of over 25,000 discussion posts from two courses containing self-annotated posts by students, we demonstrate how we can identify linguistic differences between posts expressing confusion versus curiosity, achieving 83% accuracy at distinguishing between the two affective states.","New York, NY, USA",,"Zhang, Amy X. and Igo, Michele and Facciotti, Marc and Karger, David",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054014,9.78145E+12,"confusion, emojis, curiosity, massive open online courses (moocs), forums, hashtags, emotion, online discussion","Cambridge, Massachusetts, USA",4,319?€?322,Association for Computing Machinery,L@S '17,Using Student Annotated Hashtags and Emojis to Collect Nuanced Affective States,https://doi.org/10.1145/3051457.3054014,2017
inproceedings,10.1145/3051457.3054015,"In formative assessments, one wants to provide a useful feedback to the examinee at the end of the test. In order to reduce the number of questions asked in an assessment, adaptive testing models have been developed for cognitive diagnosis, such as the ones encountered in knowledge space theory. However, when the number of skills assessed is very huge, such methods cannot scale. In this paper, we present a new method to provide adaptive tests and useful feedback to the examinee, even with large databases of skills. It will be used in Pix, a platform for certification of digital competencies for every French citizen.","New York, NY, USA",,"Vie, Jill-J\^{e}nn and Popineau, Fabrice and Tort, Fran\c{c}oise and Marteau, Benjamin and Denos, Nathalie",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054015,9.78145E+12,"knowledge components, cognitive diagnosis, q-matrices, knowledge space theory, item response theory, adaptive testing","Cambridge, Massachusetts, USA",4,323?€?326,Association for Computing Machinery,L@S '17,A Heuristic Method for Large-Scale Cognitive-Diagnostic Computerized Adaptive Testing,https://doi.org/10.1145/3051457.3054015,2017
inproceedings,10.1145/3051457.3054016,"Viewing consumption of discussion forums with hundreds or more comments depends on ranking because most users only view top-ranked comments. When comments are ranked by an ordered score (e.g. number of replies or up-votes) without adjusting for semantic similarity of near-ranked comments, top-ranked comments are more likely to emphasize the majority opinion and incur redundancy. In this paper, we propose a top K comment diversification re-ranking model using Maximal Marginal Relevance (MMR) and evaluate its impact in three categories: (1) semantic diversity, (2) inclusion of the semantics of lower-ranked comments, and (3) redundancy, within the context of a HarvardX course discussion forum. We conducted a double-blind, small-scale evaluation experiment requiring subjects to select between the top 5 comments of a diversified ranking and a baseline ranking ordered by score. For three subjects, across 100 trials, subjects selected the diversified (75% score, 25% diversification) ranking as significantly (1) more diverse, (2) more inclusive, and (3) less redundant. Within each category, inter-rater reliability showed moderate consistency, with typical Cohen-Kappa scores near 0.2. Our findings suggest that our model improves (1) diversification, (2) inclusion, and (3) redundancy, among top K ranked comments in discussion forums of online courses.","New York, NY, USA",,"Northcutt, Curtis G. and Leon, Kimberly A. and Chen, Naichun",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054016,9.78145E+12,"online courses, discussion forum, embeddings, information retrieval, search, ranking diversification","Cambridge, Massachusetts, USA",4,327?€?330,Association for Computing Machinery,L@S '17,Comment Ranking Diversification in Forum Discussions,https://doi.org/10.1145/3051457.3054016,2017
inproceedings,10.1145/3051457.3054017,"Few MOOCs offer laboratory work as part of their educational material, yet it is known that hands-on sessions are important components of science and engineering education. Equally important is understanding how students are using labs as part of their learning activity outside the constraints of space and time. In this work we present the initial results of the usage of a remote lab provided as part of a Control Systems MOOC.","New York, NY, USA",,"Halimi, Wissam and Salzmann, Christophe and Gillet, Denis",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054017,9.78145E+12,"remote labs, online education, massive open online labs, engineering education, mool, mooc","Cambridge, Massachusetts, USA",4,331?€?334,Association for Computing Machinery,L@S '17,Access to Massive Open Online Labs through a MOOC,https://doi.org/10.1145/3051457.3054017,2017
inproceedings,10.1145/3051457.3054018,"With the development of ""flipped classroom"" concept and increasing usage of web-based learning platforms in foreign language teaching field, the effectiveness of online instant feedback come into researchers' focus, and whether or not teachers should provide choices of feedback medium also becomes an issue. The following study assesses the effects of feedback medium as well as the effectiveness of offering students feedback medium choices. This in-progress large-scale randomized controlled trial is conducted using ASSISTments, an adaptive online tutoring platform.","New York, NY, USA",,"Lu, Xiwen and Xiong, Xiaolu and Heffernan, Neil T.",Proceedings of the Fourth (2017) ACM Conference on Learning @ Scale,10.1145/3051457.3054018,9.78145E+12,"randomized controlled trial, language learning, flipped classroom, feedback, e-learning, assistments","Cambridge, Massachusetts, USA",4,335?€?338,Association for Computing Machinery,L@S '17,Experimenting Choices of Video and Text Feedback in Authentic Foreign Language Assignments at Scale,https://doi.org/10.1145/3051457.3054018,2017
inproceedings,10.1145/2876034.2876045,"In this study, we develop methods for computationally measuring the degree to which students engage in MOOC forums with other students holding different political beliefs. We examine a case study of a single MOOC about education policy, Saving Schools, where we obtain measures of student education policy preferences that correlate with political ideology. Contrary to assertions that online spaces often become echo chambers or ideological silos, we find that students in this case hold diverse political beliefs, participate equitably in forum discussions, directly engage (through replies and upvotes) with students holding opposing beliefs, and converge on a shared language rather than talking past one another. Research that focuses on the civic mission of MOOCs helps ensure that open online learning engages the same breadth of purposes that higher education aspires to serve.","New York, NY, USA",,"Reich, Justin and Stewart, Brandon and Mavon, Kimia and Tingley, Dustin",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876045,9.78145E+12,"text analysis, moocs, civic education, structural topic model, political ideology, discourse","Edinburgh, Scotland, UK",10,1?€?10,Association for Computing Machinery,L@S '16,The Civic Mission of MOOCs: Measuring Engagement across Political Differences in Forums,https://doi.org/10.1145/2876034.2876045,2016
inproceedings,10.1145/2876034.2876046,"Extensive work focuses on the uses of technology at scale for post-literate populations (e.g., MOOC, learning games, Learning Management Systems). Little attention is afforded to non-literate populations, particularly in the developing world. This paper presents an approach using mobile devices with the ultimate goal to reach 770 million people. We developed a novel platform with a cloud backend to deliver educational content to over a thousand marginalized children in different countries: specifically, in remote villages without schools, urban slums with overcrowded schools, and at-risk, rural schools. Here we describe the theoretical basis of our system and results from case studies in three educational contexts. This model will help researchers and designers understand how mobile devices can help children acquire basic skills and aid each other's learning when the benefit of teachers is limited or non-existent.","New York, NY, USA",,"Breazeal, Cynthia and Morris, Robin and Gottwald, Stephanie and Galyean, Tinsley and Wolf, Maryanne",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876046,9.78145E+12,"pre-k learning and technology, open platform for education, early literacy, global literacy project, virtual preschool, reading brain","Edinburgh, Scotland, UK",10,11?€?20,Association for Computing Machinery,L@S '16,Mobile Devices for Early Literacy Intervention and Research with Global Reach,https://doi.org/10.1145/2876034.2876046,2016
inproceedings,10.1145/2876034.2876052,"Online communities continue to be an important resource for informal learning. Although many facets of online learning communities have been studied, we have limited understanding of how such communities grow over time to productively engage a large number of learners. In this paper we present a study of a large online community called Scratch which was created to help users learn software programming. We analyzed 5 years of data consisting of 1 million users and their 1.9 million projects. Examination of interactional patterns among highly active members of the community uncovered a markedly temporal dimension to participation. As membership of the Scratch online community grew over time, interest-based subcultures started to emerge. This pattern was uncovered even when clustering was based solely on social network of members. This process, which closely resembles urbanism or the growth of physically populated areas, allowed new members to combine their interests with programming.","New York, NY, USA",,"Gelman, Ben U. and Beckley, Chris and Johri, Aditya and Domeniconi, Carlotta and Yang, Seungwon",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876052,9.78145E+12,"interest-based subcultures, programming., informal learning, online communities, scratch","Edinburgh, Scotland, UK",10,21?€?30,Association for Computing Machinery,L@S '16,Online Urbanism: Interest-Based Subcultures as Drivers of Informal Learning in an Online Community,https://doi.org/10.1145/2876034.2876052,2016
inproceedings,10.1145/2876034.2876041,"Online courses on sites such as Coursera use quizzes embedded inside lecture videos (in-video quizzes) to help learners test their understanding of the video. This paper analyzes how users interact with in-video quizzes, and how in-video quizzes influence users' lecture viewing behavior. We analyze the viewing logs of users who took the Machine Learning course on Coursera. Users engage heavily with in-video quizzes -- 74% of viewers who start watching a video will attempt its corresponding in-video quiz. We observe spikes in seek activity surrounding in-video quizzes, particularly seeks from the in-video quiz to the preceding section. We show that this is likely due to users reviewing the preceding section to help them answer the quiz, as the majority of users who seek backwards from in-video quizzes have not yet submitted a correct answer, but will later attempt the quiz. Some users appear to use quiz-oriented navigation strategies, such as seeking directly from the start of the video to in-video quizzes, or skipping from one quiz to the next. We discuss implications of our findings on the design of lecture-viewing platforms.","New York, NY, USA",,"Kovacs, Geza",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876041,9.78145E+12,"lecture viewing, seeking behaviors, lecture navigation, in-video quizzes, moocs","Edinburgh, Scotland, UK",10,31?€?40,Association for Computing Machinery,L@S '16,Effects of In-Video Quizzes on MOOC Lecture Viewing,https://doi.org/10.1145/2876034.2876041,2016
inproceedings,10.1145/2876034.2876040,"Student retention is a central challenge in systems for learning at scale. It has been argued that educational video games could improve student retention by providing engaging experiences and informing the design of other online learning environments. However, educational games are not uniformly effective. Our recent research shows that player retention can be increased by using a brain points incentive structure that rewards behaviors associated with growth mindset, or the belief that intelligence can grow. In this paper, we expand on our prior work by providing new insights into how growth mindset behaviors can be effectively promoted in the educational game Refraction. We present results from an online study of 25,000 children who were exposed to five different versions of the brain points intervention. We find that growth mindset animations cause a large number of players to quit, while brain points encourage persistence. Most importantly, we find that awarding brain points randomly is ineffective; the incentive structure is successful specifically because it rewards desirable growth mindset behaviors. These findings have important implications that can support the future generalization of the brain points intervention to new educational contexts.","New York, NY, USA",,"O'Rourke, Eleanor and Peach, Erin and Dweck, Carol S. and Popovic, Zoran",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876040,9.78145E+12,"incentive structures., growth mindset, educational games","Edinburgh, Scotland, UK",10,41?€?50,Association for Computing Machinery,L@S '16,Brain Points: A Deeper Look at a Growth Mindset Incentive Structure for an Educational Game,https://doi.org/10.1145/2876034.2876040,2016
inproceedings,10.1145/2876034.2876051,"Understanding why and how students interact with educational videos is essential to further improve the quality of MOOCs. In this paper, we look at the complexity of videos to explain two related aspects of student behavior: the dwelling time (how much time students spend watching a video) and the dwelling rate (how much of the video they actually see). Building on a strong tradition of psycholinguistics, we formalize a definition for information complexity in videos. Furthermore, building on recent advancements in time-on-task measures we formalize dwelling time and dwelling rate based on click-stream trace data. The resulting computational model of video complexity explains 22.44% of the variance in the dwelling rate for students that finish watching a paragraph of a video. Video complexity and student dwelling show a polynomial relationship, where both low and high complexity increases dwelling. These results indicate why students spend more time watching (and possibly contemplating about) a video. Furthermore, they show that even fairly straightforward proxies of student behavior such as dwelling can already have multiple interpretations; illustrating the challenge of sense-making from learning analytics.","New York, NY, USA",,"Van der Sluis, Frans and Ginn, Jasper and Van der Zee, Tim",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876051,9.78145E+12,"learning analytics, dwelling time, moocs, student behavior., video, information complexity","Edinburgh, Scotland, UK",10,51?€?60,Association for Computing Machinery,L@S '16,Explaining Student Behavior at Scale: The Influence of Video Complexity on Student Dwelling Time,https://doi.org/10.1145/2876034.2876051,2016
inproceedings,10.1145/2876034.2876053,"In this talk, Sugata Mitra will take us through the origins of schooling as we know it, to the dematerialisation of institutions as we know them. Thirteen years of experiments in children's education takes us through a series of startling results -- children can self organise their own learning, they can achieve educational objectives on their own, can read by themselves. Finally, the most startling of them all: Groups of children with access to the Internet can learn anything by themselves.From the slums of India, to the villages of India and Cambodia, to poor schools in Chile, Argentina, Uruguay, the USA and Italy, to the schools of Gateshead and the rich international schools of Washington and Hong Kong, Sugata's experimental results show a strange new future for learning. Using the TED Prize, he has now built seven ""Schools in the Cloud"", of which some glimpses will be provided in the talk.","New York, NY, USA",,"Mitra, Sugata",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876053,9.78145E+12,,"Edinburgh, Scotland, UK",2,61?€?62,Association for Computing Machinery,L@S '16,The Future of Learning,https://doi.org/10.1145/2876034.2876053,2016
inproceedings,10.1145/2876034.2876037,"The study presented in this paper deals with copying answers in MOOCs. Our findings show that a significant fraction of the certificate earners in the course that we studied have used what we call harvesting accounts to find correct answers that they later submitted in their main account, the account for which they earned a certificate. In total, around 2.5% of the users who earned a certificate in the course obtained the majority of their points by using this method, and around 10% of them used it to some extent. This paper has two main goals. The first is to define the phenomenon and demonstrate its severity. The second is characterizing key factors within the course that affect it, and suggesting possible remedies that are likely to decrease the amount of cheating. The immediate implication of this study is to MOOCs. However, we believe that the results generalize beyond MOOCs, since this strategy can be used in any learning environments that do not identify all registrants.","New York, NY, USA",,"Ruiperez-Valiente, Jose A. and Alexandron, Giora and Chen, Zhongzhou and Pritchard, David E.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876037,9.78145E+12,"academic dishonesty, learning analytics, educational data mining, moocs","Edinburgh, Scotland, UK",8,63?€?70,Association for Computing Machinery,L@S '16,Using Multiple Accounts for Harvesting Solutions in MOOCs,https://doi.org/10.1145/2876034.2876037,2016
inproceedings,10.1145/2876034.2876039,"Nearly every adaptive learning system aims to present students with materials personalized to their level of understanding (Enyedy, 2014). Typically, such adaptation follows some form of mastery learning (Bloom, 1968), in which students are asked to master one topic before proceeding to the next topic. Mastery learning programs have a long history of success (Guskey and Gates, 1986; Kulik, Kulik &amp; Bangert-Drowns, 1990) and have been shown to be superior to alternative instructional approaches.Although there is evidence for the effectiveness of mastery learning when it is well supported by teachers, mastery learning's effectiveness is crucially dependent on the ability and willingness of teachers to implement it properly. In particular, school environments impose time constraints and set goals for curriculum coverage that may encourage teachers to deviate from mastery-based instruction.In this paper we examine mastery learning as implemented in Carnegie Learning's Cognitive Tutor. Like in all real-world systems, teachers and students have the ability to violate mastery learning guidance. We investigate patterns associated with violating and following mastery learning over the course of the full school year at the class and student level. We find that violations of mastery learning are associated with poorer student performance, especially among struggling students, and that this result is likely attributable to such violations of mastery learning.","New York, NY, USA",,"Ritter, Steve and Yudelson, Michael and Fancsali, Stephen E. and Berman, Susan R.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876039,9.78145E+12,"mastery learning, intelligent tutors, longitudinal data, big data, adaptive educational systems, educational outcomes","Edinburgh, Scotland, UK",9,71?€?79,Association for Computing Machinery,L@S '16,How Mastery Learning Works at Scale,https://doi.org/10.1145/2876034.2876039,2016
inproceedings,10.1145/2876034.2876048,"Massive online classes can benefit from peer interactions such as discussion, critique, or tutoring. However, to scaffold productive peer interactions, systems must be able to detect student behavior in interactions at scale, which is challenging when interactions occur over rich media like video. This paper introduces an imprecise yet simple browser-based conversational turn detector for video conversations. Turns are detected without accessing video or audio data. We show how this turn detector can find dominance in video-based conversations. In a case study with 1,027 students using Talkabout, a video-based discussion system for online classes, we show how detected conversational turn behavior correlates with participants' subjective experience in discussions and their final course grade.","New York, NY, USA",,"Stankiewicz, Adam and Kulkarni, Chinmay",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876048,9.78145E+12,"video discussions, turn taking, peer learning","Edinburgh, Scotland, UK",8,81?€?88,Association for Computing Machinery,L@S '16,$1 Conversational Turn Detector: Measuring How Video Conversations Affect Student Learning in Online Classes,https://doi.org/10.1145/2876034.2876048,2016
inproceedings,10.1145/2876034.2893374,"In this paper, we present a new set of features introduced in Course Builder that allow instructors to add skill maps to their courses. We show how skill maps can be used to provide up-to-date and actionable information on students' learning behavior and performance.","New York, NY, USA",,"Roussev, Boris and Simakov, Pavel and Orr, John and Deutsch, Amit and Cox, John and Lenaghan, Michael and Gainer, Mike",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893374,9.78145E+12,"adaptive learning, learning analytics, moocs, skill maps","Edinburgh, Scotland, UK",4,89?€?92,Association for Computing Machinery,L@S '16,Course Builder Skill Maps,https://doi.org/10.1145/2876034.2893374,2016
inproceedings,10.1145/2876034.2893375,"Students in online courses generate large amounts of data that can be used to personalize the learning process and improve quality of education. In this paper, we present the Latent Skill Embedding (LSE), a probabilistic model of students and educational content that can be used to recommend personalized sequences of lessons with the goal of helping students prepare for specific assessments. Akin to collaborative filtering for recommender systems, the algorithm does not require students or content to be described by features, but it learns a representation using access traces. We formulate this problem as a regularized maximum-likelihood embedding of students, lessons, and assessments from historical student-content interactions. Empirical findings on large-scale data from Knewton, an adaptive learning technology company, show that this approach predicts assessment results competitively with benchmark models and is able to discriminate between lesson sequences that lead to mastery and failure.","New York, NY, USA",,"Reddy, Siddharth and Labutov, Igor and Joachims, Thorsten",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893375,9.78145E+12,"sequence recommendation, adaptive learning, probabilistic embedding","Edinburgh, Scotland, UK",4,93?€?96,Association for Computing Machinery,L@S '16,Learning Student and Content Embeddings for Personalized Lesson Sequence Recommendation,https://doi.org/10.1145/2876034.2893375,2016
inproceedings,10.1145/2876034.2893376,"Online educational tools often generate learning data, and sharing such data between tutors and students can often improve learning outcomes. Unfortunately the process of sharing learning data today is not always transparent to students. Our aim is to improve the transparency and user control aspects of sharing data whilst maintaining the educational utility of data sharing between tutors and students. To do so, we start by surveying the possible methods of sharing data, and we use this to design a token-based scheme for facilitating data sharing. We implemented our scheme and observed it in use by 7,798 students over the course of one year. We find that our proposed scheme provides a good balance between transparency, user control, educational utility and scalability.","New York, NY, USA",,"Cummins, Stephen and Beresford, Alastair R. and Davies, Ian and Rice, Andrew",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893376,9.78145E+12,"authorisation, privacy, review, data sharing","Edinburgh, Scotland, UK",4,97?€?100,Association for Computing Machinery,L@S '16,Supporting Scalable Data Sharing in Online Education,https://doi.org/10.1145/2876034.2893376,2016
inproceedings,10.1145/2876034.2893378,"Many committed learners struggle to achieve their goal of completing a Massive Open Online Course (MOOC). This work investigates self-regulated learning (SRL) in MOOCs and tests if encouraging the use of SRL strategies can improve course performance. We asked a group of 17 highly successful learners about their own strategies for how to succeed in a MOOC. Their responses were coded based on a SRL framework and synthesized into seven recommendations. In a randomized experiment, we evaluated the effect of providing those recommendations to learners in the same course (N = 653). Although most learners rated the study tips as very helpful, the intervention did not improve course persistence or achievement. Results suggest that a single SRL prompt at the beginning of the course provides insufficient support. Instead, embedding technological aids that adaptively support SRL throughout the course could better support learners in MOOCs.","New York, NY, USA",,"Kizilcec, Ren\'{e} F. and P\'{e}rez-Sanagust\'{\i}n, Mar and Maldonado, Jorge J.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893378,9.78145E+12,"massive open online course, self-regulated learning","Edinburgh, Scotland, UK",4,101?€?104,Association for Computing Machinery,L@S '16,Recommending Self-Regulated Learning Strategies Does Not Improve Performance in a MOOC,https://doi.org/10.1145/2876034.2893378,2016
inproceedings,10.1145/2876034.2893379,"We investigate the use of hints as a form of scaffolding for 4,652 eligible users on a large-scale online learning environment called Isaac, which allows users to answer physics questions with up to five hints. We investigate user behaviour when using hints, users' engagement with fading (the process of gradually becoming less reliant on the hints provided), and hint strategies including Decomposition, Correction, Verification, or Comparison. Finally, we present recommendations for the design and development of online teaching tools that provide open access to hints, including a mechanism that may improve the speed at which users begin fading.","New York, NY, USA",,"Cummins, Stephen and Stead, Alistair and Jardine-Wright, Lisa and Davies, Ian and Beresford, Alastair R. and Rice, Andrew",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893379,9.78145E+12,"physics, problem solving, hints, scaffolding","Edinburgh, Scotland, UK",4,105?€?108,Association for Computing Machinery,L@S '16,Investigating the Use of Hints in Online Problem Solving,https://doi.org/10.1145/2876034.2893379,2016
inproceedings,10.1145/2876034.2893380,"In this paper, we describe a scalable learning analytics platform which runs generalized analytics models on educational data in parallel. As a proof of concept, we use this platform as a base for an end-to-end automated writing feedback system. The system allows students to view feedback on their writing in near real-time, edit their writing based on the feedback provided, and observe the progression of their performance over time. Providing students with detailed feedback is an important part of improving writing skills and an essential component towards solving Bloom's ""two sigma"" problem in education. We evaluate the effectiveness of the feedback for students with an ongoing pilot study with 800 students who are using the learning analytics platform in a college English course.","New York, NY, USA",,"Lewkow, Nicholas and Feild, Jacqueline and Zimmerman, Neil and Riedesel, Mark and Essa, Alfred and Boulanger, David and Seanosky, Jeremie and Kumar, Vive and Kinshuk and Kode, Sandhya",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893380,9.78145E+12,"performance feedback, automatic essay feedback, scalable analytics, natural language processing, analytic tools for learners","Edinburgh, Scotland, UK",4,109?€?112,Association for Computing Machinery,L@S '16,A Scalable Learning Analytics Platform for Automated Writing Feedback,https://doi.org/10.1145/2876034.2893380,2016
inproceedings,10.1145/2876034.2893382,"Detailed performance data can be exploited to achieve stronger student models when predicting next problem correctness (NPC) within intelligent tutoring systems. However, the availability and importance of these details may differ significantly when considering opportunity count (OC), or the compounded sequence of problems a student experiences within a skill. Inspired by this intuition, the present study introduces the Opportunity Count Model (OCM), a unique approach to student modeling in which separate models are built for differing OCs rather than creating a blanket model that encompasses all OCs. We use Random Forest (RF), which can be used to indicate feature importance, to construct the OCM by considering detailed performance data within tutor log files. Results suggest that OC is significant when modeling student performance and that detailed performance data varies across OCs.","New York, NY, USA",,"Wang, Yan and Ostrow, Korinn and Adjei, Seth and Heffernan, Neil",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893382,9.78145E+12,"student modeling, random forest, opportunity count, next problem correctness, intelligent tutoring system","Edinburgh, Scotland, UK",4,113?€?116,Association for Computing Machinery,L@S '16,The Opportunity Count Model: A Flexible Approach to Modeling Student Performance,https://doi.org/10.1145/2876034.2893382,2016
inproceedings,10.1145/2876034.2893383,"Many ongoing efforts in online education aim to increase accessibility through affordability and flexibility, but some critics have noted that pedagogy often suffers during these efforts. In contrast, in the low-cost for-credit Georgia Tech Online Masters of Science in Computer Science (OMSCS) program, we have observed that the features that make the program accessible also lead to pedagogical benefits. In this paper, we discuss the pedagogical benefits, and draw a causal link between those benefits and the factors that increase the program's accessibility.","New York, NY, USA",,"Joyner, David A. and Goel, Ashok K. and Isbell, Charles",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893383,9.78145E+12,"higher education., accessibility, online education","Edinburgh, Scotland, UK",4,117?€?120,Association for Computing Machinery,L@S '16,The Unexpected Pedagogical Benefits of Making Higher Education Accessible,https://doi.org/10.1145/2876034.2893383,2016
inproceedings,10.1145/2876034.2893384,"In October 2014, one-time MOOC developer Udacity completed its transition from primarily producing massive, open online courses to producing job-focused, project-based microcredentials called ""Nanodegree"" programs. With this transition came a challenge: whereas MOOCs focus on automated assessment and peer-to-peer grading, project-based microcredentials would only be feasible with expert evaluation. With dreams of enrolling tens of thousands of students at a time, the major obstacle became project evaluation. To address this, Udacity developed a system for hiring external experts as project reviewers. A year later, this system has supported project evaluation on a massive scale: 61,000 projects have been evaluated in 12 months, with 50% evaluated within 2.5 hours (and 88% within 24 hours) of submission. More importantly, students rate the feedback they receive very highly at 4.8/5.0. In this paper, we discuss the structure of the project review system, including the nature of the projects, the structure of the feedback, and the data described above.","New York, NY, USA",,"Joyner, David A.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893384,9.78145E+12,"evaluation, online education, feedback","Edinburgh, Scotland, UK",4,121?€?124,Association for Computing Machinery,L@S '16,Expert Evaluation of 300 Projects per Day,https://doi.org/10.1145/2876034.2893384,2016
inproceedings,10.1145/2876034.2893385,"The research reported in this paper used a researcher developed tool to categorize the pedagogical approaches used in MOOCs. The Assessing MOOC Pedagogies (AMP) tool characterized MOOC pedagogical approaches on ten dimensions. Preliminary testing on 20 different MOOCs demonstrated &gt;= 80% inter-reliability and the facility of the measure to distinguish differing pedagogical patterns. The patterns distinguished crossed content areas and seemed to be related to what Sfard (1998) identified as metaphors for learning; acquisition and participation approaches seemed to distinguish the pedagogies of differing MOOCs. A third, arguably important, pattern related to self-direction was also distinguished.","New York, NY, USA",,"Swan, Karen and Day, Scott and Bogle, Leonard",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893385,9.78145E+12,"moocs, pedagogy, metaphors for learning","Edinburgh, Scotland, UK",4,125?€?128,Association for Computing Machinery,L@S '16,Metaphors for Learning and MOOC Pedagogies,https://doi.org/10.1145/2876034.2893385,2016
inproceedings,10.1145/2876034.2893387,"Information sharing is a key activity of Massive Online Open Courses (MOOCs) user behavior. Sharing Uniform Resource Locators (URLs) has been identified as a means for individuals in online spaces to generate social relationships, construct knowledge, and disseminate information; however this activity has not been investigated within the MOOC space. This paper presents an observational study of URL sharing within MOOCs, and explores how a MOOC learning community responded to this micro behaviour. The research explored 1,471 comments and 416 learners who displayed URL sharing behavior from two iterations of the ""Irish Lives"" Futurelearn / Trinity College, University of Dublin MOOC. The analysis identified patterns of behavior within ""URL Sharers"", and suggests that this activity could support greater learner interaction. Although causality is not implied, the results of this analysis contributes a tentative new understanding of URL sharing in MOOCs, and denotes a new MOOC micro behaviour. This can be useful for MOOC practitioners to facilitate design choices.","New York, NY, USA",,"Gallagher, Silvia and Savage, Timothy",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893387,9.78145E+12,"uniform resource locators, online learner behaviour., massive online open courses","Edinburgh, Scotland, UK",4,129?€?132,Association for Computing Machinery,L@S '16,Observing URL Sharing Behaviour in Massive Online Open Courses,https://doi.org/10.1145/2876034.2893387,2016
inproceedings,10.1145/2876034.2893388,"We conducted two studies on the effect of visual reward mechanisms for increasing engagement with an online learning material. In the first study, we studied the effect of showing cat pictures as a reward to correct and incorrect answers to multiple choice questions, and in the second study, we created an illusion of progress using a progress bar that showed step-wise increments as students answered to the questions. Our results show the use of cat pictures as a visual reward mechanism does not significantly increase students' engagement with learning materials. At the same time, students who were shown progress bars had a statistically significant increase in the quantity of answers -- on average 88% more answers per day. However, our results also indicate that this effect declines over time, meaning that students catch up to the illusion.","New York, NY, USA",,"Lepp\""{a}nen, Leo and Vapaakallio, Lassi and Vihavainen, Arto",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893388,9.78145E+12,"visual rewards, visual feedback, student engagement, progress bar, pictures of cats, multiple choice questions, motivation, gamification","Edinburgh, Scotland, UK",4,133?€?136,Association for Computing Machinery,L@S '16,Illusion of Progress is Moar Addictive than Cat Pictures,https://doi.org/10.1145/2876034.2893388,2016
inproceedings,10.1145/2876034.2893389,This paper at hand describes the design and implementation of an analytics service to retrieve live usage data from students enrolled in a service-oriented MOOC platform for the purpose of learning analytics (LA) research. A real-time and extensible architecture for consolidating and processing data in versatile analytics stores is introduced.,"New York, NY, USA",,"Renz, Jan and Navarro-Suarez, Gerado and Sathi, Rowshan and Staubitz, Thomas and Meinel, Christoph",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893389,9.78145E+12,"mooc, learning analytics, service oriented architecture","Edinburgh, Scotland, UK",4,137?€?140,Association for Computing Machinery,L@S '16,Enabling Schema Agnostic Learning Analytics in a Service-Oriented MOOC Platform,https://doi.org/10.1145/2876034.2893389,2016
inproceedings,10.1145/2876034.2893391,"Despite the ubiquitous use of videos in online learning and enormous literature on designing online learning, there has been relatively little research on what pedagogical strategies should be used to make the most of video lessons and what constitutes an effective video for student learning. We experimented with a model of incorporating four pedagogical strategies, four instructional phases, and four production guidelines-in designing and developing video lessons for an online graduate course. In this paper, we share our experience as well as students' perceptions of their effectiveness. We also discuss what needs to be done for future research.","New York, NY, USA",,"Ou, Chaohua and Goel, Ashok K. and Joyner, David A. and Haynes, Daniel F.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893391,9.78145E+12,"moocs, learning at scale, educational videos, online learning, artificial intelligence","Edinburgh, Scotland, UK",4,141?€?144,Association for Computing Machinery,L@S '16,Designing Videos with Pedagogical Strategies: Online Students' Perceptions of Their Effectiveness,https://doi.org/10.1145/2876034.2893391,2016
inproceedings,10.1145/2876034.2893393,"Intelligent tutoring systems are known for providing customized learning opportunities for thousands of users. One feature of many systems is differentiating the amount of practice users receive. To do this, some systems rely on a threshold of consecutive correct responses. For instance, Khan Academy used to use ten correct in a row and now uses five correct in a row as the mastery threshold. The present research uses a series of randomized control trials, conducted in an online learning platform (eg., ASSISTments.org), to explore the effects of different thresholds of consecutive correct responses on learning. Results indicate that despite spending significantly more time practicing there is no significant difference on learning between two, three, four, or five consecutive correct responses. This suggests that systems, and MOOCS, can employ the simple rule of two or three consecutive correct responses when determining the amount of practice provided to users.","New York, NY, USA",,"Kelly, Kim M. and Heffernan, Neil T.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893393,9.78145E+12,"personalized instruction, on-line learning platform, mastery learning, moocs","Edinburgh, Scotland, UK",4,145?€?148,Association for Computing Machinery,L@S '16,Optimizing the Amount of Practice in an On-Line Platform,https://doi.org/10.1145/2876034.2893393,2016
inproceedings,10.1145/2876034.2893394,"Difficult test questions can be made easy by providing a set of possible answer options of which most are obviously wrong. In the education literature, a plethora of instructional guides exist for crafting a suitable set of wrong choices (distractors) in order to probe the students' understanding of the tested concept. The art of multiple-choice question design thus hinges on the question-maker's experience and knowledge of the potential misconceptions. In contrast, we advocate a data-driven approach, where correct and incorrect options are assembled directly from the students' own past submissions. Large-scale online classroom settings, such as massively open online courses (MOOCs), provide an opportunity to design optimal and adaptive multiple-choice questions that are maximally informative about the students' level of understanding of the material. We deploy a multinomial-logit discrete choice model for the setting of multiple choice testing, derive an optimization objective for selecting optimally discriminative option sets, and demonstrate the effectiveness of our approach via a user study.","New York, NY, USA",,"Labutov, Igor and Luu, Kelvin and Lipson, Hod and Studer, Christoph",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893394,9.78145E+12,"optimal experiment design, test design, optimal test, discrete choice model, active learning","Edinburgh, Scotland, UK",4,149?€?152,Association for Computing Machinery,L@S '16,Optimally Discriminative Choice Sets in Discrete Choice Models: Application to Data-Driven Test Design,https://doi.org/10.1145/2876034.2893394,2016
inproceedings,10.1145/2876034.2893395,"In contrast to multiple-choice or selected response questions, constructed response questions can result in a wide variety of incorrect responses. However, constructed responses are richer in information. We propose a technique for using each student's constructed responses in order to identify a subset of their stable conceptual misunderstandings. Our approach is designed for courses with so many students that it is infeasible to interpret every distinct wrong answer manually. Instead, we label only the most frequent wrong answers with the misunderstandings that they indicate, then predict the misunderstandings associated with other wrong answers using statistical co-occurrence patterns. This tiered approach leverages a small amount of human labeling effort to seed an automated procedure that identifies misunderstandings in students. Our approach involves much less effort than inspecting all answers, substantially outperforms a baseline that does not take advantage of co-occurrence statistics, proves robust to different course sizes, and generalizes effectively across student cohorts.","New York, NY, USA",,"Stephens-Martinez, Kristin and Ju, An and Schoen, Colin and DeNero, John and Fox, Armando",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893395,9.78145E+12,"semi-automatic misunderstanding detection, massive courses, introductory computer science, constructed response questions, education","Edinburgh, Scotland, UK",4,153?€?156,Association for Computing Machinery,L@S '16,Identifying Student Misunderstandings Using Constructed Responses,https://doi.org/10.1145/2876034.2893395,2016
inproceedings,10.1145/2876034.2893396,"One of the most challenging aspects of developing a Massive Open Online Course (MOOC) is designing an accurate method to effectively assess participant knowledge and skills. The Distributed Esteemed Endorser Review (DEER) approach has been developed as an alternative for those MOOCs where traditional approaches to assessment are not appropriate. In DEER, course projects are certified in-person by an ""Esteemed Endorser"", an individual who is typically senior in rank to the student, but is not necessarily an expert in the course content. Not only does DEER provide a means to certify that course goals have been met, it also provides MOOC participants with the opportunity to share information about what they have learned with others at the local level.","New York, NY, USA",,"Kay, Jennifer S. and Nolan, Tyler J. and Grello, Thomas M.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893396,9.78145E+12,"esteemed endorser, robot programming, educational robotics, mooc, deer, assessment","Edinburgh, Scotland, UK",4,157?€?160,Association for Computing Machinery,L@S '16,The Distributed Esteemed Endorser Review: A Novel Approach to Participant Assessment in MOOCs,https://doi.org/10.1145/2876034.2893396,2016
inproceedings,10.1145/2876034.2893469,"Whilst most research on MOOCs makes inferences about the experience of learners from their interaction with the platform, few considered the rich feedback provided by learners. This paper presents the application of a conceptual model of student experience borrowed from higher education. Its relevance in the context of MOOCs was tested by using a range of questions and presentation methods in four MOOCs selected for their specific features. With varying response rates, results from over 8900 participants show how universities might view and evaluate the experience in MOOCs compared with that in traditional courses.","New York, NY, USA",,"Vigentini, Lorenzo and Zhao, Catherine",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893469,9.78145E+12,"student experience, surveys, evaluation., moocs","Edinburgh, Scotland, UK",4,161?€?164,Association for Computing Machinery,L@S '16,Evaluating the 'Student' Experience in MOOCs,https://doi.org/10.1145/2876034.2893469,2016
inproceedings,10.1145/2876034.2893397,"Adaptive learning is the core technology behind intelligent tutoring systems, which are responsible for estimating student knowledge and providing personalized instruction to students based on their skill level. In this paper, we present a new adaptive learning system architecture, which uses Artificial Neural Network to construct the Learner Model, which automatically models relationship between different concepts in the curriculum and beats Knowledge Tracing in predicting student performance. We also propose a novel method for selecting items of optimal difficulty, personalized to student's skill level and learning rate, which decreases their learning time by 26.5% as compared to standard pre-defined curriculum sequence item selection policy.","New York, NY, USA",,"Chaplot, Devendra Singh and Rhim, Eunhee and Kim, Jihie",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893397,9.78145E+12,"student model, personalized item selection, instructional model, learner model, adaptive learning, neural networks","Edinburgh, Scotland, UK",4,165?€?168,Association for Computing Machinery,L@S '16,Personalized Adaptive Learning Using Neural Networks,https://doi.org/10.1145/2876034.2893397,2016
inproceedings,10.1145/2876034.2893398,"Massive Open Online Courses (MOOCs) have the potential to bridge education and literacy gaps by offering high quality, free courses to anyone with an Internet connection. MOOCs in their present state, however, may be relatively inaccessible to non-native English speakers, as a majority of MOOC content is in the English language. While a potential solution is to translate all MOOC content into all languages, it is not known whether this solution will satisfy the learning goals of all English as a Second Language (ESL) speakers. Through a series of interviews, we investigate ESL speakers' motivations for taking MOOCs and other online courses. Our findings show that ESL speakers have a variety of motivations for taking online courses that are not captured in current surveys, which implies that current one-size-fits-all approaches to increasing MOOC accessibility for learners with a first language other than English may not be effective. Rather, offering learners individualized tools based on their motivation and needs may be more effective.","New York, NY, USA",,"Uchidiuno, Judith and Ogan, Amy and Yarzebinski, Evelyn and Hammer, Jessica",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893398,9.78145E+12,"moocs, mooc accessibility, learning motivations., english as a second language","Edinburgh, Scotland, UK",4,169?€?172,Association for Computing Machinery,L@S '16,Understanding ESL Students' Motivations to Increase MOOC Accessibility,https://doi.org/10.1145/2876034.2893398,2016
inproceedings,10.1145/2876034.2893407,"We present LINK-REPORT, a distributed learning outcome analysis module that is integrated with the WISEngineering platform for supporting informal learning in engineering. LINK-REPORT provides a coherent workflow of outcome analysis: starting from development of learning outcome goals, to learner behavior collection, to automated grading of open ended short answer questions, and to report generation and aggregation. It generates learning data for research opportunities in modeling of learner traits.","New York, NY, USA",,"Fu, Xiang and Befferman, Tyler and Burghardt, M.D.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893407,9.78145E+12,"outcome assessment, automated grading","Edinburgh, Scotland, UK",4,173?€?176,Association for Computing Machinery,L@S '16,LINK-REPORT: Outcome Analysis of Informal Learning at Scale,https://doi.org/10.1145/2876034.2893407,2016
inproceedings,10.1145/2876034.2893408,"We present the Beetle-Grow intelligent tutoring system, which combines active experimentation, self-explanation, and formative feedback using natural language interaction. It runs in a standard web browser and has a fresh, engaging design. The underlying back-end system has previously been shown to be highly effective in teaching basic electricity and electronics concepts. Beetle-Grow has been designed to capture student interaction and indicators of learning in a form suitable for data mining, and to support future work on building tools for interactive tutoring that improve after experiencing interaction with students, as human tutors do.","New York, NY, USA",,"Farrow, Elaine and Dzikovska, Myroslava O. and Moore, Johanna D.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893408,9.78145E+12,"physics, interaction data, intelligent tutoring, electronics, natural language, conceptual learning","Edinburgh, Scotland, UK",4,177?€?180,Association for Computing Machinery,L@S '16,Beetle-Grow: An Effective Intelligent Tutoring System for Data Collection,https://doi.org/10.1145/2876034.2893408,2016
inproceedings,10.1145/2876034.2893409,"In this paper, we present a dataset consisting of data generated from 22 previously and currently running randomized controlled experiments inside the ASSIStments online learning platform. This dataset provides data mining opportunities for researchers to analyze ASSISTments data in a convenient format across multiple experiments at the same time. The data preprocessing steps are explained in detail to inform researchers about how this dataset was generated. A list of column descriptions is provided to define the columns in the dataset and a set of summary statistics are presented to briefly describe the dataset.","New York, NY, USA",,"Selent, Douglas and Patikorn, Thanaporn and Heffernan, Neil",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893409,9.78145E+12,"assistments, randomized controlled experiments, dataset","Edinburgh, Scotland, UK",4,181?€?184,Association for Computing Machinery,L@S '16,ASSISTments Dataset from Multiple Randomized Controlled Experiments,https://doi.org/10.1145/2876034.2893409,2016
inproceedings,10.1145/2876034.2893410,"Interactive simulations are commonly used tools in technology enhanced education. Simulations can be a powerful tool for allowing students to engage in inquiry, especially in science disciplines. They can help students develop an understanding of complex science phenomena in which multiple variables are at play. Developing models for complex domains, like climate science, is important for learning. Equally important, though, is understanding how students use these simulations. Finding use patterns that lead to learning will allow us to develop better guidance for students who struggle to extract the useful information from the simulation. In this study, we generate features from action log data collected while students interacted with simulations on climate change. We seek to understand what types of features are important for student learning by using regression models to map features onto learning outcomes.","New York, NY, USA",,"McBride, Elizabeth and Vitale, Jonathan M. and Gogel, Hannah and Martinez, Mario M. and Pardos, Zachary and Linn, Marcia C.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893410,9.78145E+12,"science education, action log data, data mining, inquiry learning","Edinburgh, Scotland, UK",4,185?€?188,Association for Computing Machinery,L@S '16,Predicting Student Learning Using Log Data from Interactive Simulations on Climate Change,https://doi.org/10.1145/2876034.2893410,2016
inproceedings,10.1145/2876034.2893411,"We describe the design rationale and principles of a web authoring tool for beginner web developers called Snowball. We explain how this constructionist toolkit exposes content creators to computational features of web pages, enabling them to create meaningful artifacts while they move from content creation to basic coding. Finally, we discuss how we are instrumenting learning analytics in Snowball.","New York, NY, USA",,"Kim, Meen Chul and Park, Thomas H. and Lee, Brian and Chhabra, Sukrit and Forte, Andrea",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893411,9.78145E+12,"informal learning, constructionism, web development, computing education at scale","Edinburgh, Scotland, UK",4,189?€?192,Association for Computing Machinery,L@S '16,A Constructionist Toolkit for Learning Elementary Web Development at Scale,https://doi.org/10.1145/2876034.2893411,2016
inproceedings,10.1145/2876034.2893412,"This paper introduces a new feature for instructors to communicate with their MOOC learners via SmartWatches in a different way to the traditional e-mails in order to try to avoiding procrastination. We have developed an Android Wear-based SmartWatches application designed for receiving notifications from MOOCs, and a specific section in Google Course Builder interface that allows instructors to configure and send the messages to each user registered in the course. We have evaluated the implementation of our proposal in an Introduction to Philosophy MOOC. The number and percentage of students who did assessments on time, together with their comments in a satisfaction questionnaire present very promising results.","New York, NY, USA",,"Romero, Crist\'{o}bal and Cerezo, Rebeca and Espino, Jose Antonio and Bermudez, Manuel",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893412,9.78145E+12,"smartwatches, procrastination., mooc, android wear, notifications","Edinburgh, Scotland, UK",4,193?€?196,Association for Computing Machinery,L@S '16,Using Android Wear for Avoiding Procrastination Behaviours in MOOCs,https://doi.org/10.1145/2876034.2893412,2016
inproceedings,10.1145/2876034.2893413,"While log analysis in massively open online courses and other online learning environments has mainly focused on traditional measures, such as completion rates and views of course content, research is responding to calls for analytic frameworks that are more reflective of social learning models. We introduce a generalizable approach to automatically code log data that highlights educator support roles and student actions that are consistent with recent conceptualizations of 21st century learning, such as creative production, self-directed learning, and social learning. Here, we describe details of a log-coding framework that builds from prior mixed method studies of the use of iRemix, an online social learning network, by middle school youth and adult educators in blended learning contexts.","New York, NY, USA",,"Nacu, Denise and Martin, Caitlin K. and Schutzenhofer, Michael and Pinkard, Nicole",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893413,9.78145E+12,"online learning, log analysis, teaching roles, educational data mining, 21st century learning","Edinburgh, Scotland, UK",4,197?€?200,Association for Computing Machinery,L@S '16,Beyond Traditional Metrics: Using Automated Log Coding to Understand 21st Century Learning Online,https://doi.org/10.1145/2876034.2893413,2016
inproceedings,10.1145/2876034.2893414,"This study proposes a standardised open framework to automatically generate and label discussion topics from Massive Open Online Courses (MOOCs). The proposed framework expects to overcome the issues experienced by MOOC participants and teaching staff in locating and navigating their information needs effectively. We analysed two MOOCs -- Machine Learning and Statistics: Making Sense of Data offered during 2013 and obtained statistically significant results for automated topic labeling. However, more experiments with additional MOOCs from different MOOC platforms are necessary to generalise our findings.","New York, NY, USA",,"Atapattu, Thushari and Falkner, Katrina",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893414,9.78145E+12,"mooc, naive bayes, learning analytics, latent dirichlet allocation, topic modeling, discussion forum, nlp","Edinburgh, Scotland, UK",4,201?€?204,Association for Computing Machinery,L@S '16,A Framework for Topic Generation and Labeling from MOOC Discussions,https://doi.org/10.1145/2876034.2893414,2016
inproceedings,10.1145/2876034.2893415,"Although xMOOCs are not designed to directly engage students via social media platforms, some students in these courses join MOOC-associated Facebook groups. This study explores the prevalence of Facebook groups associated with courses from MITx and HarvardX, the geographic distribution of students in such groups as compared to the courses at large, and the extent to which such groups are location and/or language homophilous. Results suggests that a non-trivial number of MOOC students engage in Facebook groups, that learners from a number of non-U.S. locations are disproportionately likely to participate in such groups, and that the groups display both location and language homophily. These findings have implications for how MOOCs and social media platforms can support learners from non-English speaking contexts.","New York, NY, USA",,"Kasunic, Anna and Hammer, Jessica and Kraut, Robert and Massimi, Michael and Ogan, Amy",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893415,9.78145E+12,"facebook, homophily, massive open online courses, moocs, social media","Edinburgh, Scotland, UK",4,205?€?208,Association for Computing Machinery,L@S '16,"A Preliminary Look at MOOC-Associated Facebook Groups: Prevalence, Geographic Representation, and Homophily",https://doi.org/10.1145/2876034.2893415,2016
inproceedings,10.1145/2876034.2893416,"Massive Open Online Courses (MOOCs) provide an effective learning platform with various high-quality educational materials accessible to learners from all over the world. However, current MOOCs lack personalized learning guidance and intelligent assessment for individuals. Though a few recent attempts have been made to trace students' knowledge states by adapting the popular Bayesian Knowledge Tracing (BKT) model, they have largely ignored the rich structures and correlations among knowledge components (KCs) within a course. This paper proposes to model both the hierarchical and the temporal properties of the knowledge states in order to improve the modeling accuracy. Based on the content organization characteristics on the Coursera MOOC platform, we provide a well-defined KC model, and develop Multi-Grained-BKT and Historical-BKT to capture the above features effectively. Experiments on a Coursera course dataset show our approach significantly improves over previous vanilla BKT models on predicting students' quiz performance.","New York, NY, USA",,"Wang, Zhuo and Zhu, Jile and Li, Xiang and Hu, Zhiting and Zhang, Ming",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893416,9.78145E+12,"student modeling, knowledge tracing, hierarchical and temporal, student assessment, moocs","Edinburgh, Scotland, UK",4,209?€?212,Association for Computing Machinery,L@S '16,Structured Knowledge Tracing Models for Student Assessment on Coursera,https://doi.org/10.1145/2876034.2893416,2016
inproceedings,10.1145/2876034.2893417,"How students do homework has been under-researched relative to classroom learning because it is more difficult to collect data on students' homework behaviors. Presumably, such data would have implications for students' achievement. To understand how students do homework and how homework performance and behaviors relate to end-of-year standardized test scores, we analyzed the system logs from an online homework support platform used by more than 1,500 seventh-grade students in Maine.","New York, NY, USA",,"Feng, Mingyu and Roschelle, Jeremy",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893417,9.78145E+12,"prediction, log analysis, online math homework","Edinburgh, Scotland, UK",4,213?€?216,Association for Computing Machinery,L@S '16,Predicting Students' Standardized Test Scores Using Online Homework,https://doi.org/10.1145/2876034.2893417,2016
inproceedings,10.1145/2876034.2893418,"One of the Educational Data Mining (EDM) main aims is to predict the final student's performance, analyzing their behavior in the Learning Management Systems (LMSs). Many studies make use of different classifiers to reach this goal, using the total interaction of the students. In this work we study if it is possible to build more accurate classification models in order to predict the output, analyzing the interaction in an incremental way. We study the data gathered for two years with three kinds of classifying algorithms and we compare the total interaction models with the incremental interaction models.","New York, NY, USA",,"Sanchez-Santillan, Miguel and Paule-Ruiz, MPuerto and Cerezo, Rebeca and Nu\~{n}ez, JCarlos",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893418,9.78145E+12,"elearning, educational data mining, classifiers","Edinburgh, Scotland, UK",4,217?€?220,Association for Computing Machinery,L@S '16,Predicting Students' Performance: Incremental Interaction Classifiers,https://doi.org/10.1145/2876034.2893418,2016
inproceedings,10.1145/2876034.2893419,"The large datasets produced by learning at scale, and the need for ways of dealing with high learner/educator ratios, mean that MOOCs and related environments are frequently used for the deployment and development of learning analytics. Despite the current proliferation of analytics, there is as yet relatively little hard evidence of their effectiveness. The Evidence Hub developed by the Learning Analytics Community Exchange (LACE) provides a way of collating and filtering the available evidence in order to support the use of analytics and to target future studies to fill the gaps in our knowledge.","New York, NY, USA",,"Ferguson, Rebecca",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893419,9.78145E+12,"evidence hub, ethics, teaching, learning, learning analytics, evidence","Edinburgh, Scotland, UK",4,221?€?224,Association for Computing Machinery,L@S '16,Learning at Scale: Using an Evidence Hub To Make Sense of What We Know,https://doi.org/10.1145/2876034.2893419,2016
inproceedings,10.1145/2876034.2893420,"We present Elice, an online CS (computer science) education platform, and Elivate, a system for taking student learning data from Elice and infers their progress through an educational taxonomy tailored for programming education. Elice captures detailed student learning activities, such as the intermediate revisions of code as students make progress toward completing their programming exercises. With those data, Elivate recognizes each student's progression through an education taxonomy which organizes intermediate stages of learning such that the taxonomy can be used to evaluate student progress as well as to design and improve course materials and structure. With more than 240,000 intermediate source codes generated by 1,000 students, we demonstrate the practicality of the Elice and Elivate. We present case studies that confirm that categorizing student actions into the different steps of the taxonomy results in better understanding of the effect of TA's assist and student's performance.","New York, NY, USA",,"Kim, Suin and Kim, Jae Won and Park, Jungkook and Oh, Alice",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893420,9.78145E+12,"social learning, computer science education, online programming, collaborative learning, online education","Edinburgh, Scotland, UK",4,225?€?228,Association for Computing Machinery,L@S '16,Elice: An Online CS Education Platform to Understand How Students Learn Programming,https://doi.org/10.1145/2876034.2893420,2016
inproceedings,10.1145/2876034.2893421,"Two major benefits of Massive Open Online Course platforms are their collection of fine grain data on student interactions with the course website and their capacity to give students immediate feedback on their work. We study the patterns of students' usage of immediate feedback in an undergraduate physics course that uses blended learning, and we present informative aggre-gate descriptives from this 474-student class. We find that overall student study strategies mirror those in ""traditional"" courses, that students strategically use the auto-checking feature of the platform, and that they extensively use the other content resources available to them on the platform. Several of these findings support educational research that has not had the benefit of the data MOOC platforms give us access to. Better understanding of how students engage with blended learning will aid residential instructors in tailoring in-class time and providing their students with recommendations for approaches to studying.","New York, NY, USA",,"DeBoer, Jennifer and Breslow, Lori",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893421,9.78145E+12,"blended learning, mooc platforms, immediate feedback","Edinburgh, Scotland, UK",4,229?€?232,Association for Computing Machinery,L@S '16,Work in Progress: Student Behaviors Using Feedback in a Blended Physics Undergraduate Classroom,https://doi.org/10.1145/2876034.2893421,2016
inproceedings,10.1145/2876034.2893422,"Digital learning environments are becoming more common for students to engage in during and outside of school. With the immense amount of data now available from these environments, researchers need tools to process, manage, and analyze the data. Current methods used by many education researchers are inefficient; however, without data science experience tools used in other professions are not accessible. In this paper, we share about a tool we created called the Functional Understanding Navigator! (FUN! Tool). We have used this tool for different research projects which has allowed us the opportunity to (1) organize our workflow process from start to finish, (2) record log data of all of our analyses, and (3) provide a platform to share our analyses with others through GitHub. This paper extends and improves existing work in educational data mining and learning analytics.","New York, NY, USA",,"Martin, Taylor and Brasiel, Sarah and Jeong, Soojeong and Close, Kevin and Lawanto, Kevin and Janisciewcz, Phil",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893422,9.78145E+12,"assessment, educational data mining, digital learning environments, micro learning","Edinburgh, Scotland, UK",4,233?€?236,Association for Computing Machinery,L@S '16,Macro Data for Micro Learning: Developing the FUN! Tool for Automated Assessment of Learning,https://doi.org/10.1145/2876034.2893422,2016
inproceedings,10.1145/2876034.2893423,"MOOCs by their design are able to reach several thousands of participants with very few instructors creating, delivering and facilitating the content. Participants interact with each other usually with text based asynchronous discussion forums built into the MOOC platform. The purpose of this research is to explore the role of social presence in facilitating peer support among a large community of learners.","New York, NY, USA",,"Appiah-Kubi, Kwamena and Rowland, Duncan",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893423,9.78145E+12,"social presence, community of inquiry, group cohesion, mooc, social interaction","Edinburgh, Scotland, UK",4,237?€?240,Association for Computing Machinery,L@S '16,PEER Support In MOOCs: The Role Of Social Presence,https://doi.org/10.1145/2876034.2893423,2016
inproceedings,10.1145/2876034.2893424,We propose a comparative judgement scheme for grading short answer questions in an online class. The scheme works by asking students to answer short answer questions. Then a multiple choice question is created whose choices are the answers given by students. We show that we can formulate a probabilistic graphical model for this scheme which lets us infer each students proficiency for answering and grading questions.,"New York, NY, USA",,"Kolhe, Pushkar and Littman, Michael L. and Isbell, Charles L.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893424,9.78145E+12,"peer grading, crowd sourcing","Edinburgh, Scotland, UK",4,241?€?244,Association for Computing Machinery,L@S '16,Peer Reviewing Short Answers Using Comparative Judgement,https://doi.org/10.1145/2876034.2893424,2016
inproceedings,10.1145/2876034.2893425,"Authentic problem solving tasks in digital environments are often open-ended with ill-defined pathways to a goal state. Scaffolds and formative feedback during this process help learners develop the requisite skills and understanding, but require assessing the problem-solving process. This paper describes a hybrid approach to assessing process at scale in the context of the use of computational thinking practices during programming. Our approach combines hypothesis-driven analysis, using an evidence-centered design framework, with discovery-driven data analytics. We report on work-in-progress involving novices and expert programmers working on Blockly games.","New York, NY, USA",,"Grover, Shuchi and Bienkowski, Marie and Niekrasz, John and Hauswirth, Matthias",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893425,9.78145E+12,"k-12 computing, assessment, evidence-centered design, problem solving, programming process","Edinburgh, Scotland, UK",4,245?€?248,Association for Computing Machinery,L@S '16,Assessing Problem-Solving Process At Scale,https://doi.org/10.1145/2876034.2893425,2016
inproceedings,10.1145/2876034.2893426,"This work-in-progress paper elaborates on a gradually evolving approach to design of open learning and the design principles used by the Open University of the Netherlands in short open courses - online masterclasses and in Massive Open Online Courses -- delivered in the learning environment of the Open University and in the experimental multilingual MOOC aggregator EMMA as part of a European project. As the paper will demonstrate, these principles can be seen as building blocks of open scalable design of active and engaging learning.","New York, NY, USA",,"Firssova, Olga and Brouns, Francis and Kalz, Marco",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893426,9.78145E+12,"scalability, moocs, open online learning, active learning, design principles","Edinburgh, Scotland, UK",4,249?€?252,Association for Computing Machinery,L@S '16,Designing for Open Learning: Design Principles and Scalability Affordances in Practice,https://doi.org/10.1145/2876034.2893426,2016
inproceedings,10.1145/2876034.2893427,"Preliminary research is presented on the generalisability of confusion, urgency and sentiment classifiers for MOOC forum posts. The Stanford MOOCPosts data set is used to train classifiers with forum posts from individual courses and validate these classifiers on MOOC forum posts from other domain areas. While low cross-domain classification accuracy is achieved, the experiment highlights the need for transfer learning and domain adaptation algorithms; and provides insight into the types of algorithms required within an educational context.","New York, NY, USA",,"Bakharia, Aneesha",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893427,9.78145E+12,"classification, mooc, forum, domain adaptation","Edinburgh, Scotland, UK",4,253?€?256,Association for Computing Machinery,L@S '16,Towards Cross-Domain MOOC Forum Post Classification,https://doi.org/10.1145/2876034.2893427,2016
inproceedings,10.1145/2876034.2893428,"Faced with growing class sizes and the dawn of the MOOC, educators are in need of tools to help them cope with the growing number of questions asked in large classes since manually answering all the questions in a timely manner is infeasible. In this paper, we propose to exploit historical question/answer data accumulated for the same or similar classes as a basis for automatically answering previously asked questions via the use of information retrieval techniques. We further propose to leverage resolved questions to create test collections for quantitative evaluation of a question retrieval algorithm without requiring additional human effort. Using this evaluation methodology, we study the effectiveness of state of the art retrieval techniques for this special retrieval task, and perform error analysis to inform future directions.","New York, NY, USA",,"Geigle, Chase and Zhai, ChengXiang",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893428,9.78145E+12,"community question answering, information retrieval","Edinburgh, Scotland, UK",4,257?€?260,Association for Computing Machinery,L@S '16,Scaling up Online Question Answering via Similar Question Retrieval,https://doi.org/10.1145/2876034.2893428,2016
inproceedings,10.1145/2876034.2893429,"While MOOCs and other forms of large-scale learning are of growing importance, the vast majority of tertiary students still study in traditional face-to-face settings. This paper examines some of the challenges in attempting to apply the benefits of large-scale learning to these settings, building on a growing repository of cross-institutional data.","New York, NY, USA",,"Dix, Alan",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893429,9.78145E+12,"moocs, learning analytics, education technology, reading lists, oer, linked data","Edinburgh, Scotland, UK",4,261?€?264,Association for Computing Machinery,L@S '16,"Challenge and Potential of Fine Grain, Cross-Institutional Learning Data",https://doi.org/10.1145/2876034.2893429,2016
inproceedings,10.1145/2876034.2893430,"In this paper a learning analytics dashboard for MOOCs is proposed. It visualises the progress of learners' activity taking into account navigation, social interactions and interaction with educational resources. This approach was tested with the MOOCs created by the University Auton\'{o}ma of Madrid (Spain) in the edX platform. Nowadays, the dashboard is being improved taking into account the received feedback from MOOCs instructors and assistants. Finally, a new version is presented to work along with edX and Open edX.","New York, NY, USA",,"Cobos, Ruth and Gil, Silvia and Lareo, Angel and Vargas, Francisco A.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893430,9.78145E+12,"learning analytics, moocs, dashboard","Edinburgh, Scotland, UK",4,265?€?268,Association for Computing Machinery,L@S '16,Open-DLAs: An Open Dashboard for Learning Analytics,https://doi.org/10.1145/2876034.2893430,2016
inproceedings,10.1145/2876034.2893431,"Massive Open Online Courses represent a fertile ground for examining student behavior. However, due to their openness MOOC attract a diverse body of students, for the most part, unknown to the course instructors. However, a certain number of students enroll in the same course multiple times, and there are records of their previous learning activities which might provide some useful information to course organizers before the start of the course. In this study, we examined how student behavior changes between subsequent course offerings. We identified profiles of returning students and also interesting changes in their behavior between two enrollments to the same course. Results and their implications are further discussed.","New York, NY, USA",,"Kovanovi\'{c}, Vitomir and Joksimovi\'{c}, Sre\'{c}ko and Ga\v{s}evi\'{c}, Dragan and Owers, James and Scott, Anne-Marie and Woodgate, Amy",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893431,9.78145E+12,"learning analytics, moocs, student behavior, clustering, self-regulated learning, educational technology use","Edinburgh, Scotland, UK",4,269?€?272,Association for Computing Machinery,L@S '16,Profiling MOOC Course Returners: How Does Student Behavior Change Between Two Course Enrollments?,https://doi.org/10.1145/2876034.2893431,2016
inproceedings,10.1145/2876034.2893432,"Professional learning is a critical component of the ongoing improvement, innovation and adoption of new practices that support learning at scale. In this context, educators must learn how to apply digital technologies and work effectively in digital networks. This study examines how higher education professionals adapted their practice to enable more open and flexible work processes. A case study carried out using Activity Theory showed that teams involved in the development of a module all need access to a range of expertise both practical and academic. At each stage, they need to be clear about the learning outcomes of the module, the responsibilities of each team and its constraints. Teams need to be willing to agree ways to shift those constraints in order to develop a module effectively.","New York, NY, USA",,"Papathoma, Tina and Ferguson, Rebecca and Littlejohn, Allison and Coe, Angela",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893432,9.78145E+12,"online courses, professional learning, innovation, case study, activity theory","Edinburgh, Scotland, UK",4,273?€?276,Association for Computing Machinery,L@S '16,Making the Production of Learning at Scale More Open and Flexible,https://doi.org/10.1145/2876034.2893432,2016
inproceedings,10.1145/2876034.2893433,"Open access and low cost make Massively Open Online Courses (MOOCs) an attractive learning platform for students all over the world. However, the majority of MOOCs are deployed in English, which can pose an accessibility problem for students with English as a Second Language (ESL). In order to design appropriate interventions for ESL speakers, it is important to correctly identify these students using a method that is scalable to the high number of MOOC enrollees. Our findings suggest that a new metric, browser language preference, may be better than the commonly-used IP address for inferring whether or not a student is ESL.","New York, NY, USA",,"Uchidiuno, Judith and Ogan, Amy and Koedinger, Kenneth R. and Yarzebinski, Evelyn and Hammer, Jessica",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893433,9.78145E+12,"foreign language students, mooc accessibility","Edinburgh, Scotland, UK",4,277?€?280,Association for Computing Machinery,L@S '16,Browser Language Preferences as a Metric for Identifying ESL Speakers in MOOCs,https://doi.org/10.1145/2876034.2893433,2016
inproceedings,10.1145/2876034.2893434,"Online tests have been identified as a core learning activity. Unlike conventional online tests, which cannot completely reflect students' learning status, two-tier tests not only consider students' answers, but also take into account reasons for their answers. Thus, research into a two-tier test had mushroomed but few studies examined why the two-tier test approach was effective. To this end, we conducted an empirical study, where a lag sequential analysis was used to analyze behavior patterns. The results indicated students with the two-tier test demonstrated different behaviors which develop ""breadth to depth"" and ""depth to breadth"" strategies.","New York, NY, USA",,"Yang, Tzu Chi and Shih, Dai Ling and Chen, Meng Chang",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893434,9.78145E+12,,"Edinburgh, Scotland, UK",4,281?€?284,Association for Computing Machinery,L@S '16,An Investigation of the Effects of Online Test Strategy on Students' Learning Behaviors,https://doi.org/10.1145/2876034.2893434,2016
inproceedings,10.1145/2876034.2893435,"Cheating in computer science classes can damage the reputation of institutions and their students. It is therefore essential to routinely authenticate student submissions with available software plagiarism detection algorithms such as Measure of Software Similarity (MOSS). Scaling this task for large classes where assignments are repeated each semester adds complexity and increases the instructor workload. The MOSS Tool for Addressing Plagiarism at Scale (MOSS-TAPS), organizes the MOSS submission task in courses that repeat coding assignments. In a recent use-case in the Online Master of Science in Computer Science (OMSCS) program at the Georgia Institute of Technology, the instructor time spent was reduced from 50 hours to only 10 minutes using the managed submission tool design presented here. MOSS-TAPS provides persistent configuration, supports a mixture of software languages and file organizations, and is implemented in pure Java for cross-platform compatibility.","New York, NY, USA",,"Sheahen, Dana and Joyner, David",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893435,9.78145E+12,"software plagiarism, moss, cheating, academic integrity","Edinburgh, Scotland, UK",4,285?€?288,Association for Computing Machinery,L@S '16,TAPS: A MOSS Extension for Detecting Software Plagiarism at Scale,https://doi.org/10.1145/2876034.2893435,2016
inproceedings,10.1145/2876034.2893436,"Flashcards are a popular study tool for exploiting the spacing effect -- the phenomenon in which periodic, spaced review of educational content improves long-term retention. The Leitner system is a simple heuristic algorithm for scheduling reviews such that forgotten items are reviewed more frequently than recalled items. We propose a formalization of the Leitner system as a queueing network model, and formulate optimal review scheduling as a throughput-maximization problem. Through simulations and theoretical analysis, we find that the Leitner Queue Network (LQN) model has desirable properties and gives insight into general principles for spaced repetition.","New York, NY, USA",,"Reddy, Siddharth and Labutov, Igor and Banerjee, Siddhartha",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893436,9.78145E+12,"flashcard scheduling, spaced repetition","Edinburgh, Scotland, UK",4,289?€?292,Association for Computing Machinery,L@S '16,A Queueing Network Model for Spaced Repetition,https://doi.org/10.1145/2876034.2893436,2016
inproceedings,10.1145/2876034.2893437,"MOOCs offer valuable learning experiences to students from all around the world. In addition to providing filmed lectures, readings, and problem sets, many MOOCs allow students to ask and answer questions about course materials with each other through interactive user forums. However, in current MOOCs, only 3 to 5 percent of those students interact in the user forum (Breslow 2013, Ros\'{e} et al. 2014) and more than 90 percent of students stop attending the course altogether (Jordan 2014). According to prior studies, this low level of social engagement in MOOCs may lead to student attrition and low performance (Ren et al. 2007). Hence, a natural question that arises then is, how can we promote interaction among students in MOOC discussion forums in order to reduce students' attrition and raise their performance? In this paper, we conduct a field experiment on the edX platform to identify factors that promote student engagement in MOOC discussion forums. Researchers have discovered that the number of people interacting in one online location (e.g. group, community or virtual classroom size) is a key characteristic mediating user engagement (Butler et. al 2014), and most prior works have shown that users in a smaller size group participate more per person. However, contrary to prior research, our results show that the students in larger size cohorts interact more per person and that this greater interaction in turn increases student retention and performance.","New York, NY, USA",,"Baek, Jiye and Shore, Jesse",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893437,9.78145E+12,"discussion forum, student engagement, cohort size, performance, moocs, student retention","Edinburgh, Scotland, UK",4,293?€?296,Association for Computing Machinery,L@S '16,Promoting Student Engagement in MOOCs,https://doi.org/10.1145/2876034.2893437,2016
inproceedings,10.1145/2876034.2893438,"We are exploring the effects of social incentives and motivation on learner performance in a massive open online course. In the preliminary study that we report here, we asked learners if they wanted to be considered for a community TAship in a subsequent offering of the course, if they finished in the top 20% of those who completed the current course instance. We prompted students near the beginning of the course and in the middle of the course. This prompt appears to have had a significant, albeit small effect on learner completion when given early in the course. The prompt had no significant effect when given later in the course. We also discuss our plans to follow-up this study.","New York, NY, USA",,"Brady, Katherine and Fisher, Douglas and Narasimham, Gayathri",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893438,9.78145E+12,"incentives, community tas, completion","Edinburgh, Scotland, UK",4,297?€?300,Association for Computing Machinery,L@S '16,Exploring the Effects of Lightweight Social Incentives on Learner Performance in MOOCs,https://doi.org/10.1145/2876034.2893438,2016
inproceedings,10.1145/2876034.2893439,"This work examines whether templates designed from principles of multimedia learning design, and learning sciences research, can support peer instruction in creating more effective educational content on the web. Initial results show that the structure and guidelines within these templates can help novices produce meaningful learning content while improving the overall learning experience. This experiment provides insights into how to design and implement structured outlines online for web users to share learning content, and potentially shift researchers' focus to more learner-centered online education.","New York, NY, USA",,"Ngoon, Tricia and Gamero-Garrido, Alexander and Klemmer, Scott",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893439,9.78145E+12,"learning, peer learning, online education, templates, peer instruction","Edinburgh, Scotland, UK",4,301?€?304,Association for Computing Machinery,L@S '16,Supporting Peer Instruction with Evidence-Based Online Instructional Templates,https://doi.org/10.1145/2876034.2893439,2016
inproceedings,10.1145/2876034.2893440,"Online learning environments are being deployed globally to offer learning opportunities to diverse student communities. We propose the deployment of such an environment in low-resource after-school settings across India. We draw on preliminary research conducted in summer 2015 that leveraged existing ties with an NGO working across 35 after-school classrooms. Our larger goal is to (1) support tutors in curating and distributing learning content to students, (2) engage students in a mobile, networked learning environment where they can share and collaborate, and (3) evaluate the feasibility of online learning environments for low-resource contexts. In this submission, our focus is on the first component.","New York, NY, USA",,"Vishwanath, Aditya and Kumar, Arkadeep and Kumar, Neha",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893440,9.78145E+12,"india, learning, hci, ictd","Edinburgh, Scotland, UK",4,305?€?308,Association for Computing Machinery,L@S '16,Learning about Teaching in Low-Resource Indian Contexts,https://doi.org/10.1145/2876034.2893440,2016
inproceedings,10.1145/2876034.2893441,"When undergraduate students are allowed to choose a time slot in which to take an exam from a large number of options (e.g., 40), the students exhibit strong preferences among the times. We found that students can be effectively modelled using constrained discrete choice theory to quantify these preferences from their observed behavior. The resulting models are suitable for load balancing when scheduling multiple concurrent exams and for capacity planning given a set schedule.","New York, NY, USA",,"West, Matthew and Zilles, Craig",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893441,9.78145E+12,"computerized testing, capacity planning, asynchronous exams, student modeling, discrete choice theory","Edinburgh, Scotland, UK",4,309?€?312,Association for Computing Machinery,L@S '16,Modeling Student Scheduling Preferences in a Computer-Based Testing Facility,https://doi.org/10.1145/2876034.2893441,2016
inproceedings,10.1145/2876034.2893442,"Learning-by-doing in MOOCs may be enhanced by embedding intelligent tutoring systems (ITSs). ITSs support learning-by-doing by guiding learners through complex practice problems while adapting to differences among learners. We extended the Cognitive Tutor Authoring Tools (CTAT), a widely-used non-programmer tool kit for building intelligent tutors, so that CTAT-built tutors can be embedded in MOOCs and e-learning platforms. We demonstrated the technical feasibility of this integration by adding simple CTAT-built tutors to an edX MOOC, ""Big Data in Education."" To the best of our knowledge, this integration is the first occasion that material created through an open-access non-programmer authoring tool for full-fledged ITS has been integrated in a MOOC. The work offers examples of key steps that may be useful in other ITS-MOOC integration efforts, together with reflections on strengths, weaknesses, and future possibilities.","New York, NY, USA",,"Aleven, Vincent and Baker, Ryan and Wang, Yuan and Sewall, Jonathan and Popescu, Octav",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893442,9.78145E+12,"interoperability, itss, moocs, intelligent tutoring systems, log data analysis, feasibility study","Edinburgh, Scotland, UK",4,313?€?316,Association for Computing Machinery,L@S '16,Bringing Non-Programmer Authoring of Intelligent Tutors to MOOCs,https://doi.org/10.1145/2876034.2893442,2016
inproceedings,10.1145/2876034.2893443,"We seek to automatically identify which items to include in a set of curriculum, and how to adaptively select these items, in order to maximize student performance on some specified set of learning objectives. Our experimental results with a histogram tutoring system suggest that Bayesian Optimization can quickly (with only a small amount of student data) find good parameters, and may help instructors identify misalignment between their course, and their desired learning objectives.","New York, NY, USA",,"Antonova, Rika and Runde, Joe and Lee, Min Hyung and Brunskill, Emma",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893443,9.78145E+12,"machine learning, automated instructional design, data-driven improvement","Edinburgh, Scotland, UK",4,317?€?320,Association for Computing Machinery,L@S '16,Automatically Learning to Teach to the Learning Objectives,https://doi.org/10.1145/2876034.2893443,2016
inproceedings,10.1145/2876034.2893444,"Modern deep neural networks have achieved impressive results in a variety of automated tasks, such as text generation, grammar learning, and speech recognition. This paper discusses how education research might leverage recurrent neural network architectures in two small case studies. Specifically, we train a two-layer Long Short-Term Memory (LSTM) network on two distinct forms of education data: (1) essays written by students in a summative environment, and (2) MOOC clickstream data. Without any features specified beforehand, the network attempts to learn the underlying structure of the input sequences. After training, the model can be used generatively to produce new sequences with the same underlying patterns exhibited by the input distribution. These early explorations demonstrate the potential for applying deep learning techniques to large education data sets.","New York, NY, USA",,"Tang, Steven and Peterson, Joshua C. and Pardos, Zachary A.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893444,9.78145E+12,"deep learning, educational data mining, long short-term memory","Edinburgh, Scotland, UK",4,321?€?324,Association for Computing Machinery,L@S '16,Deep Neural Networks and How They Apply to Sequential Education Data,https://doi.org/10.1145/2876034.2893444,2016
inproceedings,10.1145/2876034.2893400,"Writing a thesis is no less challenging a task for students, than for organizations who instruct and tutor thesis writing at higher education institutions. Annually within just our departments, 1000 undergraduates face the task of writing a thesis. Increasing student numbers and stagnating resources pose management problems, as well as constant threats to the quality of instruction. In reaction to this, we started exploring how instruction and supervision of thesis writers and related administrative tasks could be electronically supported, allowing for scale effects.A learning environment named Thesis Writer (TW) was developed, and piloted during the fall of 2015. TW supports individual writing and collaboration between writers, peers, tutors, and supervisors. This web-based software runs in common web browsers, independently of the operating system.In this paper we highlight the core functions of TW and address such uses in which scale effects can be realized. Conference attendees can use and test the system including real-time collaboration, in either English or German, and discuss experiences made and data collected during the pilot by 300 BA students.","New York, NY, USA",,"Rapp, Christian and Kruse, Otto",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893400,9.78145E+12,"academic writing, research-based learning, technology enhanced learning, learning to write","Edinburgh, Scotland, UK",2,325?€?326,Association for Computing Machinery,L@S '16,Thesis Writer (TW): Tapping Scale Effects in Academic Writing Instruction,https://doi.org/10.1145/2876034.2893400,2016
inproceedings,10.1145/2876034.2893401,"Faculty development in the area of emerging technologies is demanding and resource intensive. This increases when aiming to qualify instructors to support their teaching virtually, e.g. in blended- and distance learning environments. Most elements of instructional design, delivery, and assessment require rethinking for technology integration. It is also a challenge to develop a sound instructional design model and corresponding teaching materials for courses aimed at developing the necessary skills and competences among staff. With ""e-Tutor"" a corresponding certificate course was developed at Ankara University, Turkey, a country for which, due to its geographical size and population, e-Learning is now highly popular. Under a project funded by the Swiss National Science Foundation, the course was translated into English, Russian, and Ukrainian, and then made accessible as an Open Educational Resource under Creative Commons Licence. Delivered in Turkish since 2011 with 350 participants, the course has also been successfully conducted with 300 participants from 11 countries in English, and with 320 participants in Ukrainian. This paper will briefly introduce the course design and its resources, before addressing to what extent it allows for scaling effects in staff development.","New York, NY, USA",,"Rapp, Christian and G\""{u}lbahar, Yasemin",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893401,9.78145E+12,"e-learning, e-tutoring, faculty development, train-the-trainer, e-competences","Edinburgh, Scotland, UK",2,327?€?328,Association for Computing Machinery,L@S '16,E-Tutor: Scaling Staff Development in the Area of e-Learning Competences,https://doi.org/10.1145/2876034.2893401,2016
inproceedings,10.1145/2876034.2893402,"Education is being powered by technology in many ways. One of the main advantages is making use of data to improve the learning process. The massive open online course (MOOC) phenomenon became viral some years ago, and with it many different platforms emerged. However most of them are proprietary solutions (i.e. Coursera, Udacity) and cannot be used by interested stakeholders. At the moment Open edX is placed as the primary open source application to support MOOCs. The community using Open edX is growing at a fast pace with many interested institutions. Nevertheless, the learning analytics support of Open edX is still in its first steps. In this paper we present an overview and demonstration of ANALYSE, an open source learning analytics tool for Open edX. ANALYSE includes currently 12 new visualizations that can be used by both instructors and students.","New York, NY, USA",,"Pijeira D\'{\i}az, H\'{e}ctor J. and Santofimia Ruiz, Javier and Ruip\'{e}rez-Valiente, Jos\'{e} A. and Mu\~{n}oz-Merino, Pedro J. and Delgado Kloos, Carlos",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893402,9.78145E+12,"open edx, learning analytics, visualizations, moocs","Edinburgh, Scotland, UK",2,329?€?330,Association for Computing Machinery,L@S '16,A Demonstration of ANALYSE: A Learning Analytics Tool for Open EdX,https://doi.org/10.1145/2876034.2893402,2016
inproceedings,10.1145/2876034.2893403,"We will demonstrate the Beetle-Grow intelligent tutoring system, which combines active experimentation, self-explanation, and formative feedback using natural language interaction. It runs in a standard web browser and has a fresh, engaging design. The underlying back-end system has previously been shown to be highly effective in teaching basic electricity and electronics concepts.Beetle-Grow has been designed to capture student interaction and indicators of learning in a form suitable for data mining, and to support future work on building tools for interactive tutoring that improve after experiencing interaction with students, as human tutors do.We are interested in partnering with teachers and other education researchers to carry out large-scale user trials with Beetle-Grow in the classroom and remotely.","New York, NY, USA",,"Farrow, Elaine and Moore, Johanna D.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893403,9.78145E+12,"intelligent tutoring, natural language, physics, conceptual learning, electronics, interaction data","Edinburgh, Scotland, UK",2,331?€?332,Association for Computing Machinery,L@S '16,Beetle-Grow: An Effective Intelligent Tutoring System to Support Conceptual Change,https://doi.org/10.1145/2876034.2893403,2016
inproceedings,10.1145/2876034.2893404,"An interactive demonstration on how to design and implement randomized controlled experiments at scale within the ASSISTments TestBed, a new collaborative for educational research funded by the National Science Foundation (NSF). The Assessment of Learning infrastructure (ALI), a unique data retrieval and analysis tool, is also demonstrated.","New York, NY, USA",,"Ostrow, Korinn S. and Heffernan, Neil T.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893404,9.78145E+12,"assistments testbed, randomized controlled experimentation at scale, assessment of learning infrastructure, authentic learning environments","Edinburgh, Scotland, UK",2,333?€?334,Association for Computing Machinery,L@S '16,Studying Learning at Scale with the ASSISTments TestBed,https://doi.org/10.1145/2876034.2893404,2016
inproceedings,10.1145/2876034.2893405,"Staff from edX, MIT, and Harvard will present two instructor dashboards for edX MOOCs. Current workflows will be described, from parsing and displaying data to using dashboards for course revision. A major focus will be lessons learned in the first two years of deployment.","New York, NY, USA",,"Fredericks, Colin and Lopez, Glenn and Shnayder, Victor and Rayyan, Saif and Seaton, Daniel",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893405,9.78145E+12,"edx, analytics, instructor, mooc, dashboard","Edinburgh, Scotland, UK",2,335?€?336,Association for Computing Machinery,L@S '16,Instructor Dashboards In EdX,https://doi.org/10.1145/2876034.2893405,2016
inproceedings,10.1145/2876034.2893406,"We present Elice, an online CS (computer science) education platform, and Elivate, a system for (i) taking student learning data from Elice, (ii) inferring their progress through an educational taxonomy tailored for programming education, and (iii) generating the real-time assistance for students and lecturers. Online courses suffer from high average attrition rates, and early prediction can enable early personalized feedback to motivate and assist students who may be having difficulties. Elice captures detailed student learning activities including intermediate revisions of code as students make progress toward completing their programming exercises and timestamps of student logins and submissions. Elivate then takes those data to analyze each student's progress and estimate the time to completion. In doing so, Elivate uses a learning taxonomy and automatic clustering of source code revisions. Using more than 240,000 code revisions generated by 1,000 students, we demonstrate how Elivate processes large-scale student data and generates appropriate real-time feedback for students.","New York, NY, USA",,"Kim, Suin and Kim, Jae Won and Park, Jungkook and Oh, Alice",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2893406,9.78145E+12,"online education, collaborative learning, online programming, social learning, computer science education","Edinburgh, Scotland, UK",2,337?€?338,Association for Computing Machinery,L@S '16,Elivate: A Real-Time Assistant for Students and Lecturers as Part of an Online CS Education Platform,https://doi.org/10.1145/2876034.2893406,2016
inproceedings,10.1145/2876034.2896321,"For the past four years The Open University has published annual Innovating Pedagogy reports. Our aim has been to shift the focus of horizon scanning for education away from novel technologies towards new forms of teaching, learning and assessment for an interactive world, to guide teachers and policy makers in productive innovation. In the most recent report, from over thirty pedagogies, ranging from bricolage to stealth assessment, we have identified six overarching themes, of scale, connectivity, reflection, extension, embodiment, and personalisation [8]. Delivering education at massive scale has been the headline innovation of the past four years. This success begs the question of ""which pedagogies can work successfully at scale?"".Sports coaching is an example of teaching that does not scale. It involves monitoring and diagnosis of an individual's performance, based on holistic observation of body movements, followed by personal tutoring and posture adjustments. Any of these elements might be deployed at scale (for example, diagnostic learning analytics [10], or AI-based personal tutoring [4] but in combination they require the physical presence of a human coach.The major xMOOC platforms were initially based on an instructivist pedagogy of a repeated cycle of inform and test. This has the benefit of being relatively impervious to scale. A lecture can be presented to 200 students in a theatre or to 20,000 viewers online with similar impact. Delivered on personal computers, instructivist pedagogy offers elements of personalisation, by providing adaptive feedback on quiz answers and alternative routes through the content.","New York, NY, USA",,"Sharples, Mike",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2896321,9.78145E+12,,"Edinburgh, Scotland, UK",2,339?€?340,Association for Computing Machinery,L@S '16,Effective Pedagogy at Scale: Social Learning and Citizen Inquiry,https://doi.org/10.1145/2876034.2896321,2016
inproceedings,10.1145/2876034.2876038,"Student assessments are important because they allow collecting evidence about learning. However, time spent on evaluating students may be otherwise used for instructional activities. Computer-based learning platforms provide the opportunity for unobtrusively gathering students' digital learning footprints. This data can be used to track learning progress and make inference about student competencies. We present a novel data analysis pipeline, Student Proficiency Inferrer from Game data (SPRING), that allows modeling game playing behavior in educational games. Unlike prior work, SPRING is a fully data-driven method that does not require costly domain knowledge engineering. Moreover, it produces a simple interpretable model that not only fits the data but also predicts learning outcomes. We validate our framework using data collected from students playing 11 educational mini-games. Our results suggest that SPRING can predict math assessments accurately on withheld test data (Correlation=0.55, Spearman rho=0.51).","New York, NY, USA",,"Falakmasir, Mohammad H. and Gonzalez-Brenes, Jos\'{e} P. and Gordon, Geoffrey J. and DiCerbo, Kristen E.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876038,9.78145E+12,"educational games, student modeling, hidden markov models, stealth assessment","Edinburgh, Scotland, UK",9,341?€?349,Association for Computing Machinery,L@S '16,A Data-Driven Approach for Inferring Student Proficiency from Game Activity Logs,https://doi.org/10.1145/2876034.2876038,2016
inproceedings,10.1145/2876034.2876049,"Automated grading is essential for scaling up learning. In this paper, we conduct the first systematic study of how to automate grading of a complex assignment using a medical case assessment as a test case. We propose to solve this problem using a supervised learning approach and introduce three general complementary types of feature representations of such complex assignments for use in supervised learning. We first show with empirical experiments that it is feasible to automate grading of such assignments provided that the instructor can grade a number of examples. We further study how to integrate an automated grader with human grading and propose to frame the problem as learning to rank assignments to exploit pairwise preference judgments and use NDPM as a measure for evaluation of the accuracy of ranking. We then propose a sequential pairwise online active learning strategy to minimize the effort of human grading and optimize the collaboration of human graders and an automated grader. Experiment results show that this strategy is indeed effective and can substantially reduce human effort as compared with randomly sampling assignments for manual grading.","New York, NY, USA",,"Geigle, Chase and Zhai, ChengXiang and Ferguson, Duncan C.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876049,9.78145E+12,"active learning, text mining, supervised learning, ordinal regression, learning to rank, automatic grading","Edinburgh, Scotland, UK",10,351?€?360,Association for Computing Machinery,L@S '16,An Exploration of Automated Grading of Complex Assignments,https://doi.org/10.1145/2876034.2876049,2016
inproceedings,10.1145/2876034.2876050,"Scaffolded projects with automated feedback are core instructional components of many massive courses. In subjects that include programming, feedback is typically provided by test cases constructed manually by the instructor. This paper explores the effectiveness of fuzz testing, a randomized technique for verifying the behavior of programs. In particular, we apply fuzz testing to identify when a student's solution differs in behavior from a reference implementation by randomly exploring the space of legal inputs to a program. Fuzz testing serves as a useful complement to manually constructed tests. Instructors can concentrate on designing targeted tests that focus attention on specific issues while using fuzz testing for comprehensive error checking. In the first project of a 1,400-student introductory computer science course, fuzz testing caught errors that were missed by a suite of targeted test cases for more than 48% of students. As a result, the students dedicated substantially more effort to mastering the nuances of the assignment.","New York, NY, USA",,"Sridhara, Sumukh and Hou, Brian and Lu, Jeffrey and DeNero, John",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876050,9.78145E+12,"online learning, behavioral analytics, automated assessment","Edinburgh, Scotland, UK",7,361?€?367,Association for Computing Machinery,L@S '16,Fuzz Testing Projects in Massive Courses,https://doi.org/10.1145/2876034.2876050,2016
inproceedings,10.1145/2876034.2876036,"Peer grading is the process of students reviewing each others' work, such as homework submissions, and has lately become a popular mechanism used in massive open online courses (MOOCs). Intrigued by this idea, we used it in a course on algorithms and data structures at the University of Hamburg. Throughout the whole semester, students repeatedly handed in submissions to exercises, which were then evaluated both by teaching assistants and by a peer grading mechanism, yielding a large dataset of teacher and peer grades. We applied different statistical and machine learning methods to aggregate the peer grades in order to come up with accurate final grades for the submissions (supervised and unsupervised, methods based on numeric scores and ordinal rankings). Surprisingly, none of them improves over the baseline of using the mean peer grade as the final grade. We discuss a number of possible explanations for these results and present a thorough analysis of the generated dataset.","New York, NY, USA",,"Sajjadi, Mehdi S.M. and Alamgir, Morteza and von Luxburg, Ulrike",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876036,9.78145E+12,"l@s, peer review, peer assessment, peer grading, ordinal analysis, rank aggregation, machine learning","Edinburgh, Scotland, UK",10,369?€?378,Association for Computing Machinery,L@S '16,Peer Grading in a Course on Algorithms and Data Structures: Machine Learning Algorithms Do Not Improve over Simple Baselines,https://doi.org/10.1145/2876034.2876036,2016
inproceedings,10.1145/2876034.2876042,"While explanations may help people learn by providing information about why an answer is correct, many problems on online platforms lack high-quality explanations. This paper presents AXIS (Adaptive eXplanation Improvement System), a system for obtaining explanations. AXIS asks learners to generate, revise, and evaluate explanations as they solve a problem, and then uses machine learning to dynamically determine which explanation to present to a future learner, based on previous learners' collective input. Results from a case study deployment and a randomized experiment demonstrate that AXIS elicits and identifies explanations that learners find helpful. Providing explanations from AXIS also objectively enhanced learning, when compared to the default practice where learners solved problems and received answers without explanations. The rated quality and learning benefit of AXIS explanations did not differ from explanations generated by an experienced instructor.","New York, NY, USA",,"Williams, Joseph Jay and Kim, Juho and Rafferty, Anna and Maldonado, Samuel and Gajos, Krzysztof Z. and Lasecki, Walter S. and Heffernan, Neil",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876042,9.78145E+12,"learning at scale, explanation, machine learning, learnersourcing, crowdsourcing, adaptive learning","Edinburgh, Scotland, UK",10,379?€?388,Association for Computing Machinery,L@S '16,AXIS: Generating Explanations at Scale with Learnersourcing and Machine Learning,https://doi.org/10.1145/2876034.2876042,2016
inproceedings,10.1145/2876034.2876043,"Massive Open Online Courses (MOOCs) have revolutionized higher education by offering university-like courses for a large amount of learners via the Internet. The paper at hand takes a closer look on peer assessment as a tool for delivering individualized feedback and engaging assignments to MOOC participants. Benefits, such as scalability for MOOCs and higher order learning, and challenges, such as grading accuracy and rogue reviewers, are described. Common practices and the state-of-the-art to counteract challenges are highlighted. Based on this research, the paper at hand describes a peer assessment workflow and its implementation on the openHPI and openSAP MOOC platforms. This workflow combines the best practices of existing peer assessment tools and introduces some small but crucial improvements.","New York, NY, USA",,"Staubitz, Thomas and Petrick, Dominic and Bauer, Matthias and Renz, Jan and Meinel, Christoph",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876043,9.78145E+12,"assessment., online learning, mooc, peer assessment","Edinburgh, Scotland, UK",10,389?€?398,Association for Computing Machinery,L@S '16,Improving the Peer Assessment Experience on MOOC Platforms,https://doi.org/10.1145/2876034.2876043,2016
inproceedings,10.1145/2876034.2876044,"Large classes, both online and residential, typically demand many graders for evaluating students' written work. Some classes attempt to use autograding or peer grading, but these both present challenges to assigning grades at for-credit institutions, such as the difficulty of autograding to evaluate free-response answers and the lack of expert oversight in peer grading. In a large, online class at Georgia Tech in Summer 2015, we experimented with a new approach to grading: framing graders as meta-reviewers, charged with evaluating the original work in the context of peer reviews. To evaluate this approach, we conducted a pair of controlled experiments and a handful of qualitative analyses. We found that having access to peer reviews improves the perceived quality of feedback provided by graders without decreasing the graders' efficiency and with only a small influence on the grades assigned.","New York, NY, USA",,"Joyner, David A. and Ashby, Wade and Irish, Liam and Lam, Yeeling and Langston, Jacob and Lupiani, Isabel and Lustig, Mike and Pettoruto, Paige and Sheahen, Dana and Smiley, Angela and Bruckman, Amy and Goel, Ashok",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876044,9.78145E+12,"peer review, online education.","Edinburgh, Scotland, UK",10,399?€?408,Association for Computing Machinery,L@S '16,Graders as Meta-Reviewers: Simultaneously Scaling and Improving Expert Evaluation for Large Online Classrooms,https://doi.org/10.1145/2876034.2876044,2016
inproceedings,10.1145/2876034.2876035,"The rising number of Massive Open Online Courses (MOOCs) enable people to advance their knowledge and competencies in a wide range of fields. Learning though is only the first step, the transfer of the taught concepts into practice is equally important and often neglected in the investigation of MOOCs. In this paper, we consider the specific case of FP101x (a functional programming MOOC on edX) and the extent to which learners alter their programming behaviour after having taken the course. We are able to link about one third of all FP101x learners to GitHub, the most popular social coding platform to date and contribute a first exploratory analysis of learner behaviour beyond the MOOC platform. A detailed longitudinal analysis of GitHub log traces reveals that (i) more than 8% of engaged learners transfer, and that (ii) most existing transfer learning findings from the classroom setting are indeed applicable in the MOOC setting as well.","New York, NY, USA",,"Chen, Guanliang and Davis, Dan and Hauff, Claudia and Houben, Geert-Jan",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876035,9.78145E+12,"functional programming, moocs, transfer learning, github","Edinburgh, Scotland, UK",10,409?€?418,Association for Computing Machinery,L@S '16,Learning Transfer: Does It Take Place in MOOCs? An Investigation into the Uptake of Functional Programming in Practice,https://doi.org/10.1145/2876034.2876035,2016
inproceedings,10.1145/2876034.2876047,"The Massive Open Online Courses (MOOC) have experienced rapid development. However, high dropout rate has become a salient issue. Many studies have attempted to understand this phenomenon; other have explored mechanisms for enhancing retention. For instance, social media has been used to improve student engagement and retention. However there is a lack of (1) empirical studies of social media use and engagement compared to embedded MOOC forums; and (2) rationales for social media use from both instructors' and students' perspectives. We addressed these open issues through the collection and analysis of real usage data from three MOOC forums and their associated social media (i.e., Facebook) groups as well as conducting interviews of instructors and students. We found that students show higher engagement and retention in social media than in MOOC forums, and identified both instructors' and students' perspectives that lead to the results. We discuss design implications for future MOOC platforms.","New York, NY, USA",,"Zheng, Saijing and Han, Kyungsik and Rosson, Mary Beth and Carroll, John M.",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876047,9.78145E+12,"social media, facebook, moocs, coursera, mixed method, massive open online course","Edinburgh, Scotland, UK",10,419?€?428,Association for Computing Machinery,L@S '16,The Role of Social Media in MOOCs: How to Use Social Media to Enhance Student Retention,https://doi.org/10.1145/2876034.2876047,2016
inproceedings,10.1145/2876034.2876054,"Massive scale education has emerged through online tools such as Wikipedia, Khan Academy, and MOOCs. The number of students being reached is high, but what about the quality of the educational experience? As we scale learning, we need to scale research to address this question. Such learning research should not just determine whether high quality has been achieved, but it should provide a process for how to reliably produce high quality learning. Scaling practical learning research is as much an opportunity as a problem. The opportunity comes from the fact that online courses are not only good for widespread delivery, but are natural vehicles for data collection and experimental instrumentation. I will provide examples of research done in the context of widely used educational technologies that both contribute interesting scientific findings and have practical implications for increasing the quality of learning at scale.","New York, NY, USA",,"Koedinger, Ken",Proceedings of the Third (2016) ACM Conference on Learning @ Scale,10.1145/2876034.2876054,9.78145E+12,,"Edinburgh, Scotland, UK",1,429,Association for Computing Machinery,L@S '16,Practical Learning Research at Scale,https://doi.org/10.1145/2876034.2876054,2016
inproceedings,10.1145/3247485,,"New York, NY, USA",,"Kiczales, Gregor",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/3247485,9.78145E+12,,"Vancouver, BC, Canada",,,Association for Computing Machinery,L@S '15,Session Details: Opening Keynote Address,https://doi.org/10.1145/3247485,2015
inproceedings,10.1145/2724660.2724684,"Most of the current research on improving learning outcomes focuses on a small subset of variables of an immensely multi-dimensional space of the learning ecosystem. Most digital learning tools primarily focus on individual students, other research focuses only on teacher professional development, or only on curriculum improvement. In this talk I will describe our efforts on how to discover optimal parameters of the entire ecosystem that considers student factors (engagement and mastery), classroom factors (blended learning variations and group learning variations), curriculum factors (multidimensional variation of existing curricula), and teacher factors (in-class tools that mitigate weaknesses, and promote teacher development). I will describe our work on algorithms to discover optimal learning pathways in this high-dimensional space. I will conclude with the outcomes of deploying a portion of our platform on algebra challenges conducted on two US states and the country of Norway.Zoran Popovic is a Director of Center for Game Science at University of Washington and founder of Enlearn. Trained as a computer scientist his research focus is on creating interactive engaging environments for learning and scientific discovery. His laboratory created Foldit, a biochemistry game that produced three Nature publications in just two years, an award-winning math learning games played by over five million learners worldwide.He is currently focusing on engaging methods that can rapidly develop experts in arbitrary domains with particular focus on revolutionizing K-12 math education. His Algebra Challenges conducted in Washington, Minnesota, and Norway, have shown that 96% of children even in elementary school can learn key algebra concepts in 1.5 hours. He has recently founded Enlearn to apply his work on generative adaptation to any curricula towards the goal of achieving full mastery by 95% of students. His contributions to the field of interactive computer graphics have been recognized by a number of awards including the NSF CAREER Award, Alfred P. Sloan Fellowship and ACM SIGGRAPH Significant New Researcher Award.","New York, NY, USA",,"Popovic, Zoran",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724684,9.78145E+12,,"Vancouver, BC, Canada",1,1,Association for Computing Machinery,L@S '15,Achieving 96% Mastery at National Scale through Inspired Learning and Generative Adaptivity,https://doi.org/10.1145/2724660.2724684,2015
inproceedings,10.1145/2724660.2724661,"Automated writing evaluation (AWE) has been shown to be an effective mechanism for quickly providing feedback to students. It has already seen wide adoption in enterprise-scale applications and is starting to be adopted in large-scale contexts. Training an AWE model has historically required a single batch of several hundred writing examples and human scores for each of them. This requirement limits large-scale adoption of AWE since human-scoring essays is costly. Here we evaluate algorithms for ensuring that AWE models are consistently trained using the most informative essays. Our results show how to minimize training set sizes while maximizing predictive performance, thereby reducing cost without unduly sacrificing accuracy. We conclude with a discussion of how to integrate this approach into large-scale AWE systems.","New York, NY, USA",,"Dronen, Nicholas and Foltz, Peter W. and Habermehl, Kyle",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724661,9.78145E+12,automated essay scoring,"Vancouver, BC, Canada",8,3?€?10,Association for Computing Machinery,L@S '15,Effective Sampling for Large-Scale Automated Writing Evaluation Systems,https://doi.org/10.1145/2724660.2724661,2015
inproceedings,10.1145/2724660.2724667,"Student modeling within intelligent tutoring systems is a task largely driven by binary models that predict student knowledge or next problem correctness (i.e., Knowledge Tracing (KT)). However, using a binary construct for student assessment often causes researchers to overlook the feedback innate to these platforms. The present study considers a novel method of tabling an algorithmically determined partial credit score and problem difficulty bin for each student's current problem to predict both binary and partial next problem correctness. This study was conducted using log files from ASSISTments, an adaptive mathematics tutor, from the 2012-2013 school year. The dataset consisted of 338,297 problem logs linked to 15,253 unique student identification numbers. Findings suggest that an efficiently tabled model considering partial credit and problem difficulty performs about as well as KT on binary predictions of next problem correctness. This method provides the groundwork for modifying KT in an attempt to optimize student modeling.","New York, NY, USA",,"Ostrow, Korinn and Donnelly, Christopher and Adjei, Seth and Heffernan, Neil",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724667,9.78145E+12,"tabling method, knowledge tracing, problem difficulty, partial credit, student modeling, next problem correctness","Vancouver, BC, Canada",10,11?€?20,Association for Computing Machinery,L@S '15,Improving Student Modeling Through Partial Credit and Problem Difficulty,https://doi.org/10.1145/2724660.2724667,2015
inproceedings,10.1145/2724660.2724669,"Massive open online course (MOOC) platforms increasingly allow easily implemented randomized experiments. The heterogeneity of MOOC students, however, leads to two methodological obstacles in analyzing interventions to increase engagement. (1) Many MOOC participation metrics have distributions with substantial positive skew from highly active users as well as zero-inflation from high attrition. (2) High attrition means that in some experimental designs, most users assigned to the treatment never receive it; analyses that do not consider attrition result in ""intent-to-treat"" (ITT) estimates that underestimate the true effects of interventions. We address these challenges in analyzing an intervention to improve forum participation in the 2014 JusticeX course offered on the edX MOOC platform. We compare the results of four ITT models (OLS, logistic, quantile, and zero-inflated negative binomial regressions) and three ""treatment-on-treated"" (TOT) models (Wald estimator, 2SLS with a second stage logistic model, and instrumental variables quantile regression). A combination of logistic, quantile, and zero-inflated negative binomial regressions provide the most comprehensive description of the ITT effects. TOT methods then adjust the ITT underestimates. Substantively, we demonstrate that self-assessment questions about forum participation encourage more students to engage in forums and increases the participation of already active students.","New York, NY, USA",,"Lamb, Anne and Smilack, Jascha and Ho, Andrew and Reich, Justin",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724669,9.78145E+12,"engagement, randomized controlled trials, a/b testing, attrition, zero-inflation, moocs, treatment-on-treated","Vancouver, BC, Canada",10,21?€?30,Association for Computing Machinery,L@S '15,Addressing Common Analytic Challenges to Randomized Experiments in MOOCs: Attrition and Zero-Inflation,https://doi.org/10.1145/2724660.2724669,2015
inproceedings,10.1145/2724660.2724676,"When students work with peers, they learn more actively, build richer knowledge structures, and connect material to their lives. However, not every peer learning experience online sees successful adoption. This paper articulates and addresses three adoption challenges for global-scale peer learning. First, peer interactions struggle to bootstrap critical mass. However, class incentives can signal importance and spur initial usage. Second, online classes have limited peer visibility and awareness, so students often feel alone even when surrounded by peers. We find that highlighting interdependence and strengthening norms can mitigate this issue. Third, teachers can readily access ""big"" aggregate data but not ""thick"" contextual data that helps build intuitions, so software should guide teachers' scaffolding of peer interactions. We illustrate these challenges through studying 8,500 students' usage of two peer learning platforms, Talkabout and PeerStudio. This paper measures efficacy through sign-up and participation rates and the structure and duration of student interactions.","New York, NY, USA",,"Kotturi, Yasmine and Kulkarni, Chinmay E. and Bernstein, Michael S. and Klemmer, Scott",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724676,9.78145E+12,"online education, social learning., peer learning","Vancouver, BC, Canada",8,31?€?38,Association for Computing Machinery,L@S '15,Structure and Messaging Techniques for Online Peer Learning Systems That Increase Stickiness,https://doi.org/10.1145/2724660.2724676,2015
inproceedings,10.1145/2724660.2724675,"A large amount of research in the field of educational data analytics has focused primarily on student next problem correctness. Although the prediction of such information is useful in assessing current student performance, it is better for teachers and instructors to place attention on student knowledge over a longer period of time. Several researchers have articulated that it is important to predict aspects that are more meaningful, inspiring our work here to utilize the large amounts of student data available to derive more substantial predictions over student knowledge. Our goal in this paper is to utilize prerequisite information to better predict student knowledge quantitatively as a subsequent skill is begun. Learning systems like ASSISTments and Khan Academy already record such prerequisite information, and can therefore be used to construct a method of prediction as described in this paper. Using these inter-skill relationships, our method estimates students' initial knowledge based on performance on each prerequisite skill. We compare our method with the standard Knowledge Tracing (KT) model and majority class in terms of the predictive accuracy of students' first responses on subsequent skills. Our results support our method as a viable means of representing student prerequisite knowledge in a subsequent skill, leading to results that outperform the majority class and that are comparably superior to KT by providing more definitive student knowledge estimates without sacrificing predictive accuracy.","New York, NY, USA",,"Botelho, Anthony and Wan, Hao and Heffernan, Neil",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724675,9.78145E+12,"subsequent skills, knowledge tracing, initial knowledge, predicting student knowledge, prerequisite, first response prediction, mastery speed","Vancouver, BC, Canada",7,39?€?45,Association for Computing Machinery,L@S '15,The Prediction of Student First Response Using Prerequisite Skills,https://doi.org/10.1145/2724660.2724675,2015
inproceedings,10.1145/2724660.2724666,"Students in the developing world are frequently cited as being among the most important beneficiaries of online education initiatives such as massive open online courses (MOOCs). While some predict that online classrooms will replace physical classrooms, our experience suggests that blending online and in-person instruction is more likely to succeed in developing regions. However, very little research has actually been done on the effects of online education or blended learning in these environments. In this paper we describe a blended learning initiative that combines videos from a large online course with peer-led sessions for undergraduate technical education in India. We performed a randomized controlled trial (RCT) that indicates our intervention was associated with a small but significant improvement in performance on a summative exam. We discuss the results of the RCT and an ethnographic study of the intervention to make recommendations for future, scalable blended learning initiatives for places such as India.","New York, NY, USA",,"Cutrell, Edward and O'Neill, Jacki and Bala, Srinath and Nitish, B. and Cross, Andrew and Gupta, Nakull and Kumar, Viraj and Thies, William",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724666,9.78145E+12,"rct, blended learning, mooc, online education, massive open online course, india","Vancouver, BC, Canada",10,47?€?56,Association for Computing Machinery,L@S '15,Blended Learning in Indian Colleges with Massively Empowered Classroom,https://doi.org/10.1145/2724660.2724666,2015
inproceedings,10.1145/2724660.2724680,"Attrition in online learning is generally higher than in traditional settings, especially in large-scale online learning environments. A systematic analysis of individual differences in attrition and performance in 20 massive open online courses (N &gt; 67,000) revealed a geographic achievement gap and a gender achievement gap. Online learners in Africa, Asia, and Latin America scored substantially lower grades and were only half as likely to persist than those in Europe, Oceania, and Northern America. Women also exhibited lower persistence and performance than men. Yet more persistent learners were only marginally more satisfied with their achievement. The primary obstacle for most learners was finding time for the course, which was partly related to low levels of volitional control. Self-ascribed successful learners reported higher levels of goal striving, growth mindset, and feelings of social belonging than unsuccessful ones. Insights into why learners leave online courses inform models of attrition and targeted interventions to support learners achieve their goals.","New York, NY, USA",,"Kizilcec, Ren\'{e} F. and Halawa, Sherif",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724680,9.78145E+12,"social belonging, massive open online course, goal striving, mooc, self-regulation, volition, persistence, online education, individual differences, dropout, growth mindset","Vancouver, BC, Canada",10,57?€?66,Association for Computing Machinery,L@S '15,Attrition and Achievement Gaps in Online Learning,https://doi.org/10.1145/2724660.2724680,2015
inproceedings,10.1145/2724660.2724673,"Wheel-spinning refers to a phenomenon in which a student has spent a considerable amount of time practicing a skill, yet displays little or no progress towards mastery. Wheel-spinning has been shown to be a common problem affecting a significant number of students in different tutoring systems and is negatively associated with learning. In this study, we construct a model of wheel-spinning, using generic features easily calculated from most tutoring systems. We show that for two different systems' data, the model generalizes to future students very well and can detect wheel-spinning in an early stage with high accuracy. We also refine the scope of the wheel-spinning problem in two systems using the model's predictions.","New York, NY, USA",,"Gong, Yue and Beck, Joseph E.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724673,9.78145E+12,"wheel-spinning, behavioral detector, mastery learning, prediction, student modeling","Vancouver, BC, Canada",8,67?€?74,Association for Computing Machinery,L@S '15,Towards Detecting Wheel-Spinning: Future Failure in Mastery Learning,https://doi.org/10.1145/2724660.2724673,2015
inproceedings,10.1145/2724660.2724670,"Rapid feedback is a core component of mastery learning, but feedback on open-ended work requires days or weeks in most classes today. This paper introduces PeerStudio, an assessment platform that leverages the large number of students' peers in online classes to enable rapid feedback on in-progress work. Students submit their draft, give rubric-based feedback on two peers' drafts, and then receive peer feedback. Students can integrate the feedback and repeat this process as often as they desire. In MOOC deployments, the median student received feedback in just twenty minutes. Rapid feedback on in-progress work improves course outcomes: in a controlled experiment, students' final grades improved when feedback was delivered quickly, but not if delayed by 24 hours. More than 3,600 students have used PeerStudio in eight classes, both massive and in-person. This research demonstrates how large classes can leverage their scale to encourage mastery through rapid feedback and revision.","New York, NY, USA",,"Kulkarni, Chinmay E. and Bernstein, Michael S. and Klemmer, Scott R.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724670,9.78145E+12,"deliberate practice, peer assessment, mooc, peer learning, mastery learning","Vancouver, BC, Canada",10,75?€?84,Association for Computing Machinery,L@S '15,PeerStudio: Rapid Peer Feedback Emphasizes Revision and Improves Performance,https://doi.org/10.1145/2724660.2724670,2015
inproceedings,10.1145/2724660.2724671,"This study investigates chat room data from a massive open online course (MOOC) that has been organized several times since January 2012. What makes the organization unique is that the chat room has always remained the same, allowing past participants to mingle with the new course takers. Participants who have previously attended the course have started to support the novices, voluntarily taking the role of mentors, while at the same time also learning themselves. Two and a half years of chat logs and interviews show that it is possible that a community consisting of previous and current participants emerges naturally. Furthermore, there are plenty of students that unconditionally help others, even when they themselves no longer attend the course. Our observations suggest that communities of practice emerge naturally around the chat rooms of MOOCs.","New York, NY, USA",,"Nelimarkka, Matti and Vihavainen, Arto",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724671,9.78145E+12,"tenured mooc participant, massive open online course, mooc-alumni, online community, internet relay chat, community of practice","Vancouver, BC, Canada",9,85?€?93,Association for Computing Machinery,L@S '15,Alumni &amp; Tenured Participants in MOOCs: Analysis of Two Years of MOOC Discussion Channel Activity,https://doi.org/10.1145/2724660.2724671,2015
inproceedings,10.1145/2724660.2724665,"Many MOOCs report high drop off rates for their students. Among the factors reportedly contributing to this picture are lack of motivation, feelings of isolation, and lack of interactivity in MOOCs. This paper investigates the potential of gamification with social game elements for increasing retention and learning success. Students in our experiment showed a significant increase of 25% in retention period (videos watched) and 23% higher average scores when the course interface was gamified. Social game elements amplify this effect significantly -- students in this condition showed an increase of 50% in retention period and 40% higher average test scores.","New York, NY, USA",,"Krause, Markus and Mogalle, Marc and Pohl, Henning and Williams, Joseph Jay",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724665,9.78145E+12,"massive open online courses, social engagement, learning at scale, mooc, gamification","Vancouver, BC, Canada",8,95?€?102,Association for Computing Machinery,L@S '15,A Playful Game Changer: Fostering Student Retention in Online Education with Social Gamification,https://doi.org/10.1145/2724660.2724665,2015
inproceedings,10.1145/2724660.2724683,"In this paper, we address issues of transparency, modularity, and privacy with the introduction of an open source, web-based data repository and analysis tool tailored to the Massive Open Online Course community. The tool integrates data request/authorization and distribution workflows as well as a simple analytics module upload format to enable reuse and replication of analytics results among instructors and researchers. We survey the evolving landscape of competing data models, all of which can be accommodated in the platform. Data model descriptions are provided to analytics authors who choose, much like with smartphone app stores, to write for any number of data models depending on their needs and the proliferation of the particular data model. Two case study examples of analytics and interactive visualizations are described in the paper. The result is a simple but effective approach to learning analytics immediately applicable to X consortium institutions and beyond.","New York, NY, USA",,"Pardos, Zachary A. and Kao, Kevin",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724683,9.78145E+12,"reproducible research, edx, mooc, visualizations, open learning analytics, modularization, dashboards","Vancouver, BC, Canada",8,103?€?110,Association for Computing Machinery,L@S '15,MoocRP: An Open-Source Analytics Platform,https://doi.org/10.1145/2724660.2724683,2015
inproceedings,10.1145/2724660.2724681,"The printing press long ago and the computer today have made widespread access to information possible. Learning theorists have suggested, however, that mere information is a poor way to learn. Instead, more effective learning comes through doing. While the most popularized element of today's MOOCs are the video lectures, many MOOCs also include interactive activities that can afford learning by doing. This paper explores the learning benefits of the use of informational assets (e.g., videos and text) in MOOCs, versus the learning by doing opportunities that interactive activities provide. We find that students doing more activities learn more than students watching more videos or reading more pages. We estimate the learning benefit from extra doing (1 SD increase) to be more than six times that of extra watching or reading. Our data, from a psychology MOOC, is correlational in character, however we employ causal inference mechanisms to lend support for the claim that the associations we find are causal.","New York, NY, USA",,"Koedinger, Kenneth R. and Kim, Jihee and Jia, Julianna Zhuxin and McLaughlin, Elizabeth A. and Bier, Norman L.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724681,9.78145E+12,"oer, moocs, learning prediction, course effectiveness, learning by doing, open education","Vancouver, BC, Canada",10,111?€?120,Association for Computing Machinery,L@S '15,Learning is Not a Spectator Sport: Doing is Better than Watching for Learning from a MOOC,https://doi.org/10.1145/2724660.2724681,2015
inproceedings,10.1145/2724660.2724677,"Thousands of students enroll in Massive Open Online Courses~(MOOCs) to seek opportunities for learning and self-improvement. However, the learning process often involves struggles with confusion, which may have an adverse effect on the course participation experience, leading to dropout along the way. In this paper, we quantify that effect. We describe a classification model using discussion forum behavior and clickstream data to automatically identify posts that express confusion. We then apply survival analysis to quantify the impact of confusion on student dropout. The results demonstrate that the more confusion students express or are exposed to, the lower the probability of their retention. Receiving support and resolution of confusion helps mitigate this effect. We explore the differential effects of confusion expressed in different contexts and related to different aspects of courses. We conclude with implications for design of interventions towards improving the retention of students in MOOCs.","New York, NY, USA",,"Yang, Diyi and Wen, Miaomiao and Howley, Iris and Kraut, Robert and Rose, Carolyn",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724677,9.78145E+12,"survival analysis, massive open online courses (mooc), confusion","Vancouver, BC, Canada",10,121?€?130,Association for Computing Machinery,L@S '15,Exploring the Effect of Confusion in Discussion Forums of Massive Open Online Courses,https://doi.org/10.1145/2724660.2724677,2015
inproceedings,10.1145/2724660.2724674,"We analyzed informal learning in Scratch Online -- an online community with over 4.3 million users and 6.7 million user-generated content. Users develop projects, which are graphical interfaces involving manipulation of programming blocks. We investigated two fundamental questions: how can we model informal learning, and what patterns of informal learning emerge. We proceeded in two phases. First, we modeled learning as a trajectory of cumulative programming block usage by long-term users who created at least 50 projects. Second, we applied K-means++ clustering to uncover patterns of learning and corresponding subpopulations. We found four groups of users manifesting four different patterns of learning, ranging from the smallest to the largest improvement. At one end of the spectrum, users learned more and in a faster manner. At the opposite end, users did not show much learning, even after creating dozens of projects. The modeling and clustering of trajectory patterns that enabled us to quantitatively analyze informal learning may be applicable to other similar communities. The results can also support administrators of online communities in implementing customized interventions for specific subpopulations.","New York, NY, USA",,"Yang, Seungwon and Domeniconi, Carlotta and Revelle, Matt and Sweeney, Mack and Gelman, Ben U. and Beckley, Chris and Johri, Aditya",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724674,9.78145E+12,"online community, informal learning, clustering, learning analytics, scratch, programming, modeling","Vancouver, BC, Canada",10,131?€?140,Association for Computing Machinery,L@S '15,Uncovering Trajectories of Informal Learning in Large Online Communities of Creators,https://doi.org/10.1145/2724660.2724674,2015
inproceedings,10.1145/2724660.2724662,"Advances in open-online education have led to a dramatic increase in the size, diversity, and traceability of learner populations, offering tremendous opportunities to study detailed learning behavior of users around the world. This paper adapts the topic modeling approach of Latent Dirichlet Allocation (LDA) to uncover behavioral structure from student logs in a MITx Massive Open Online Course, 8.02x: Electricity and Magnetism. LDA is typically found in the field of natural language processing, where it identifies the latent topic structure within a collection of documents. However, this framework can be adapted for analysis of user-behavioral patterns by considering user interactions with courseware as a ``bag of interactions'' equivalent to the ``bag of words'' model found in topic modeling. By employing this representation, LDA forms probabilistic use cases that clusters students based on their behavior. Through the probability distributions associated with each use case, this approach provides an interpretable representation of user access patterns, while reducing the dimensionality of the data and improving accuracy. Using only the first week of logs, we can predict whether or not a student will earn a certificate with 0.81 ?? 0.01 cross-validation accuracy. Thus, the method presented in this paper is a powerful tool in understanding user behavior and predicting outcomes.","New York, NY, USA",,"Coleman, Cody A. and Seaton, Daniel T. and Chuang, Isaac",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724662,9.78145E+12,"latent dirichlet allocation, use case modeling, student behavior, massive open online courses","Vancouver, BC, Canada",8,141?€?148,Association for Computing Machinery,L@S '15,Probabilistic Use Cases: Discovering Behavioral Patterns for Predicting Certification,https://doi.org/10.1145/2724660.2724662,2015
inproceedings,10.1145/2724660.2724682,"We propose a novel automated grading system that can compare two multiview engineering drawings consisting of three views that may have allowable translations, scales, and offsets, and can recognize frequent error types as well as individual drawing errors. We show that translation, scale, and offset-invariant comparison can be conducted by estimating the affine transformation for each individual view within drawings. Our system directly aims to evaluate students' skills creating multiview engineering drawings. Since it is important for our students to be familiar with widely used software such as AutoCAD, our system does not require a separate interface or environment, but directly grades the saved DWG/DXF files from AutoCAD. We show the efficacy of the proposed algorithm by comparing its results with human grading. Beyond the advantages of convenience and accuracy, based on our data set of students' answers, we can analyze the common errors of the class as a whole using our system.","New York, NY, USA",,"Kwon, Youngwook Paul and McMains, Sara",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724682,9.78145E+12,"ransac, multiview engineering drawing, autograder, affine transformation estimation","Vancouver, BC, Canada",10,157?€?166,Association for Computing Machinery,L@S '15,An Automated Grading/Feedback System for 3-View Engineering Drawings Using RANSAC,https://doi.org/10.1145/2724660.2724682,2015
inproceedings,10.1145/2724660.2724664,"While computer and communication technologies have provided effective means to scale up many aspects of education, the submission and grading of assessments such as homework assignments and tests remains a weak link. In this paper, we study the problem of automatically grading the kinds of open response mathematical questions that figure prominently in STEM (science, technology, engineering, and mathematics) courses. Our data-driven framework for mathematical language processing (MLP) leverages solution data from a large number of learners to evaluate the correctness of their solutions, assign partial-credit scores, and provide feedback to each learner on the likely locations of any errors. MLP takes inspiration from the success of natural language processing for text data and comprises three main steps. First, we convert each solution to an open response mathematical question into a series of numerical features. Second, we cluster the features from several solutions to uncover the structures of correct, partially correct, and incorrect solutions. We develop two different clustering approaches, one that leverages generic clustering algorithms and one based on Bayesian nonparametrics. Third, we automatically grade the remaining (potentially large number of) solutions based on their assigned cluster and one instructor-provided grade per cluster. As a bonus, we can track the cluster assignment of each step of a multistep solution and determine when it departs from a cluster of correct solutions, which enables us to indicate the likely locations of errors to learners. We test and validate MLP on real-world MOOC data to demonstrate how it can substantially reduce the human effort required in large-scale educational platforms.","New York, NY, USA",,"Lan, Andrew S. and Vats, Divyanshu and Waters, Andrew E. and Baraniuk, Richard G.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724664,9.78145E+12,"machine learning, bayesian nonparametrics, feedback, mathematical language processing, automatic grading, clustering, assessment","Vancouver, BC, Canada",10,167?€?176,Association for Computing Machinery,L@S '15,Mathematical Language Processing: Automatic Grading and Feedback for Open Response Mathematical Questions,https://doi.org/10.1145/2724660.2724664,2015
inproceedings,10.1145/2724660.2724672,"Advances in online and computer supported education afford exciting opportunities to revolutionize the classroom, while also presenting a number of new challenges not faced in traditional educational settings. Foremost among these challenges is the problem of accurately and efficiently evaluating learner work as the class size grows, which is directly related to the larger goal of providing quality, timely, and actionable formative feedback. Recently there has been a surge in interest in using peer grading methods coupled with machine learning to accurately and fairly evaluate learner work while alleviating the instructor bottleneck and grading overload. Prior work in peer grading almost exclusively focuses on numerically scored grades -- either real-valued or ordinal. In this work, we consider the implications of peer ranking in which learners rank a small subset of peer work from strongest to weakest, and propose new types of computational analyses that can be applied to this ranking data. We adopt a Bayesian approach to the ranked peer grading problem and develop a novel model and method for utilizing ranked peer-grading data. We additionally develop a novel procedure for adaptively identifying which work should be ranked by particular peers in order to dynamically resolve ambiguity in the data and rapidly resolve a clearer picture of learner performance. We showcase our results on both synthetic and several real-world educational datasets.","New York, NY, USA",,"Waters, Andrew E. and Tinapple, David and Baraniuk, Richard G.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724672,9.78145E+12,"automatic grading, peer grading, adaptive recommender systems, rank aggregation, bayesian methods","Vancouver, BC, Canada",7,177?€?183,Association for Computing Machinery,L@S '15,BayesRank: A Bayesian Approach to Ranked Peer Grading,https://doi.org/10.1145/2724660.2724672,2015
inproceedings,10.1145/2724660.2724663,"We report on an experiment testing the effects of releasing all of the content in a Massive Open Online Course (MOOC) at launch versus in a staggered release. In 2013, HarvardX offered two ""runs"" of the HeroesX course: In the first, content was released weekly over four months; in the second, all content was released at once. We develop three operationalizations of ""ontrackness"" to measure how students participated in sync with the recommended syllabus. Ontrackness in both versions was low, though in the second, mean ontrackness was approximately one-half of levels in the first HeroesX. We find few differences in persistence, participation, and completion between the two runs. Controlling for a students' number of active weeks, we estimate modest positive effects of ontrackness on certification. The revealed preferences of students for flexibility and the minimal benefits of ontrackness suggest that releasing content all at once may be a viable strategy for MOOC designers.","New York, NY, USA",,"Mullaney, Tommy and Reich, Justin",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724663,9.78145E+12,"synchronicity, natural experiment, ontrackness, moocs","Vancouver, BC, Canada",10,185?€?194,Association for Computing Machinery,L@S '15,Staggered Versus All-At-Once Content Release in Massive Open Online Courses: Evaluating a Natural Experiment,https://doi.org/10.1145/2724660.2724663,2015
inproceedings,10.1145/2724660.2724668,"Exploring the whole sequence of steps a student takes to produce work, and the patterns that emerge from thousands of such sequences is fertile ground for a richer understanding of learning. In this paper we autonomously generate hints for the Code.org `Hour of Code,' (which is to the best of our knowledge the largest online course to date) using historical student data. We first develop a family of algorithms that can predict the way an expert teacher would encourage a student to make forward progress. Such predictions can form the basis for effective hint generation systems. The algorithms are more accurate than current state-of-the-art methods at recreating expert suggestions, are easy to implement and scale well. We then show that the same framework which motivated the hint generating algorithms suggests a sequence-based statistic that can be measured for each learner. We discover that this statistic is highly predictive of a student's future success.","New York, NY, USA",,"Piech, Chris and Sahami, Mehran and Huang, Jonathan and Guibas, Leonidas",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724668,9.78145E+12,"hint generation, educational datamining., problem solving policy","Vancouver, BC, Canada",10,195?€?204,Association for Computing Machinery,L@S '15,Autonomously Generating Hints by Inferring Problem Solving Policies,https://doi.org/10.1145/2724660.2724668,2015
inproceedings,10.1145/2724660.2724679,"Automatic assessment reduces the need for individual feedback in massive courses, but often focuses only on scoring solutions, rather than assessing whether students correctly understand problems. We present an enriched approach to automatic assessment that explicitly assists students in understanding the detailed specification of technical problems that they are asked to solve, in addition to evaluating their solutions. Students are given a suite of solution test cases, but they must first unlock each test case by validating its behavior before they are allowed to apply it to their proposed solution. When provided with this automated feedback early in the problem-solving process, students ask fewer clarificatory questions and express less confusion about assessments. As a result, instructors spend less time explaining problems to students. In a 1300-person university course, we observed that the vast majority of students chose to validate their understanding of test cases before attempting to solve problems. These students reported that the validation process improved their understanding.","New York, NY, USA",,"Basu, Soumya and Wu, Albert and Hou, Brian and DeNero, John",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2724679,9.78145E+12,"online learning, behavioral analytics, automated assessment","Vancouver, BC, Canada",9,205?€?213,Association for Computing Machinery,L@S '15,Problems Before Solutions: Automated Problem Clarification at Scale,https://doi.org/10.1145/2724660.2724679,2015
inproceedings,10.1145/2724660.2735205,"There is great enthusiasm for the idea that massive amounts of data from online interactions of learners with material can lead to a rapid improvement cycle, driven by analysis of the data, experimentation, and intervention to do more of what works and less of what doesn't. This talk discusses techniques for working with massive amounts of data.Peter Norvig is a Director of Research at Google Inc. Previously he was head of Google's core search algorithms group, and of NASA Ames's Computational Sciences Division, making him NASA's senior computer scientist. He received the NASA Exceptional Achievement Award in 2001. He has taught at the University of Southern California and the University of California at Berkeley, from which he received a Ph.D. in 1986 and the distinguished alumni award in 2006. He was co-teacher of an Artificial Intelligence class that signed up 160,000 students, helping to kick off the current round of massive open online classes. His publications include the books Artificial Intelligence: A Modern Approach (the leading textbook in the field), Paradigms of AI Programming: Case Studies in Common Lisp, Verbmobil: A Translation System for Face-to-Face Dialog, and Intelligent Help Systems for UNIX. He is also the author of the Gettysburg Powerpoint Presentation and the world's longest palindromic sentence. He is a fellow of the AAAI, ACM, California Academy of Science and American Academy of Arts &amp; Sciences.","New York, NY, USA",,"Norvig, Peter",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2735205,9.78145E+12,,"Vancouver, BC, Canada",1,215,Association for Computing Machinery,L@S '15,Machine Learning for Learning at Scale,https://doi.org/10.1145/2724660.2735205,2015
inproceedings,10.1145/2724660.2728662,"We report on the motivation and qualitative studies that examine the design of a sentiment and context collection tool in a mobile-enabled blended learning technology. The tool concept emerged from field studies with teachers and students from two primary schools in Kenya. In this paper, we discuss the background and motivation of learners sentiment and context. Next, we present the overall design of the proposed module and its prototype implementation in a blended learning environment. Detailed discussions on the algorithms underlying the tool are beyond the scope of this paper.","New York, NY, USA",,"Clarkes-Nias, Jaye and Mutahi, Juliet and Kinai, Andrew and Bent, Oliver and Weldemariam, Komminist and Srivastava, Saurabh",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728662,9.78145E+12,"sentiment, education, analytics, context, blended learning, user interface","Vancouver, BC, Canada",6,217?€?222,Association for Computing Machinery,L@S '15,Towards Capturing Learners Sentiment and Context,https://doi.org/10.1145/2724660.2728662,2015
inproceedings,10.1145/2724660.2728663,"We measure the effectiveness of a traditional honor code at deterring cheating in an online examination, and we compare it to that of a stern warning. Through experimental evaluation in a 409-student online course, we find that a pre-task warning leads to a significant decrease in the rate of cheating while an honor code has a smaller (non-significant) effect. Unlike much prior work, we measure the rate of cheating directly and we do not rely on potentially inaccurate post-examination surveys. Our findings demonstrate that replacing traditional honor codes with warnings could be a simple and effective way to deter cheating in online courses.","New York, NY, USA",,"Corrigan-Gibbs, Henry and Gupta, Nakull and Northcutt, Curtis and Cutrell, Edward and Thies, William",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728663,9.78145E+12,"mooc, online course, cheating, honeypot, honor code","Vancouver, BC, Canada",6,223?€?228,Association for Computing Machinery,L@S '15,Measuring and Maximizing the Effectiveness of Honor Codes in Online Courses,https://doi.org/10.1145/2724660.2728663,2015
inproceedings,10.1145/2724660.2728664,The design of learning materials and researching their efficacy involves the application of both theoretical learning principles and ways of working or practices to move towards evidence based improvement. This paper abstracts 4 categories from our on-going work of educational technology research which we have found to be important in considering what constitutes a successful Technology-Enhanced Learning implementation. These considerations influence the likelihood or feasibility of the wider adoption a particular Technology-Enhanced Learning implementation in the longer term. We also discuss how these considerations relate to the scalability of the development.,"New York, NY, USA",,"Scanlon, Eileen and O'Shea, Timothy M.M. and McAndrew, Patrick",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728664,9.78145E+12,"learning analytics, technology-enhanced learning, interdisciplinarity","Vancouver, BC, Canada",4,229?€?232,Association for Computing Machinery,L@S '15,Technology-Enhanced Learning: Evidence-Based Improvement,https://doi.org/10.1145/2724660.2728664,2015
inproceedings,10.1145/2724660.2728665,"The study of Operating Systems and Systems Programming provides invaluable software engineering experience and crucial conceptual understanding that make it an essential component of an undergraduate computer science curriculum. It is also imperative that classroom course material and infrastructure keep pace with rapidly evolving technology. A ""modern"" course will provide an accurate software engineering experience and prevent the study of outdated concepts. With the recent increase in size and popularity of computer science courses, all course material must also be appropriately scalable. In order to create such a ""modern"" systems course, we redesigned UC Berkeley's CS 162, a 300 student Introduction to Operating Systems &amp; Systems Programming course. In this paper we detail our unique curriculum layout, our advanced infrastructure support for students, and future work on extending our infrastructure for other large computer science courses","New York, NY, USA",,"Shankar, Vaishaal and Culler, David",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728665,9.78145E+12,"user mode, infrastructure, teaching, operating systems, pedagogy, kernel mode, version control","Vancouver, BC, Canada",4,233?€?236,Association for Computing Machinery,L@S '15,A Modern Student Experience InSystems Programming,https://doi.org/10.1145/2724660.2728665,2015
inproceedings,10.1145/2724660.2728666,"In order to learn the impact of MOOCs, we conducted a SPOC experiment on the course of Data Structures and Algorithms in Peking University. In this paper, we analyze student online activities, test scores, and two surveys using statistical methods (t-test, analysis of variance, correlation analysis and OLS regression) to understand what factors will foster improvements in student learning. We find that the ""SPOC + Flipped"" is a helpful mode to teach algorithm, time spent on the course and students' confidence had a positive impact on learning effect, and SPOC resource should be made full use of.","New York, NY, USA",,"Zhang, Ming and Zhu, Jile and Zou, Yanzhen and Yan, Hongfei and Hao, Dan and Liu, Chuxiong",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728666,9.78145E+12,"spoc, algorithms, education, flipped classroom","Vancouver, BC, Canada",4,237?€?240,Association for Computing Machinery,L@S '15,"Educational Evaluation in the PKU SPOC Course ""Data Structures and Algorithms""",https://doi.org/10.1145/2724660.2728666,2015
inproceedings,10.1145/2724660.2728667,"This work investigates whether enrolling in a Massive Open Online Course (MOOC) with friends or colleagues can improve a learner's performance and social interaction during the course. Our results suggest that signing up for a MOOC with peers correlates positively with the rate of course completion, level of achievement, and discussion forum usage. Further analysis seems to suggest that a learner's interaction with their friends compliments a MOOC by acting as a form of self-blended learning.","New York, NY, USA",,"Brooks, Christopher and Stalburg, Caren and Dillahunt, Tawanna and Robert, Lionel",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728667,9.78145E+12,"mooc, blended learning, social learning, collaboration, student success","Vancouver, BC, Canada",4,241?€?244,Association for Computing Machinery,L@S '15,Learn With Friends: The Effects of Student Face-to-Face Collaborations on Massive Open Online Course Activities,https://doi.org/10.1145/2724660.2728667,2015
inproceedings,10.1145/2724660.2728668,"Demographics factors have been used successfully as predictors of student success in traditional higher education systems, but their relationship to achievement in MOOC environments has been largely untested. In this work we explore the predictive power of user demographics compared to learner interaction trace data generated by students in two MOOCs. We show that demographic information offers minimal predictive power compared to activity models, even when compared to models created very early on in the course before substantial interaction data has accrued.","New York, NY, USA",,"Brooks, Christopher and Thompson, Craig and Teasley, Stephanie",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728668,9.78145E+12,"mooc, demographics, interaction data mining, activity, predictive modeling, student success, learning analytics","Vancouver, BC, Canada",4,245?€?248,Association for Computing Machinery,L@S '15,Who You Are or What You Do: Comparing the Predictive Power of Demographics vs. Activity Patterns in Massive Open Online Courses (MOOCs),https://doi.org/10.1145/2724660.2728668,2015
inproceedings,10.1145/2724660.2728669,"In this work, we track the interaction of students across multiple Massive Open Online Courses (MOOCs) on edX. Leveraging the ``burstiness"" factor of three of the most commonly exhibited interaction forms made possible by online learning (i.e, video lecture viewing, coursework access and discussion forum posting), we take on the task of predicting student performance (operationalized as grade) across these courses. Specifically, we utilize the probabilistic framework of Conditional Random Fields (CRF) to formalize the problem of predicting the sequence of grades achieved by a student in different MOOCs, taking into account the contextual dependency of this outcome measure on students' general interaction trend across courses. Based on a comparative analysis of the combination of interaction features, our best CRF model can achieve a precision of 0.581, recall of 0.660 and a weighted F-score of 0.560, outweighing several baseline discriminative classifiers applied at each sequence position. These findings have implications for initiating early instructor intervention, so as to engage students along less active interaction dimensions that could be associated with low grades.","New York, NY, USA",,"Sinha, Tanmay and Cassell, Justine",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728669,9.78145E+12,"grade, moocs, conditional random field modeling","Vancouver, BC, Canada",4,249?€?252,Association for Computing Machinery,L@S '15,Connecting the Dots: Predicting Student Grade Sequences from Bursty MOOC Interactions over Time,https://doi.org/10.1145/2724660.2728669,2015
inproceedings,10.1145/2724660.2728670,"Student discussions over video in massive classes allow students to explore course content, share personal experiences and get feedback on their ideas. However, such discussions frequently turn into casual conversations without focusing on the curriculum and the learning objectives. This short paper explores whether students can achieve multiple learning objectives by solving challenges collaboratively during discussions. We introduce `think-pair-share' technique for video discussions. Our pilot results, drawn from a Coursera class, suggest that participants prefer to exchange information with their peers using personal stories and connecting stories with curriculum increases participant engagement.","New York, NY, USA",,"Pandey, Vineet and Kotturi, Yasmine and Kulkarni, Chinmay and Bernstein, Michael S. and Klemmer, Scott",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728670,9.78145E+12,"video, discussion, synchronous collaboration, small groups","Vancouver, BC, Canada",4,253?€?256,Association for Computing Machinery,L@S '15,Connecting Stories and Pedagogy Increases Participant Engagement in Discussions,https://doi.org/10.1145/2724660.2728670,2015
inproceedings,10.1145/2724660.2728671,"While most MOOCs rely on world-famous experts to teach the masses, in many circumstances students may learn more from people who share their context such as local teachers or peers. Here, we describe an experiment to explore how the ""source"" of video content, the teacher, affects online learning, specifically in the context of higher education in Indian colleges. The proposed experiment will compare three content sources -- a local lecturer (teacher from an Indian engineering college), a local peer (both male and female students similar to the targeted audience), and an internationally recognized expert (a Stanford lecturer). Students will watch videos by the various source authors, after which we will measure differences in their preference, engagement, and learning. In addition, we discuss our experiences with helping students prepare video lectures and describe the support and processes we used to curate interesting and clear peer-generated content.","New York, NY, USA",,"Gupta, Nakull and Neill, Jacki O' and Cross, Andrew and Cutrell, Edward and Thies, William",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728671,9.78145E+12,"online education, peer learning, source effects, moocs","Vancouver, BC, Canada",4,257?€?260,Association for Computing Machinery,L@S '15,Source Effects in Online Education,https://doi.org/10.1145/2724660.2728671,2015
inproceedings,10.1145/2724660.2728673,"The assessment of learning in large online courses such as Massive Online Open Courses, or MOOCs, requires tools that are valid, reliable, and can be automatically administered and scored. We have developed and assessed a tool called Knowledge Assembly for Learning and Assessment, or KNOWLA. The tool measures a student's knowledge in a particular subject by having her assemble a set of scrambled phrases into a logical order. Initial testing indicates that KNOWLA is reliable, and can be used to measure learning gains. KNOWLA also shows promise as a learning tool.","New York, NY, USA",,"Thompson, Meredith M. and Braude, Eric and Canfield, Christopher D. and Halfond, Jay and Sengupta, Aparaita",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728673,9.78145E+12,"arts and humanities, measurement, adult education, student assessment","Vancouver, BC, Canada",5,267?€?271,Association for Computing Machinery,L@S '15,Assessment of KNOWLA: Knowledge Assembly for Learning and Assessment,https://doi.org/10.1145/2724660.2728673,2015
inproceedings,10.1145/2724660.2728674,"Nowadays, many universities utilize groupware support for students to post and share their e-reports, and the students can browse and vote other students' reports in e-learning. Teachers then need to evaluate all students' reports, but this will require a great deal of time and effort for a fair evaluation of the reports. Therefore, we propose an e-report scoring method based on student peer evaluation by considering the relationship between voting and posting time of the e-reports, to promote the quality of the votes and prevent unfair votes. Then, the method can provide scores of reports based on a voting graph by analyzing students who vote the reports. In this paper, we perform a student peer evaluation using groupware based on voting with a ""Like"" button in a course practice, and compare the results with teachers' evaluation.","New York, NY, USA",,"Wang, Yuanyuan and Kawai, Yukiko and Miyamoto, Setsuko and Sumiya, Kazutoshi",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728674,9.78145E+12,"e-reports, student peer evaluation, voting, groupware","Vancouver, BC, Canada",4,273?€?276,Association for Computing Machinery,L@S '15,An E-Report Scoring Method Based on Student Peer Evaluation Using Groupware,https://doi.org/10.1145/2724660.2728674,2015
inproceedings,10.1145/2724660.2728675,"In this document, we describe the third-party authentication system we added to Open edX. With this system, Open edX administrators can allow their users to sign in with a large array of external authentication providers. We outline the features and advantages of the system, describe how it can be extended and customized, and highlight reusable design principles that can be applied to other authentication implementations in online education.","New York, NY, USA",,"Cox, John and Simakov, Pavel",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728675,9.78145E+12,"education, testing., authorization, authentication, privacy, security, api design, identity","Vancouver, BC, Canada",4,277?€?280,Association for Computing Machinery,L@S '15,Adding Third-Party Authentication to Open EdX: A Case Study,https://doi.org/10.1145/2724660.2728675,2015
inproceedings,10.1145/2724660.2728676,"An efficient peer grading mechanism is proposed for grading the multitude of assignments in online courses. This novel approach is based on game theory and mechanism design. A set of assumptions and a mathematical model is ratified to simulate the dominant strategy behavior of students in a given mechanism. A benchmark function accounting for grade accuracy and workload is established to quantitatively compare effectiveness and scalability of various mechanisms. After multiple iterations of mechanisms under increasingly realistic assumptions, three are proposed: Calibration, Improved Calibration, and Deduction. The Calibration mechanism performs as predicted by game theory when tested in an online crowd-sourced experiment, but fails when students are assumed to communicate. The Improved Calibration mechanism addresses this assumption, but at the cost of more effort spent grading. The Deduction mechanism performs relatively well in the benchmark, outperforming the Calibration, Improved Calibration, traditional automated, and traditional peer grading systems. The mathematical model and benchmark opens the way for future derivative works to be performed and compared.","New York, NY, USA",,"Wu, William and Daskalakis, Constantinos and Kaashoek, Nicolaas and Tzamos, Christos and Weinberg, Matthew",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728676,9.78145E+12,"peer grading, mooc, mechanism design, game theory, learning at scale, massive open online courses","Vancouver, BC, Canada",6,281?€?286,Association for Computing Machinery,L@S '15,Game Theory Based Peer Grading Mechanisms for MOOCs,https://doi.org/10.1145/2724660.2728676,2015
inproceedings,10.1145/2724660.2728677,"Economic theory about peers can help learning scientists and designers scale their work from the scale of small classrooms to limitless learning experiences. I propose: 1. We may increase productivity in online learning by changing technologies around peers; many structures around peers can scale with class size. 2. It is not always in students' best interests to be good peers, and collective action failures may worsen with class size. I conducted an experiment in a NovoEd MOOC for teachers that was motivated by these propositions; it leads to future questions about unintended and emergent effects.","New York, NY, USA",,"Williams, Betsy Anne",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728677,9.78145E+12,"peers, collective action, learning, moocs, education production function, incentives, economics, teams","Vancouver, BC, Canada",6,287?€?292,Association for Computing Machinery,L@S '15,"Peers in MOOCs: Lessons Based on the Education Production Function, Collective Action, and an Experiment",https://doi.org/10.1145/2724660.2728677,2015
inproceedings,10.1145/2724660.2728678,"In this paper, we discuss current practices and challenges of teaching psychology experiments. We review experiential learning and analogical learning pedagogies, which have informed the design of TELLab, an online platform for supporting effective experiential learning of psychology concepts.","New York, NY, USA",,"Li, Na and Gajos, Krzysztof Z. and Nakayama, Ken and Enos, Ryan",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728678,9.78145E+12,"online exper-imentation, analogical learning, experiential learning","Vancouver, BC, Canada",5,293?€?297,Association for Computing Machinery,L@S '15,TELLab: An Experiential Learning Tool for Psychology,https://doi.org/10.1145/2724660.2728678,2015
inproceedings,10.1145/2724660.2728679,"This study investigated the extent to which students asked and instructors answered content-related questions in MOOC discussion forums; subsequently a classification model was built to identify such questions based on extracted linguistic features. Results showed content-related threads were a minority and under-addressed by instructors. However, linguistic modeling was promising in identifying them with high reliability.","New York, NY, USA",,"Cui, Yi and Wise, Alyssa Friend",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728679,9.78145E+12,"machine learning, massive open online courses, social interaction, natural language processing","Vancouver, BC, Canada",5,299?€?303,Association for Computing Machinery,L@S '15,Identifying Content-Related Threads in MOOC Discussion Forums,https://doi.org/10.1145/2724660.2728679,2015
inproceedings,10.1145/2724660.2728680,"In this work-in-progress, we present our preliminary findings from an exploratory study on understanding learners' general behavior and perception towards learning with classmates in MOOCs. One-on-one semi-structured interview designed with grounded theory method was conducted with seven MOOC learners. Initial analysis of the interview data revealed several interesting insights on learners' behavior in working with other learners in MOOCs. We intend to expand the findings in future work to derive design implications for incorporating collaborative features into MOOCs.","New York, NY, USA",,"Chua, Soon Hau and Kim, Juho and Monserrat, Toni-Jan Keith and Zhao, Shengdong",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728680,9.78145E+12,"collaborative learning, learning behavior, massive open online courses, online learning, moocs","Vancouver, BC, Canada",4,305?€?308,Association for Computing Machinery,L@S '15,Understanding Learners' General Perception Towards Learning with MOOC Classmates: An Exploratory Study,https://doi.org/10.1145/2724660.2728680,2015
inproceedings,10.1145/2724660.2728681,"Ongoing student feedback on course content and assignments can be valuable for MOOC instructors in the absence of face-to-face-interaction. To collect ongoing feedback and scalably identify valuable suggestions, we built the MOOC Collaborative Assessment and Feedback Engine (M-CAFE). This mobile platform allows MOOC students to numerically assess the course, their own performance, and provide textual suggestions about how the course could be improved on a weekly basis. M-CAFE allows students to visualize how they compare with their peers and read and evaluate what others have suggested, providing peer-to-peer collaborative filtering. We evaluate M-CAFE based on data from two EdX MOOCs.","New York, NY, USA",,"Zhou, Mo and Cliff, Alison and Huang, Allen and Krishnan, Sanjay and Nonnecke, Brandie and Uchino, Kanji and Joseph, Sam and Fox, Armando and Goldberg, Ken",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728681,9.78145E+12,"course assessment, instructor support, collaborative filtering, moocs","Vancouver, BC, Canada",4,309?€?312,Association for Computing Machinery,L@S '15,M-CAFE: Managing MOOC Student Feedback with Collaborative Filtering,https://doi.org/10.1145/2724660.2728681,2015
inproceedings,10.1145/2724660.2728682,"Online computer adaptive learning is increasingly being used in classrooms as a way to provide guided learning for students. Such tutors have the potential to provide tailored feedback based on specific student needs and misunderstandings. Bayesian knowledge tracing (BKT) is used to model student knowledge when knowledge is assumed to be changing throughout a single assessment period; in contrast, traditional Item Response Theory (IRT) models assume student knowledge to be constant within an assessment period. The basic BKT model assumes that the chance a student transitions from ""not knowing"" to ""knowing"" after each item is the same, and problems are considered learning opportunities. It could be the case, however, that learning is actually context sensitive, where students' learning might be improved when the items and their associated tutoring content are delivered to the student in a particular order. In this paper, we use BKT models to find such context sensitive transition probabilities from real data delivered by an online tutoring system, ASSISTments. After empirically deriving orderings that lead to better learning, we qualitatively analyze the items and their tutoring content to uncover any mechanisms that might explain why such orderings are modeled to have higher learning potential.","New York, NY, USA",,"Tang, Steven and McBride, Elizabeth and Gogel, Hannah and Pardos, Zachary A.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728682,9.78145E+12,"item ordering, bayesian knowledge tracing, item difficulty","Vancouver, BC, Canada",4,313?€?316,Association for Computing Machinery,L@S '15,Item Ordering Effects with Qualitative Explanations Using Online Adaptive Tutoring Data,https://doi.org/10.1145/2724660.2728682,2015
inproceedings,10.1145/2724660.2728683,"We present results from a pilot study where students successfully created complex assessments for a MOOC in introductory electronics -- an area with a very large expert-novice gap. Previous work in learnersourcing found that learners can productively contribute through simple tasks. However, many course resources require a high level of expertise to create, and prior work fell short on tasks with a large expert-novice gap, such as textbook creation or concept tagging. Since these constitute a substantial portion of course creation costs, addressing this issue is prerequisite to substantially shifting MOOC economics through learnersourcing. This represents one of the first successes in learnersourcing with a large expert-novice gap. In the pilot, we reached out to 206 students (out of thousands who met eligibility criteria) who contributed 14 complex high-quality design problems. This results suggests a full cohort could contribute hundreds of problems. We achieved this through a four-pronged approach: (1) pre-selecting top learners (2) community feedback process (3) student mini-course in pedagogy (4) instructor review and involvement.","New York, NY, USA",,"Mitros, Piotr",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728683,9.78145E+12,"crowdsourcing, mooc, learnersourcing, assessment, cscw","Vancouver, BC, Canada",4,317?€?320,Association for Computing Machinery,L@S '15,Learnersourcing of Complex Assessments,https://doi.org/10.1145/2724660.2728683,2015
inproceedings,10.1145/2724660.2728684,"The digitization of educational course content has proved to be problematic for math instructors due to the lack of quality feedback tools that can accommodate the commenter to efficiently express math formulae and convey descriptions about complex ideas contextualized in situ. This paper proposes that RichReview, a document annotation system which creates inking, voice and deictic gestures on top of the student's submitted work, is a possible formative math feedback solution, because it enables face-to-face like commentary within the contexts of the document at hand. A preliminary qualitative evaluation study conducted while having students receive RichReview feedback showed promise to our approach to enhance the quality of feedback, with the implication that incorporating multi-modal feedback into workflows can be an effective method to address elements of feedback submissions lacking in coursework that has moved online.","New York, NY, USA",,"Randles, Bernie and Yoon, Dongwook and Cheatle, Amy and Jung, Malte and Guimbretiere, Francois",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728684,9.78145E+12,"asynchronous communication, formative feedback, math education, multi-modal user interfaces","Vancouver, BC, Canada",6,321?€?326,Association for Computing Machinery,L@S '15,Supporting Face-to-Face Like Communication Modalities for Asynchronous Assignment Feedback in Math Education,https://doi.org/10.1145/2724660.2728684,2015
inproceedings,10.1145/2724660.2728685,"This paper argues that improving learning reliably and at scale requires a specific orientation toward measurement, understood broadly. Drawing on examples from a partnership between SRI International and The Carnegie Foundation for the Advancement of Teaching, this paper describes measures of student behaviors that are being used by researchers and instructors to improve learning environments at more than 50 community colleges and four-year universities for thousands of students.","New York, NY, USA",,"Krumm, Andrew E. and D'Angelo, Cynthia and Podkul, Timothy E. and Feng, Mingyu and Yamada, Hiroyuki and Beattie, Rachel and Hough, Heather and Thorn, Chris",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728685,9.78145E+12,"developmental mathematics, practical measurement, learning behaviors","Vancouver, BC, Canada",4,327?€?330,Association for Computing Machinery,L@S '15,Practical Measures of Learning Behaviors,https://doi.org/10.1145/2724660.2728685,2015
inproceedings,10.1145/2724660.2728686,"Video games have great potential to motivate students in environments for learning at scale. However, little is known about how to design in-game incentive structures to maximize learning and engagement. In this work, we expand on our previous research that introduced a new ""brain points"" incentive structure designed to promote the growth mindset, or the belief that intelligence is malleable. We replicate our original findings, showing that brain points increase student persistence and use of strategy. We also explore how brain points impact students from different demographic groups. We find that brain points are less engaging for low-income students, and discuss methods of improving our design in the future.","New York, NY, USA",,"O'Rourke, Eleanor and Chen, Yvonne and Haimovitz, Kyla and Dweck, Carol S. and Popovi\'{c}, Zoran",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728686,9.78145E+12,"growth mindset, educational games, incentive structures","Vancouver, BC, Canada",4,331?€?334,Association for Computing Machinery,L@S '15,Demographic Differences in a Growth Mindset Incentive Structure for Educational Games,https://doi.org/10.1145/2724660.2728686,2015
inproceedings,10.1145/2724660.2728687,"In this paper, we present early research evaluating the predictive power of a variety of temporal features across student subpopulations with distinctive behaviors at the beginning of the course. Initial results illustrate that these features predict important differences across the subpopulations and over time in the courses. Ultimately, these results have implications for effectively targeting adaptive scaffolding tailored to the particular intentions and goals of subpopulations in MOOCs.","New York, NY, USA",,"Ye, Cheng and Kinnebrew, John S. and Biswas, Gautam and Evans, Brent J. and Fisher, Douglas H. and Narasimham, Gayathri and Brady, Katherine A.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728687,9.78145E+12,"moocs, machine learning, behavior prediction","Vancouver, BC, Canada",4,335?€?338,Association for Computing Machinery,L@S '15,Behavior Prediction in MOOCs Using Higher Granularity Temporal Information,https://doi.org/10.1145/2724660.2728687,2015
inproceedings,10.1145/2724660.2728688,"Formative writing systems with automated scoring provide opportunities for students to write, receive feedback, and then revise essays in a timely iterative cycle. This paper describes ongoing investigations of a formative writing tool through mining student data in order to understand how the system performs and to measure improvement in student writing. The sampled data included over 1.3M student essays written in response to approximately 200 pre-defined prompts as well as a log of all student actions and computer generated feedback. Analyses both measured and modeled changes in student performance over revisions, the effects of system responses and the amount of time students spent working on assignments. Implications are discussed for employing large-scale data analytics to improve educational outcomes, to understand the role of feedback in writing, to drive improvements in formative technology and to aid in designing better kinds of feedback and scaffolding to support students in the writing process.","New York, NY, USA",,"Foltz, Peter W. and Rosenstein, Mark",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728688,9.78145E+12,"data mining, log file analysis, educational software, large scale data analytics, automated essay scoring, educational data mining","Vancouver, BC, Canada",4,339?€?342,Association for Computing Machinery,L@S '15,Analysis of a Large-Scale Formative Writing Assessment System with Automated Feedback,https://doi.org/10.1145/2724660.2728688,2015
inproceedings,10.1145/2724660.2728689,"The Massive Open Online Course (MOOC) paradigm has developed rapidly and achieved significant attention from a broad range of populations. However, many people who enroll in MOOCs do not have successful learning experiences. For example, some studies suggest that the relatively weak feelings of community and meager opportunities for collaboration may be contributing to a high dropout rate in MOOCs. In light of such problems, we are exploring new design features that could support enhanced social interactions, collaborative learning and feelings of community. We present our design ideas through a set of activity design scenarios, along with an analysis of possible benefits and negative consequences of our design.","New York, NY, USA",,"Zheng, Saijing and Rosson, Mary Beth and Shih, Patrick C. and Carroll, John M.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728689,9.78145E+12,"sub-networks, online learning, scenario-based design, collaborative learning, moocs, space and place","Vancouver, BC, Canada",4,343?€?346,Association for Computing Machinery,L@S '15,Designing MOOCs as Interactive Places for Collaborative Learning,https://doi.org/10.1145/2724660.2728689,2015
inproceedings,10.1145/2724660.2728690,"Along with the advent of MOOCs and other online learning platforms such as Khan Academy, the role of online education has continued to grow in relation to that of traditional on-campus instruction. Rather than tackle the problem of evaluating large educational units such as entire online courses, this paper approaches a smaller problem: exploring a framework for evaluating more granular educational units, in this case, short educational videos. We have chosen to leverage an adaptation of traditional Bayesian Knowledge Tracing (BKT), intended to incorporate the usage of video content in addition to assessment activity. By exploring the change in predictive error when alternately including or omitting video activity, we suggest a metric for determining the relevance of videos to associated assessments. To validate our hypothesis and demonstrate the application of our proposed methods we use data obtained from the popular Khan Academy website.","New York, NY, USA",,"MacHardy, Zachary and Pardos, Zachary A.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728690,9.78145E+12,"bayesian inference, instructional technology, educational videos, online education, knowledge tracing","Vancouver, BC, Canada",4,347?€?350,Association for Computing Machinery,L@S '15,Toward the Evaluation of Educational Videos Using Bayesian Knowledge Tracing and Big Data,https://doi.org/10.1145/2724660.2728690,2015
inproceedings,10.1145/2724660.2728691,"Online discussion forums in a MOOC setting allow students to become aware of other students enrolled in the course. However, what is (usually) visible in the forums is the output of ``active'' students who engage in asking and answering questions. In addition to such active participants, there is (as always in online communities) a large group of ``passive'' users (so-called lurkers), who might find the forum useful to their learning, and read it regularly, despite remaining ``invisible''. Our analysis of a large MOOC online forum shows that for every active participant in the forum there are two passive ones. 30% of active participants complete the course, compared to only 6.6% of the passive participants. Vice-versa, 67% of students who complete the course are also active in the forum. However, ``invisible activity'' (e.g. reading or searching the forum) is something that both groups practice equally and more frequently, while only 3.3% of forum actions are visible.","New York, NY, USA",,"Mustafaraj, Eni and Bu, Jessica",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728691,9.78145E+12,"discussion forums, lurkers, online communities, moocs","Vancouver, BC, Canada",4,351?€?354,Association for Computing Machinery,L@S '15,The Visible and Invisible in a MOOC Discussion Forum,https://doi.org/10.1145/2724660.2728691,2015
inproceedings,10.1145/2724660.2728692,"Designing educational games that meet both learning and entertainment objectives is a challenging task. Games that begin by developing specific educational goals and are later wrapped in a game or narrative context risk appearing forced, while those that begin with gaming elements to which educational elements are added may appear superficial. In this paper, we describe the methodology and results from a three-day interdisciplinary hackathon for developing game narratives designed to address both needs. We present details regarding the hackathon, the collaborative teams, and an example of the outcomes produced.","New York, NY, USA",,"Wylie, Ruth and Finn, Ed and Eschrich, Joseph and Monsef, Kiyash and Hawkins, Robert",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728692,9.78145E+12,"educational games, interdisciplinary collaboration, narratives","Vancouver, BC, Canada",4,355?€?358,Association for Computing Machinery,L@S '15,Exploring Collaborative Storytelling as a Method for Creating Educational Games,https://doi.org/10.1145/2724660.2728692,2015
inproceedings,10.1145/2724660.2728693,"Research suggests that online peer review can provide critical help to learners who would otherwise not be given individualized feedback on their work. However, little is known about how different characteristics of review systems impact reviewers. This extended abstract presents preliminary results from an online experiment examining how explicit numeric ratings change peer reviews. A between-subject experiment found that peer reviewers who were asked to generate a numeric rating as well as general feedback gave significantly more explanations and made more positive comments compared with reviewers who were asked to give general feedback only. These exploratory findings suggest the need to further examine how online peer review systems' affordances can impact the reviews given in these systems.","New York, NY, USA",,"Hicks, Catherine M. and Fraser, C. Ailie and Desai, Purvi and Klemmer, Scott",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728693,9.78145E+12,"writing, peer assessment, online learning, peer review","Vancouver, BC, Canada",4,359?€?362,Association for Computing Machinery,L@S '15,Do Numeric Ratings Impact Peer Reviewers?,https://doi.org/10.1145/2724660.2728693,2015
inproceedings,10.1145/2724660.2728694,"Teaching computer architecture as a hands-on engineering course to approximately 250 MIT students per semester requires a large, dedicated teaching staff. This Spring, a shortened version of the course will be deployed on edX to a potentially far larger cohort of students, without additional teaching staff. To better support students, we have deployed developmental versions of three learner-sourcing systems to as many as 500 students. These systems harvest and organize students' collective knowledge about debugging and optimizing solutions. We plan to deploy and study the next iteration of these systems on edX this Spring.","New York, NY, USA",,"Glassman, Elena L. and Terman, Christopher J. and Miller, Robert C.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728694,9.78145E+12,"learning at scale, engineering education","Vancouver, BC, Canada",4,363?€?366,Association for Computing Machinery,L@S '15,Learner-Sourcing in an Engineering Class at Scale,https://doi.org/10.1145/2724660.2728694,2015
inproceedings,10.1145/2724660.2728695,"A challenge in introductory and intermediate programming courses is understanding how students approached solving a particular programming problem, in order to provide feedback on how they might improve. In both Massive Open Online Courses (MOOCs) and large residential courses, such feedback is difficult to provide for each student individually. To multiply the instructor's leverage, we would like to group student submissions according to the general problem-solving strategy they used, as the first stage of a ``feedback pipeline''. We describe ongoing explorations of a variety of clustering algorithms and similarity metrics using a corpus of over 800 student submissions to a simple programming assignment from a programming MOOC. We find that for a majority of submissions, it is possible to automatically create clusters such that an instructor ``eyeballing'' some representative submissions from each cluster can readily describe qualitatively what the common elements are in student submissions in that cluster. This information can be the basis for feedback to the students or for comparing one group of students' approach with another's.","New York, NY, USA",,"Yin, Hezheng and Moghadam, Joseph and Fox, Armando",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728695,9.78145E+12,"moocs, clustering, autograding","Vancouver, BC, Canada",6,367?€?372,Association for Computing Machinery,L@S '15,Clustering Student Programming Assignments to Multiply Instructor Leverage,https://doi.org/10.1145/2724660.2728695,2015
inproceedings,10.1145/2724660.2728696,"We examine the process of engineering features for developing models that improve our understanding of learners' online behavior in MOOCs. Because feature engineering relies so heavily on human insight, we engage the crowd for feature proposals and guidance on how to operationalize them. When we examined our crowd-sourced features in the context of predicting stopout, not only were they impressively nuanced, but they also integrated more than one interaction mode between the learner and platform and described how the learner was relatively performing.","New York, NY, USA",,"Veeramachaneni, Kalyan and Adl, Kiarash and O'Reilly, Una-May",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728696,9.78145E+12,"feature engineering, crowd sourcing, machine learning","Vancouver, BC, Canada",4,373?€?376,Association for Computing Machinery,L@S '15,Feature Factory: Crowd Sourced Feature Discovery,https://doi.org/10.1145/2724660.2728696,2015
inproceedings,10.1145/2724660.2728697,"An important part of learning is interactions with peers, mentors, teaching assistants and the instructor. Discussions and group work allow for interactive learning and deeper understanding of class concepts. Online learning environments struggle to replicate this process. This is especially true when the scale of an online class is increased. In order to address this issue a few MOOCs solicit teaching assistants to answer questions, and through their social position, help set academic standards in discussion forums. However, little is know about how different social roles influence the attribution of value to statements in these environments. This study demonstrates that the attitudes expressed by individuals in facilitating roles influence the acceptance of information shared in a discussion board setting.","New York, NY, USA",,"Shillair, Ruth and Wash, Rick",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728697,9.78145E+12,"social status in online environments, attribution of value, moocs, online education","Vancouver, BC, Canada",4,377?€?380,Association for Computing Machinery,L@S '15,Are You Listening? Social Roles and Perceived Value of Statements in Online Learning Communities,https://doi.org/10.1145/2724660.2728697,2015
inproceedings,10.1145/2724660.2728698,The results of a study of online peer learning suggests that it may be advantageous to automatically assign students to small peer learning groups based on how many students initially get answers to questions correct.,"New York, NY, USA",,"Hearst, Marti A. and Fox, Armando and Coetzee, D. and Hartmann, Bjoern",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728698,9.78145E+12,"peer learning, online learning, crowdsourcing","Vancouver, BC, Canada",3,381?€?383,Association for Computing Machinery,L@S '15,All It Takes Is One: Evidence for a Strategy for Seeding Large Scale Peer Learning Interactions,https://doi.org/10.1145/2724660.2728698,2015
inproceedings,10.1145/2724660.2728699,"Using aggregated Learning Management System data and course evaluation data from 26 online courses, we evaluated the relationship between measures of online activity, course and assessment structure, and student perceptions of course value. We find relationships between selected dimensions of learner engagement that reflect current constructivist theories of learning. This work demonstrates the potential value of pooled, easily accessible, and anonymous data for high-level inferences regarding design of online courses and the learner experience.","New York, NY, USA",,"Roll, Ido and Macfadyen, Leah P. and Sandilands, Debra",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728699,9.78145E+12,"engagement, student evaluation of teaching, learning management system, learning analytics","Vancouver, BC, Canada",4,385?€?388,Association for Computing Machinery,L@S '15,"Evaluating the Relationship Between Course Structure, Learner Activity, and Perceived Value of Online Courses",https://doi.org/10.1145/2724660.2728699,2015
inproceedings,10.1145/2724660.2728700,"Existing datasets tell us only a partial story about the contextual factors that impact learners in Massive Online Open Courses (MOOCs). Information about race/ethnicity, education, and income helps us understand socioeconomic status, but such data is notoriously difficult to collect in an international context. Extant MOOC studies have not paid due attention to socioeconomic variables; they have either taken a U.S.-centric approach, ignored important country-specific dimensions of variables, or failed to ask about certain variables altogether, such as race/ethnicity. During a qualitative study of 24 self-regulated learners from population groups underrepresented in MOOCs, we piloted a short U.S.-centric demographic questionnaire. Preliminary results suggest that a large-scale survey designed for both cross-national and country-specific analyses would provide valuable information to MOOC researchers.","New York, NY, USA",,"Kasunic, Anna and Hammer, Jessica and Ogan, Amy",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728700,9.78145E+12,"socioeconomic status, moocs, international, demographics, survey design","Vancouver, BC, Canada",4,389?€?392,Association for Computing Machinery,L@S '15,Cultural Relevance in MOOCs: Asking About Socioeconomic Context,https://doi.org/10.1145/2724660.2728700,2015
inproceedings,10.1145/2724660.2728701,"With the increasing demand on knowledge sharing and problem solving, there is a growing participation on online Question &amp; Answer (Q&amp;A) forums in the recent past. We classify the online community participation on Stack Exchange into two different genres, one is technical and another is non-technical. Though several studies have measured community activity, studies that compare activity across forums within different topic areas are limited. In this work we examine the effect of incentives on contributions by exploring the differences between technical and non-technical communities in terms of user's participation. Given the increased attention on discussion forums as part of online learning, especially MOOCs, we believe that our findings can assist with providing better support for learners across different content areas.","New York, NY, USA",,"Ahmed, Saif and Yang, Seungwon and Johri, Aditya",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728701,9.78145E+12,"technical, activity, non-technical, online community, q&amp;a forum, stack exchange","Vancouver, BC, Canada",6,393?€?398,Association for Computing Machinery,L@S '15,Does Online Q&amp;A Activity Vary Based on Topic: A Comparison of Technical and Non-Technical Stack Exchange Forums,https://doi.org/10.1145/2724660.2728701,2015
inproceedings,10.1145/2724660.2728702,"In this work, we propose and evaluate an active learning algorithm in context of CPSGrader, an automatic grading and feedback generation tool for laboratory-based courses in the area of cyber-physical systems. CPSGrader detects the presence of certain classes of mistakes using test benches that are generated in part via machine learning from solutions that have the fault and those that do not (positive and negative examples). We develop a clustering-based active learning technique that selects from a large database of unlabeled solutions, a small number of reference solutions for the expert to label that will be used as training data. The goal is to achieve better accuracy of fault identification with fewer reference solutions as compared to random selection. We demonstrate the effectiveness of our algorithm using data obtained from an on-campus laboratory-based course at UC Berkeley.","New York, NY, USA",,"Juniwal, Garvit and Jain, Sakshi and Donz\'{e}, Alexandre and Seshia, Sanjit A.",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728702,9.78145E+12,"density-based spatial clustering of applications with noise, auto-grading, embedded/cyber-physical systems, dynamic time warping, mooc, active learning","Vancouver, BC, Canada",5,399?€?403,Association for Computing Machinery,L@S '15,Clustering-Based Active Learning for CPSGrader,https://doi.org/10.1145/2724660.2728702,2015
inproceedings,10.1145/2724660.2728703,"We report the one of the first applications of treatment/control group learning experiments in MOOCs. We have compared the efficacy of deliberate practice-practicing a key procedure repetitively-with traditional practice on ""whole problems"". Evaluating the learning using traditional whole problems we find that traditional practice outperforms drag and drop, which in turn outperforms multiple choice. In addition, we measured the amount of learning that occurs during a pretest administered in a MOOC environment that transfers to the same question if placed on the posttest. We place a limit on the amount of such transfer, which suggests that this type of learning effect is very weak compared to the learning observed throughout the entire course.","New York, NY, USA",,"Chudzicki, Christopher and Pritchard, David E. and Chen, Zhongzhou",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728703,9.78145E+12,"ab experiments, mooc, education, online education","Vancouver, BC, Canada",4,405?€?408,Association for Computing Machinery,L@S '15,Learning Experiments Using AB Testing at Scale,https://doi.org/10.1145/2724660.2728703,2015
inproceedings,10.1145/2724660.2728704,"In contrast to typical laboratory experiments, the everyday use of online educational resources by large populations and the prevalence of software infrastructure for A/B testing leads us to consider how platforms can embed in vivo experiments that do not merely support research, but ensure practical improvements to their educational components. Examples are presented of randomized experimental comparisons conducted by subsets of the authors in three widely used online educational platforms -- Khan Academy, edX, and ASSISTments. We suggest design principles for platform technology to support randomized experiments that lead to practical improvements -- enabling Iterative Improvement and Collaborative Work -- and explain the benefit of their implementation by WPI co-authors in the ASSISTments platform.","New York, NY, USA",,"Williams, Joseph Jay and Ostrow, Korinn and Xiong, Xiaolu and Glassman, Elena and Kim, Juho and Maldonado, Samuel G. and Li, Na and Reich, Justin and Heffernan, Neil",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728704,9.78145E+12,"a/b testing, mooc, intelligent tutoring system, crowdsourcing, collaborative work, randomized controlled trial","Vancouver, BC, Canada",4,409?€?412,Association for Computing Machinery,L@S '15,Using and Designing Platforms for In Vivo Educational Experiments,https://doi.org/10.1145/2724660.2728704,2015
inproceedings,10.1145/2724660.2728705,"Most education and workplace learning takes place in classroom contexts far removed from laboratories or field sites with special arrangements for scientific research. But digital online resources provide a novel opportunity for large-scale efforts to bridge the real-world and laboratory settings which support data collection and randomized A/B experiments comparing different versions of content or interactions [2]. However, there are substantial technological and practical barriers in aligning instructors and researchers to use learning technologies like blended lessons/exercises &amp; MOOCs as both a service for students and a realistic context to conduct research. This paper explains how the concept of a ""MOOClet"" can facilitate research-practitioner collaborations. MOOClets [3] are defined as modular components of a digital resource that can be implemented in technology to: (1) allow modification to create multiple versions, (2) allow experimental comparison and personalization of different versions, (3) reliably specify what data are collected. We suggest a framework in which instructors specify what kinds of changes to lessons, exercises, and emails they would be willing to adopt, and what data they will collect and make available. Researchers can then: (1) specify or design experiments that compare the effects of different versions on quantifiable outcomes. (2) Explore algorithms for maximizing particular outcomes by choosing alternative versions of a MOOClet based on the input variables available. We present a prototype survey tool for instructors intended to facilitate practitioner-researcher matches and successful collaborations.","New York, NY, USA",,"Williams, Joseph Jay and Kim, Juho and Keegan, Brian",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728705,9.78145E+12,"collaborative work, experiment, education, mooclet","Vancouver, BC, Canada",4,413?€?416,Association for Computing Machinery,L@S '15,Supporting Instructors in Collaborating with Researchers Using MOOClets,https://doi.org/10.1145/2724660.2728705,2015
inproceedings,10.1145/2724660.2728706,"We describe a new method to troubleshoot and improve domain and student models from interactive learning environments. The method applies as long as the models can generate predictions of student behavior. The method is a visualization of model predictions, categorized using a metric of recent performance. We describe the method, its application in prior work to student models, and a proposed extension to domain models.","New York, NY, USA",,"Goldin, Ilya and Galyardt, April",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728706,9.78145E+12,"education, tutoring systems, psychometrics, student models, assessment, machine learning, domain models","Vancouver, BC, Canada",4,417?€?420,Association for Computing Machinery,L@S '15,Viz-R: Using Recency to Improve Student and Domain Models,https://doi.org/10.1145/2724660.2728706,2015
inproceedings,10.1145/2724660.2728707,"As a step towards scaling personalized instruction, we seek to automatically identify the key features of the interactive learning process teachers use to select the next activity when teaching a single student. Such features could both inform computational student models designed to facilitate instructional decisions, and help enable automated self-improving teaching systems that leverage this identified feature set. We present preliminary results that a very small set of features is almost as good as a much larger set of features at predicting human tutor decisions when teaching students about histograms.","New York, NY, USA",,"Lee, Min Hyung and Runde, Joe and Jibril, Warfa and Wang, Zhuoying and Brunskill, Emma",Proceedings of the Second (2015) ACM Conference on Learning @ Scale,10.1145/2724660.2728707,9.78145E+12,"classification, teacher modeling, learning from demonstration, intelligent tutoring systems","Vancouver, BC, Canada",4,421?€?424,Association for Computing Machinery,L@S '15,Learning the Features Used To Decide How to Teach,https://doi.org/10.1145/2724660.2728707,2015
inproceedings,10.1145/2556325.2578292,"The invention of the movie camera was initially seen as a way to reach ""massive"" by filming plays; we are in an equivalent stage with our early MOOCs. Thinking outside the box of ""teaching"" is essential to realizing learning at scale. Virtual worlds and augmented realities can complement digitized classroom instruction through simulated apprenticeships, embedded support for learning everywhere, and transformed social interactions. Going big also requires thinking small: analyzing diagnostic micro-patterns to customize individual learning, sifting through millions of participants to find the ideal partners to aid each other's growth. To reach massive with universal access and powerful outcomes, we must creatively expand our visions of platforms, pedagogy, and financing.","New York, NY, USA",,"Dede, Christopher J.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2578292,9.78145E+12,"immersion, transformed social interaction, augmented realities, personalizationn, mobile, virtual worlds, massive, learning analytics","Atlanta, Georgia, USA",2,1?€?2,Association for Computing Machinery,L@S '14,"New Wine in No Bottles: Immersive, Personalized Ubiquitous Learning",https://doi.org/10.1145/2556325.2578292,2014
inproceedings,10.1145/2556325.2566240,"Students who registered for the Mapping with Google massive open online course (MOOC) were asked several questions during the registration process to identify prior experience with eleven skills as well as their goals for registering for the course. Students selected goals from a list; they were periodically reminded of these goals during the MOOC. At the end of the course, we compared students' self reports of goal achievement on a post-course survey with behavioral click-stream analysis. In addition, we assessed how well prior skill in a subject predicts a student's course completion and found no correlation. Our research shows that students who completed course activities were more likely to earn certificates of completion than peers who did not.","New York, NY, USA",,"Wilkowski, Julia and Deutsch, Amit and Russell, Daniel M.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566240,9.78145E+12,"distance learning, moocs","Atlanta, Georgia, USA",8,3?€?10,Association for Computing Machinery,L@S '14,Student Skill and Goal Achievement in the Mapping with Google MOOC,https://doi.org/10.1145/2556325.2566240,2014
inproceedings,10.1145/2556325.2566250,"Because MOOCs offer complete logs of student activities for each student there is hope that it may be possible to find out which activities are the most useful for learning. We start this quest by examining correlations between time spent on specific course resources and various measures of student performance: score on assessments, skill as defined by Item Response Theory, improvement in skill over the period of the course, and conceptual improvement as measured by a pre-post test. We study two MOOCs offered on edX.org by MIT faculty: Circuits and Electronics (6.002x) and Mechanics Review (8.MReV). Surprisingly, we find strong negative correlations in 6.002x between student skill and resource use; we attribute these findings to the fact that students with higher initial skills can do the exercises faster and with less time spent on instructional resources. We find weak or slightly negative correlations between relative improvement and resource use in 6.002x. The correlations with learning are stronger for conceptual knowledge in 8.MReV than with relative improvement, but similar for all course activities (except that eText checkpoint questions correlate more strongly with relative improvement). Clearly, the wide distribution of demographics and initial skill in MOOCs challenges us to isolate the habits of learning and resource use that correlate with learning for different students.","New York, NY, USA",,"Champaign, John and Colvin, Kimberly F. and Liu, Alwina and Fredericks, Colin and Seaton, Daniel and Pritchard, David E.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566250,9.78145E+12,"learning comparison, irt, educational data mining, learning behaviors, edx, mooc","Atlanta, Georgia, USA",10,11?€?20,Association for Computing Machinery,L@S '14,Correlating Skill and Improvement in 2 MOOCs with a Student's Time on Tasks,https://doi.org/10.1145/2556325.2566250,2014
inproceedings,10.1145/2556325.2566247,"The current generation of Massive Open Online Courses (MOOCs) attract a diverse student audience from all age groups and over 196 countries around the world. Researchers, educators, and the general public have recently become interested in how the learning experience in MOOCs differs from that in traditional courses. A major component of the learning experience is how students navigate through course content.This paper presents an empirical study of how students navigate through MOOCs, and is, to our knowledge, the first to investigate how navigation strategies differ by demographics such as age and country of origin. We performed data analysis on the activities of 140,546 students in four edX MOOCs and found that certificate earners skip on average 22% of the course content, that they frequently employ non-linear navigation by jumping backward to earlier lecture sequences, and that older students and those from countries with lower student-teacher ratios are more comprehensive and non-linear when navigating through the course.From these findings, we suggest design recommendations such as for MOOC platforms to develop more detailed forms of certification that incentivize students to deeply engage with the content rather than just doing the minimum necessary to earn a passing grade. Finally, to enable other researchers to reproduce and build upon our findings, we have made our data set and analysis scripts publicly available.","New York, NY, USA",,"Guo, Philip J. and Reinecke, Katharina",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566247,9.78145E+12,"mooc, navigation strategy, massive open online course, non-linear learning","Atlanta, Georgia, USA",10,21?€?30,Association for Computing Machinery,L@S '14,Demographic Differences in How Students Navigate through MOOCs,https://doi.org/10.1145/2556325.2566247,2014
inproceedings,10.1145/2556325.2566237,"With thousands of learners watching the same online lecture videos, analyzing video watching patterns provides a unique opportunity to understand how students learn with videos. This paper reports a large-scale analysis of in-video dropout and peaks in viewership and student activity, using second-by-second user interaction data from 862 videos in four Massive Open Online Courses (MOOCs) on edX. We find higher dropout rates in longer videos, re-watching sessions (vs first-time), and tutorials (vs lectures). Peaks in re-watching sessions and play events indicate points of interest and confusion. Results show that tutorials (vs lectures) and re-watching sessions (vs first-time) lead to more frequent and sharper peaks. In attempting to reason why peaks occur by sampling 80 videos, we observe that 61% of the peaks accompany visual transitions in the video, e.g., a slide view to a classroom view. Based on this observation, we identify five student activity patterns that can explain peaks: starting from the beginning of a new material, returning to missed content, following a tutorial step, replaying a brief segment, and repeating a non-visual explanation. Our analysis has design implications for video authoring, editing, and interface design, providing a richer understanding of video learning on MOOCs.","New York, NY, USA",,"Kim, Juho and Guo, Philip J. and Seaton, Daniel T. and Mitros, Piotr and Gajos, Krzysztof Z. and Miller, Robert C.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566237,9.78145E+12,"online education, in-video dropout, peak detection., interaction peaks, video analysis, mooc","Atlanta, Georgia, USA",10,31?€?40,Association for Computing Machinery,L@S '14,Understanding In-Video Dropouts and Interaction Peaks Inonline Lecture Videos,https://doi.org/10.1145/2556325.2566237,2014
inproceedings,10.1145/2556325.2566239,"Videos are a widely-used kind of resource for online learning. This paper presents an empirical study of how video production decisions affect student engagement in online educational videos. To our knowledge, ours is the largest-scale study of video engagement to date, using data from 6.9 million video watching sessions across four courses on the edX MOOC platform. We measure engagement by how long students are watching each video, and whether they attempt to answer post-video assessment problems.Our main findings are that shorter videos are much more engaging, that informal talking-head videos are more engaging, that Khan-style tablet drawings are more engaging, that even high-quality pre-recorded classroom lectures might not make for engaging online videos, and that students engage differently with lecture and tutorial videos.Based upon these quantitative findings and qualitative insights from interviews with edX staff, we developed a set of recommendations to help instructors and video producers take better advantage of the online video format. Finally, to enable researchers to reproduce and build upon our findings, we have made our anonymized video watching data set and analysis scripts public. To our knowledge, ours is one of the first public data sets on MOOC resource usage.","New York, NY, USA",,"Guo, Philip J. and Kim, Juho and Rubin, Rob",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566239,9.78145E+12,"online education, video engagement, mooc","Atlanta, Georgia, USA",10,41?€?50,Association for Computing Machinery,L@S '14,How Video Production Affects Student Engagement: An Empirical Study of MOOC Videos,https://doi.org/10.1145/2556325.2566239,2014
inproceedings,10.1145/2556325.2566248,"Video games are increasingly recognized as a compelling platform for instruction that could be leveraged to teach students at scale. Hint systems that provide personalized feedback to students in real time are a central component of many effective interactive learning environments, however little is known about how hints impact player behavior and motivation in educational games. In this work, we study the effectiveness of hints by comparing four designs based on successful hint systems in intelligent tutoring systems and commercial games. We present results from a study of 50,000 students showing that all four hint systems negatively impacted performance compared to a baseline condition with no hints. These results suggest that traditional hint systems may not translate well into the educational game environment, highlighting the importance of studying student behavior to understand the impact of new interactive learning technologies.","New York, NY, USA",,"O'Rourke, Eleanor and Ballweber, Christy and Popovi\'{\i}, Zoran",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566248,9.78145E+12,"behavioral analytics, educational games, hint systems","Atlanta, Georgia, USA",10,51?€?60,Association for Computing Machinery,L@S '14,Hint Systems May Negatively Impact Performance in Educational Games,https://doi.org/10.1145/2556325.2566248,2014
inproceedings,10.1145/2556325.2566244,"In Fall 2013 we offered an open online Introduction to Recommender Systems through Coursera, while simultaneously offering a for-credit version of the course on-campus using the Coursera platform and a flipped classroom instruction model. As the goal of offering this course was to experiment with this type of instruction, we performed extensive evaluation including surveys of demographics, self-assessed skills, and learning intent; we also designed a knowledge-assessment tool specifically for the subject matter in this course, administering it before and after the course to measure learning. We also tracked students through the course, including separating out students enrolled for credit from those enrolled only for the free, open course. This article reports on our findings.","New York, NY, USA",,"Konstan, Joseph A. and Walker, J.D. and Brooks, D. Christopher and Brown, Keith and Ekstrand, Michael D.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566244,9.78145E+12,"mooc, evaluation, open learning, distance learning","Atlanta, Georgia, USA",10,61?€?70,Association for Computing Machinery,L@S '14,Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC,https://doi.org/10.1145/2556325.2566244,2014
inproceedings,10.1145/2556325.2566245,"This research investigates the impact professors, and other instructional staff, have on student content knowledge acquisition in a physical science MOOC offered through the University of Illinois at Urbana-Champaign. An A/B test was used to randomly assign MOOC participants in either a control group (with no instructional interaction) or an intervention group (in which the professor and teaching assistants responded to comments in the discussion and complied summary weekly feedback statements) to identify the differences in learning outcomes, participation rates, and student satisfaction. The study found that instructor intervention had no statistically significant impact on overall completion rates, overall badge acquisition rates, student participation rates, or satisfaction with the course, but did (p&lt;0.05) lead to a higher rate of forum badge completion, an area that was targeted by the intervention.","New York, NY, USA",,"Tomkin, Jonathan H. and Charlevoix, Donna",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566245,9.78145E+12,"a/b testing, mooc, collaborative learning.","Atlanta, Georgia, USA",8,71?€?78,Association for Computing Machinery,L@S '14,Do Professors Matter? Using an a/b Test to Evaluate the Impact of Instructor Involvement on MOOC Student Outcomes,https://doi.org/10.1145/2556325.2566245,2014
inproceedings,10.1145/2556325.2566246,"For an instructor who is teaching a massive open online course (MOOC), what is the best way to understand their class? What is the best way to view how the students are interacting with the content while the course is running? To help prepare for the next iteration, how should the course's data be best analyzed after the fact? How do these instructional monitoring needs differ between online courses with tens of thousands of students and courses with only tens? This paper reports the results of a survey of 92 MOOC instructors who answered questions about which information they find useful in their course, with the end goal of creating an information display for MOOC instructors.The main findings are: (i) quantitative data sources such as grades, although useful, are not sufficient; understanding the activity in discussion forums and student surveys was rated useful for all use cases by a large majority of respondents, (ii) chat logs were not seen as useful, (iii) for the most part, the same sources of information were seen as useful as found in surveys of smaller online courses, (iv) mockups of existing and novel visualization techniques were responded to positively for use both while the course is running and for planning a revision of the course, and (v) a wide range of views was expressed about other details.","New York, NY, USA",,"Stephens-Martinez, Kristin and Hearst, Marti A. and Fox, Armando",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566246,9.78145E+12,"e-learning, moocs, visualizations, instructor support, massive open online courses","Atlanta, Georgia, USA",10,79?€?88,Association for Computing Machinery,L@S '14,Monitoring MOOCs: Which Information Sources Do Instructors Value?,https://doi.org/10.1145/2556325.2566246,2014
inproceedings,10.1145/2556325.2566243,"In comparison to multiple choice or other recognition-oriented forms of assessment, short answer questions have been shown to offer greater value for both students and teachers; for students they can improve retention of knowledge, while for teachers they provide more insight into student understanding. Unfortunately, the same open-ended nature which makes them so valuable also makes them more difficult to grade at scale. To address this, we propose a cluster-based interface that allows teachers to read, grade, and provide feedback on large groups of answers at once. We evaluated this interface against an unclustered baseline in a within-subjects study with 25 teachers, and found that the clustered interface allows teachers to grade substantially faster, to give more feedback to students, and to develop a high-level view of students' understanding and misconceptions.","New York, NY, USA",,"Brooks, Michael and Basu, Sumit and Jacobs, Charles and Vanderwende, Lucy",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566243,9.78145E+12,"clustering, assessment, user interfaces, moocs, grading interfaces, grading, clustering interfaces","Atlanta, Georgia, USA",10,89?€?98,Association for Computing Machinery,L@S '14,Divide and Correct: Using Clusters to Grade Short Answers at Scale,https://doi.org/10.1145/2556325.2566243,2014
inproceedings,10.1145/2556325.2566238,"Peer assessment helps students reflect and exposes them to different ideas. It scales assessment and allows large online classes to use open-ended assignments. However, it requires students to spend significant time grading. How can we lower this grading burden while maintaining quality? This paper integrates peer and machine grading to preserve the robustness of peer assessment and lower grading burden. In the identify-verify pattern, a grading algorithm first predicts a student grade and estimates confidence, which is used to estimate the number of peer raters required. Peers then identify key features of the answer using a rubric. Finally, other peers verify whether these feature labels were accurately applied. This pattern adjusts the number of peers that evaluate an answer based on algorithmic confidence and peer agreement. We evaluated this pattern with 1370 students in a large, online design class. With only 54% of the student grading time, the identify-verify pattern yields 80-90% of the accuracy obtained by taking the median of three peer scores, and provides more detailed feedback. A second experiment found that verification dramatically improves accuracy with more raters, with a 20% gain over the peer-median with four raters. However, verification also leads to lower initial trust in the grading system. The identify-verify pattern provides an example of how peer work and machine learning can combine to improve the learning experience.","New York, NY, USA",,"Kulkarni, Chinmay E. and Socher, Richard and Bernstein, Michael S. and Klemmer, Scott R.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566238,9.78145E+12,"assessment, automated assessment, peer learning, online learning","Atlanta, Georgia, USA",10,99?€?108,Association for Computing Machinery,L@S '14,Scaling Short-Answer Grading by Combining Peer Assessment with Algorithmic Scoring,https://doi.org/10.1145/2556325.2566238,2014
inproceedings,10.1145/2556325.2566241,"While there is a large amount of work on creating autograded massive open online courses (MOOCs), some kinds of complex, qualitative exam questions are still beyond the current state of the art. For MOOCs that need to deal with these kinds of questions, it is not possible for a small course staff to grade students' qualitative work. To test the efficacy of self-evaluation as a method for complex-question evaluation, students in two Google MOOCs have submitted projects and evaluated their own work. For both courses, teaching assistants graded a random sample of papers and compared their grades with self-evaluated student grades. We found that many of the submitted projects were of very high quality, and that a large majority of self-evaluated projects were accurately evaluated, scoring within just a few points of the gold standard grading.","New York, NY, USA",,"Wilkowski, Julia and Russell, Daniel M. and Deutsch, Amit",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566241,9.78145E+12,"distance learning, moocs, assessment","Atlanta, Georgia, USA",8,109?€?116,Association for Computing Machinery,L@S '14,Self-Evaluation in Advanced Power Searching and Mapping with Google MOOCs,https://doi.org/10.1145/2556325.2566241,2014
inproceedings,10.1145/2556325.2566249,"Discussion forums, employed by MOOC providers as the primary mode of interaction among instructors and students, have emerged as one of the important components of online courses. We empirically study contribution behavior in these online collaborative learning forums using data from 44 MOOCs hosted on Coursera, focusing primarily on the highest-volume contributors---""superposters""---in a forum. We explore who these superposters are and study their engagement patterns across the MOOC platform, with a focus on the following question---to what extent is superposting a positive phenomenon for the forum? Specifically, while superposters clearly contribute heavily to the forum in terms of quantity, how do these contributions rate in terms of quality, and does this prolific posting behavior negatively impact contribution from the large remainder of students in the class?We analyze these questions across the courses in our dataset, and find that superposters display above-average engagement across Coursera, enrolling in more courses and obtaining better grades than the average forum participant; additionally, students who are superposters in one course are significantly more likely to be superposters in other courses they take. In terms of utility, our analysis indicates that while being neither the fastest nor the most upvoted, superposters' responses are speedier and receive more upvotes than the average forum user's posts; a manual assessment of quality on a subset of this content supports this conclusion that a large fraction of superposter contributions indeed constitute useful content. Finally, we find that superposters' prolific contribution behavior does not `drown out the silent majority'---high superposter activity correlates positively and significantly with higher overall activity and forum health, as measured by total contribution volume, higher average perceived utility in terms of received votes, and a smaller fraction of orphaned threads.","New York, NY, USA",,"Huang, Jonathan and Dasgupta, Anirban and Ghosh, Arpita and Manning, Jane and Sanders, Marc",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566249,9.78145E+12,"data mining, mooc, education, collaborative learning, online forums, massive open online course, coursera","Atlanta, Georgia, USA",10,117?€?126,Association for Computing Machinery,L@S '14,Superposter Behavior in MOOC Forums,https://doi.org/10.1145/2556325.2566249,2014
inproceedings,10.1145/2556325.2566242,"We study effects of introducing a real-time chatroom into a massive open online course with several thousand students, supplementing an existing forum. The chatroom was supported by teaching assistants, and generated thousands of lines of discussion by 28% of 681 consenting chat condition participants, mostly on-topic. Despite this, chat activity remained low ($mu=8.2$ messages per hour) and we could find no significant effect of chat use on objective or subjective dependent variables such as grades, retention, forum participation, or students' sense of community. Further investigation reveals that only 12% of chat participants have substantive interactions, while the remainder are either passive or have trivial interactions that are unlikely to result in learning.We also find that pervasive, highly visible chat interfaces are highly effective in encouraging both active and substantive participation in chat. When compared to chat interfaces that are restricted to a single webpage, the pervasive interface exhibits changes{2.8 times} as many users with substantive interactions.","New York, NY, USA",,"Coetzee, Derrick and Fox, Armando and Hearst, Marti A. and Hartmann, Bjoern",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2566242,9.78145E+12,"experiment, retention, chat, massive open online course, synchronous, mooc, chatroom, participation","Atlanta, Georgia, USA",10,127?€?136,Association for Computing Machinery,L@S '14,Chatrooms in MOOCs: All Talk and No Action,https://doi.org/10.1145/2556325.2566242,2014
inproceedings,10.1145/2556325.2579110,"The software platforms that mediate online learning experiences are the common ground where learning science and computer science intersect. This panel will discuss the affordances of current online learning platforms and lessons learned in using them with students. The goal of the panel is to help learning scientists and computer scientists understand each others' needs and how they might be effectively addressed in these platforms. The panelists, who have experience creating/using these platforms and interacting with learning scientists, will discuss how current platforms for learning at scale might evolve to better serve the community.","New York, NY, USA",,"Sahami, Mehran and Kohlmeier, Jace and Norvig, Peter and Paepcke, Andreas and Saberi, Amin",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2579110,9.78145E+12,"massive open online courses, moocs, online learning","Atlanta, Georgia, USA",2,137?€?138,Association for Computing Machinery,L@S '14,Panel: Online Learning Platforms and Data Science,https://doi.org/10.1145/2556325.2579110,2014
inproceedings,10.1145/2556325.2567848,"Since introducing Internet-based distance education programs in 1996, Drexel University has gained recognition as an online education leader. Remaining at the vanguard means finding innovative, automated solutions to determine which students are contributing to thoughtful discussion, helping faculty engage with online students more efficiently, and spending less time managing ever more complex Learning Management Systems (LMS). We introduce ForumDash, a BBLearn plugin for the Blackboard LMS1, designed to enhance online learning. Through its three visualization tools, ForumDash shows instructors which students are contributing, struggling, or distracted, thereby helping instructors target their efforts, save time managing online courses, and scale course tools up to the level of Massive Open Online Courses (MOOCs). ForumDash also provides students with performance feedback, showing them whether their participation levels are satisfactory. Initial testing with two Drexel University Online courses produced positive feedback, and larger scale testing is in progress.","New York, NY, USA",,"Speck, Jacquelin and Gualtieri, Eugene and Naik, Gaurav and Nguyen, Thach and Cheung, Kevin and Alexander, Larry and Fenske, David",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567848,9.78145E+12,"learning management systems, online learning, information visualization","Atlanta, Georgia, USA",2,139?€?140,Association for Computing Machinery,L@S '14,ForumDash: Analyzing Online Discussion Forums,https://doi.org/10.1145/2556325.2567848,2014
inproceedings,10.1145/2556325.2567849,"The Online Course Tool for Adaptive Learning (OCTAL) is an adaptive exercise system that customizes the progression of question topics to each student. By creating a concept dependency graph of topics in a course and modeling a student's knowledge state, the tool presents questions that test knowledge within a student's zone of proximal development. We intend OCTAL to be a formative assessment tool that is not tied to any specific course by providing language-agnostic questions on computer science concepts. While the tool will be generalizable for many courses, our first prototype includes a concept map and question set for UC Berkeley's introductory computer science course, CS10: The Beauty and Joy of Computing. Using the tool, we will launch an experiment in the spring to investigate metacognitive improvements in the identification of knowledge gaps by presenting online course material in a nonlinear fashion.","New York, NY, USA",,"Armendariz, Daniel and MacHardy, Zachary and Garcia, Daniel D.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567849,9.78145E+12,"adaptive assessment, non-linear courses, student modeling, concept map","Atlanta, Georgia, USA",2,141?€?142,Association for Computing Machinery,L@S '14,OCTAL: Online Course Tool for Adaptive Learning,https://doi.org/10.1145/2556325.2567849,2014
inproceedings,10.1145/2556325.2567850,"In many online courses, information about learners is collected via surveys for accounting, instructional design, and research purposes. Aggregate information from such surveys is frequently reported in news articles and research papers, among other publications. While some authors acknowledge the potential bias due to non-response in course surveys, there are no investigations on the severity of the bias and methods for bias reduction in the online education context. A regression-based response-propensity model is described and applied to reweight a course survey, and discrepancies between adjusted and unadjusted outcome distributions are provided.","New York, NY, USA",,"Kizilcec, Ren\'{e} F.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567850,9.78145E+12,"non-response bias, survey research, survey reweighting","Atlanta, Georgia, USA",2,143?€?144,Association for Computing Machinery,L@S '14,Reducing Non-Response Bias with Survey Reweighting: Applications for Online Learning Researchers,https://doi.org/10.1145/2556325.2567850,2014
inproceedings,10.1145/2556325.2567851,"Massive Open Online Courses (MOOCs) are seen as an opportunity for individuals to gain access to education, develop new skills to prepare for high-paying jobs, and achieve upward mobility without incurring the increasingly high debt that comes with a university degree. Despite this perception, few studies have examined whether populations with the most to gain do leverage these resources. We analyzed student demographic information from course surveys and performance data of MOOC participation in a single course. We targeted students who stated that they were motivated to take the course because they ""cannot afford to pursue a formal education,"" and compared them to the group of all other students. Our three key findings are that 1) a higher percentage of non-traditional enrolled students are in this population than the comparison population, 2) in an independent t-test, a statistically significant portion (28%) of this group has less than a 4-year college degree versus 15% of the comparison group, and 3) the completion rate between both groups are relatively equal.","New York, NY, USA",,"Dillahunt, Tawanna and Chen, Bingxin and Teasley, Stephanie",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567851,9.78145E+12,"affordability, moocs, learning analytics, education","Atlanta, Georgia, USA",2,145?€?146,Association for Computing Machinery,L@S '14,Model Thinking: Demographics and Performance of Mooc Students Unable to Afford a Formal Education,https://doi.org/10.1145/2556325.2567851,2014
inproceedings,10.1145/2556325.2567852,"Understanding motivations for enrolling in MOOCs is key for personalizing and scaling the online learning experience. We develop a standardized survey item for measuring learners' reasons to enroll, based on a corpus of open-ended responses from previous course surveys. Online coders were employed in the iterative development of response options. The item was designed to minimize response biases by adhering to best practices from survey design research.","New York, NY, USA",,"Schneider, Emily and Kizilcec, Ren\'{e} F.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567852,9.78145E+12,"survey research, motivation, mooc learner goals","Atlanta, Georgia, USA",2,147?€?148,Association for Computing Machinery,L@S '14,"""Why Did You Enroll in This Course?"": Developing a Standardized Survey Question for Reasons to Enroll",https://doi.org/10.1145/2556325.2567852,2014
inproceedings,10.1145/2556325.2567853,"Computer-based learning environments can provide valuable resources for learning at scale, but students in these environments might learn without an instructor. Subgoal labels have been used in worked examples in STEM domains to help a learner understand the purpose of a set of steps, and this feature has increased problem solving performance [1]. Subgoal labels, however, have not been tested in instructional text. The present study explored this intervention. The results of the present study show that learners who received subgoal labels in both the text and example outperformed those in other conditions. When subgoal labeled text is paired with an unlabeled example, however, performance does not improve. These findings indicate that subgoal labeled instructional text when paired with subgoal labeled examples can improve performance in a computer-based learning environment.","New York, NY, USA",,"Margulieux, Lauren E. and Catrambone, Richard",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567853,9.78145E+12,"stem education, subgoal learning, procedural text, online learning, worked examples","Atlanta, Georgia, USA",2,149?€?150,Association for Computing Machinery,L@S '14,Improving Problem Solving Performance in Computer-Based Learning Environments through Subgoal Labels,https://doi.org/10.1145/2556325.2567853,2014
inproceedings,10.1145/2556325.2567854,"Peer learning, in which students discuss questions in small groups, has been widely reported to improve learning outcomes in traditional classroom settings. Classroom-based peer learning relies on students being in the same place at the same time to form peer discussion groups, but this is rarely true for online students in MOOCs. We built a software tool that facilitates chat-based peer learning in MOOCs by 1) automatically forming ad-hoc discussion groups and 2) scaffolding the interactions between students in these groups. We report on a pilot deployment of this tool; post-use surveys administered to participants show that the tool was positively received and support the feasibility of synchronous online collaborative learning in MOOCs.","New York, NY, USA",,"Lim, Seongtaek and Coetzee, Derrick and Hartmann, Bjoern and Fox, Armando and Hearst, Marti A.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567854,9.78145E+12,"chat, massive open online courses (moocs), peer learning","Atlanta, Georgia, USA",2,151?€?152,Association for Computing Machinery,L@S '14,Initial Experiences with Small Group Discussions in MOOCs,https://doi.org/10.1145/2556325.2567854,2014
inproceedings,10.1145/2556325.2567855,"Video lectures are nowadays widely used by growing numbers of learners all over the world. Nevertheless, learners' interactions with the videos are not readily available, because online video platforms do not share them. In this paper, we present an open-source video learning analytics system, which is also available as a free service to researchers. Our system facilitates the analysis of video learning behavior by capturing learners' interactions with the video player (e.g, seek/scrub, play, pause). In an empirical user study, we captured hundreds of user interactions with the video player by analyzing the interactions as a learner activity time series. We found that learners employed the replaying activity to retrieve the video segments that contained the answers to the survey questions. The above findings indicate the potential of video analytics to represent learner behavior. Further research, should be able to elaborate on learner behavior by collecting large-scale data. In this way, the producers of online video pedagogy will be able to understand the use of this emerging medium and proceed with the appropriate amendments to the current video-based learning systems and practices.","New York, NY, USA",,"Chorianopoulos, Konstantinos and Giannakos, Michail N. and Chrisochoides, Nikos",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567855,9.78145E+12,"video, user interactions, learning analytics, education","Atlanta, Georgia, USA",2,153?€?154,Association for Computing Machinery,L@S '14,Open System for Video Learning Analytics,https://doi.org/10.1145/2556325.2567855,2014
inproceedings,10.1145/2556325.2567856,"Given a class of large number of students, each exhibiting a different ability level, how can we form teams of students so that the expected performance of team members improves due to team participation? We take a computational perspective and formally define two versions of such team-formation problem: the MAXTEAM and the MAXPARTITION problems. The first asks for the identification of a single team of students that improves the performance of most of the participating team members. The second asks for a partitioning of students into non-overlapping teams that also maximizes the benefit of the participating students. We show that the first problem can be solved optimally in polynomial time, while the second is NP-complete. For the MAXPARTITION problem, we also design an efficient approximate algorithm for solving it. Our experiments with generated data coming from different distributions demonstrate that our algorithm is significantly better than any of the popular strategies for dividing students in a class into sections.","New York, NY, USA",,"Agrawal, Rakesh and Golshan, Behzad and Terzi, Evimaria",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567856,9.78145E+12,"clustering, education","Atlanta, Georgia, USA",2,155?€?156,Association for Computing Machinery,L@S '14,Forming Beneficial Teams of Students in Massive Online Classes,https://doi.org/10.1145/2556325.2567856,2014
inproceedings,10.1145/2556325.2567857,"Maintaining and cultivating student engagement is a prerequisite for MOOCs to have broad educational impact. Understanding student engagement as a course progresses helps characterize student learning patterns and can aid in minimizing dropout rates, initiating instructor intervention. In this paper, we construct a probabilistic model connecting student behavior and class performance, formulating student engagement types as latent variables. We show that our model identifies course success indicators that can be used by instructors to initiate interventions and assist students.","New York, NY, USA",,"Ramesh, Arti and Goldwasser, Dan and Huang, Bert and Daume, Hal and Getoor, Lise",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567857,9.78145E+12,"mooc, learner engagement, probabilistic modeling","Atlanta, Georgia, USA",2,157?€?158,Association for Computing Machinery,L@S '14,Uncovering Hidden Engagement Patterns for Predicting Learner Performance in MOOCs,https://doi.org/10.1145/2556325.2567857,2014
inproceedings,10.1145/2556325.2567858,"Programming best-practices are a difficult subject to learn for beginner computer science students. In the classroom, these practices are appreciated and taught through a combination of lectures and group projects. Group projects, however, take time and are ill-suited for Massive Open Online Courses (MOOCs).This project aims to develop a web-based many-player programming game which addresses these issues by having large numbers of students code many small functions in parallel, give feedback on each other's implementations, and compose them into much larger programs. Gameplay will require only a few hours and should provide rapid and substantive feedback on the reusability and flexibility of a student's code.We have developed and playtested a small-scale prototype to determine if software engineering lessons could be learned through such a game. Further prototypes will test the game at MOOC scales and with different structures. We will develop a final version to deploy to MIT's online class 6.005x: Software Construction.","New York, NY, USA",,"Xiao, David and Miller, Robert C.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567858,9.78145E+12,"educational games, team programming, moocs, software engineering education","Atlanta, Georgia, USA",2,159?€?160,Association for Computing Machinery,L@S '14,A Multiplayer Online Game for Teaching Software Engineering Practices,https://doi.org/10.1145/2556325.2567858,2014
inproceedings,10.1145/2556325.2567859,"In the physical classroom, peer interactions motivate students and expand their perspective. We suggest that synchronous peer interaction can benefit massive online courses as well. Talkabout organizes students into video discussion groups and allows instructors to determine group composition and discussion content. Using Talkabout, students pick a discussion time that suits their schedule. The system groups the students into small video discussions based on instructor preferences such as gender or geographic balance. To date, 2,474 students in five massive online courses have used Talkabout to discuss topics ranging from prejudice to organizational theory. Talkabout discussions are diverse: in one course, the median six-person discussion group had students from four different countries. Students enjoyed discussing in these diverse groups: the average student participated for 66 minutes, twice the course requirement. Students in more geographically distributed groups also scored higher on the final, suggesting that distributed discussions have educational value.","New York, NY, USA",,"Cambre, Julia and Kulkarni, Chinmay and Bernstein, Michael S. and Klemmer, Scott R.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567859,9.78145E+12,"small groups, discussion, synchronous collaboration, video","Atlanta, Georgia, USA",2,161?€?162,Association for Computing Machinery,L@S '14,Talkabout: Small-Group Discussions in Massive Global Classes,https://doi.org/10.1145/2556325.2567859,2014
inproceedings,10.1145/2556325.2567860,"Massive online courses introduced Community TAs (CTAs) to help scale teaching staff support. CTAs are former top students who return as volunteer course staff. We studied CTAs in 3 classes on Coursera, including interviews and surveys from a Human-Computer Interaction (HCI) class. A key benefit of CTAs is their brokering role that mediates staff and student goals. CTAs provide greater discussion forum coverage (both in quantity and time of day) compared to instructor and Head TA (HTA) capabilities and contribute to peer assessment. As CTAs are new teachers, physically distributed, and culturally diverse, clear division of responsibilities is especially important.","New York, NY, USA",,"Papadopoulos, Kathryn and Sritanyaratana, Lalida and Klemmer, Scott R.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567860,9.78145E+12,"volunteer teaching, community tas, teaching assistants","Atlanta, Georgia, USA",2,163?€?164,Association for Computing Machinery,L@S '14,"Community TAs Scale High-Touch Learning, Provide Student-Staff Brokering, and Build Esprit de Corps",https://doi.org/10.1145/2556325.2567860,2014
inproceedings,10.1145/2556325.2567861,"Online environments introduce unprecedented scale for formal and informal learning communities. In these environments, user-contributed content enables social constructivist approaches to education. In particular, students can help each other by providing hints and suggestions on how to approach problems, by rating each other's suggestions, and by engaging in discussions about the questions. In addition, students can also learn through composing their own questions. Furthermore, with grounding in Item Response Theory, data mining and statistical student models can assess questions and hints for their quality and effectiveness. As a result, internet-scale learning environments allow us to move from simple, canned quizzing systems to a new model where automated, data-driven analysis continuously assesses and refines the quality of teaching material. Our poster describes a framework and prototype of an online drill-and-practice system that leverages user-contributed content and large-scale data to organically improve itself.","New York, NY, USA",,"Buffardi, Kevin and Edwards, Stephen H.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567861,9.78145E+12,"adaptive feedback, active learning, item response theory, automated assessment, computer-supported cooperative learning (cscl), social constructivism, internet-scale data","Atlanta, Georgia, USA",2,165?€?166,Association for Computing Machinery,L@S '14,Adaptive and Social Mechanisms for Automated Improvement of ELearning Materials,https://doi.org/10.1145/2556325.2567861,2014
inproceedings,10.1145/2556325.2567862,This paper discusses learning at scale from the perspective of two UK Universities engaging in technology enhanced learning. Three case studies are used to illustrate ways in which scale has been achieved. There is diversity in how scale is supported but also common factors. Openness and choice appear as enablers in all cases.,"New York, NY, USA",,"Scanlon, Eileen and McAndrew, Patrick and O'Shea, Tim",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567862,9.78145E+12,distance learning,"Atlanta, Georgia, USA",2,167?€?168,Association for Computing Machinery,L@S '14,"Distance Learning, OER, and MOOCs: Some UK Experiences",https://doi.org/10.1145/2556325.2567862,2014
inproceedings,10.1145/2556325.2567863,"Massive open online courses (MOOCs) provide learning materials and automated assessments for large numbers of virtual users. Because every interaction is recorded, we can longitudinally model performance over the course of the class. We create a panel model of achievement in an early MOOC to estimate within- and between-user differences. In this study, we hope to contribute to HCI literature by, first, applying quasi-experimental methods to identify behaviors that may support student learning in a virtual environment, and, second, by using a panel model that takes into account the longitudinal, dynamic nature of a multiple-week class.","New York, NY, USA",,"DeBoer, Jennifer and Breslow, Lori",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567863,9.78145E+12,"longitudinal modeling, moocs, learning activities","Atlanta, Georgia, USA",2,169?€?170,Association for Computing Machinery,L@S '14,Tracking Progress: Predictors of Students' Weekly Achievement during a Circuits and Electronics MOOC,https://doi.org/10.1145/2556325.2567863,2014
inproceedings,10.1145/2556325.2567865,"Open-ended homework problems such as coding assignments give students a broad range of freedom for the design of solutions. We aim to use the diversity in correct solutions to enhance student learning by automatically suggesting alternate solutions. Our approach is to perform a two-level hierarchical clustering of student solutions to first partition them based on the choice of algorithm and then partition solutions implementing the same algorithm based on low-level implementation details. Our initial investigations in domains of introductory programming and computer architecture demonstrate that we need two different classes of features to perform effective clustering at the two levels, namely abstract features and concrete features.","New York, NY, USA",,"Glassman, Elena L. and Singh, Rishabh and Miller, Robert C.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567865,9.78145E+12,"program comprehension, algorithm recognition, feature engineering","Atlanta, Georgia, USA",2,171?€?172,Association for Computing Machinery,L@S '14,Feature Engineering for Clustering Student Solutions,https://doi.org/10.1145/2556325.2567865,2014
inproceedings,10.1145/2556325.2567866,"Discussion forums are an integral part of all online and many offline courses. But in many cases they are presented as an afterthought, offered to the students to use as they wish. In this paper, we explore ways to steer discussion forums to produce high-quality learning interactions. In the context of a Physics course, we investigate two ideas: seeding the forum with prior-year student content, and varying the sizes of ""sections"" of students who can see each other's comments.","New York, NY, USA",,"Miller, Kelly and Zyto, Sacha and Karger, David and Mazur, Eric",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567866,9.78145E+12,annotation software,"Atlanta, Georgia, USA",2,173?€?174,Association for Computing Machinery,L@S '14,Improving Online Class Forums by Seeding Discussions and Managing Section Size,https://doi.org/10.1145/2556325.2567866,2014
inproceedings,10.1145/2556325.2567867,Student Explorer is an early warning system designed to support academic advising that uses learning analytics to categorize students' ongoing academic performance and effort. Advisors use this tool to provide just-in-time assistance to students at risk of underperforming in their classes. Student Explorer is designed to eventually support targeted advising for thousands of undergraduate students.,"New York, NY, USA",,"Lonn, Steven and Teasley, Stephanie D.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567867,9.78145E+12,"higher education, academic advising, learning analytics","Atlanta, Georgia, USA",2,175?€?176,Association for Computing Machinery,L@S '14,Student Explorer: A Tool for Supporting Academic Advising at Scale,https://doi.org/10.1145/2556325.2567867,2014
inproceedings,10.1145/2556325.2567868,"Learning programming at scale underlies computer science education ranging from basic programming to advanced software engineering topics. There are strong needs of providing effective system supports for learning programming at scale. Among various desirable characteristics of such system supports, system supports shall allow students to write programs via an online Integrated Development Environment (IDE), allow students to get feedback on how they perform on the given programming exercises, etc. To aim for such effective system supports for learning programming at scale, research teams from Peking University have developed two systems: POP (denoting Peking University Online Programming System) and POJ (denoting Peking University Online Judge System). These two systems have achieved high impact among students around the world (especially those in China). In this paper, we present the overview of the two systems, along with our ongoing and future work on extending the systems for achieving higher effectiveness in supporting learning programming at scale.","New York, NY, USA",,"Wang, Qianxiang and Li, Wenxin and Xie, Tao",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567868,9.78145E+12,"online ide, programming systems","Atlanta, Georgia, USA",2,177?€?178,Association for Computing Machinery,L@S '14,Educational Programming Systems for Learning at Scale,https://doi.org/10.1145/2556325.2567868,2014
inproceedings,10.1145/2556325.2567869,"Due to the recent emergence of massive open online courses (MOOCs), students and teachers are gaining unprecedented access to high-quality educational content. However, many questions remain on how best to utilize that content in a classroom environment. In this small-scale, exploratory study, we compared two ways of using a recorded video lecture. In the online learning condition, students viewed the video on a personal computer, and also viewed a follow-up tutorial (a quiz review) on the computer. In the blended learning condition, students viewed the video as a group in a classroom, and received the follow-up tutorial from a live lecturer. We randomly assigned 102 students to these conditions, and assessed learning outcomes via a series of quizzes. While we saw significant learning gains after each session conducted, we did not observe any significant differences between the online and blended learning groups. We discuss these findings as well as areas for future work.","New York, NY, USA",,"Cross, Andrew and Ashok, B. and Bala, Srinath and Cutrell, Edward and Datha, Naren and Kumar, Rahul and Kumar, Viraj and Parthasarathy, Madhusudan and Prakash, Siddharth and Rajamani, Sriram and Sangameswaran, Satish and Sharma, Deepika and Thies, William",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567869,9.78145E+12,"massive open online course, massively empowered classroom, online education, blended learning","Atlanta, Georgia, USA",2,179?€?180,Association for Computing Machinery,L@S '14,Online Learning versus Blended Learning: An Exploratory Study,https://doi.org/10.1145/2556325.2567869,2014
inproceedings,10.1145/2556325.2567871,"In large programming classes, MOOCs or online communities, it is challenging to find peers and mentors to help with learning specific programming concepts. In this paper we present first steps towards an automated, scalable system for matching learners with Python programmers who have expertise in different areas. The learner matching system builds a knowledge model for each programmer by analyzing their authored code and extracting features that capture domain knowledge and style. We demonstrate the feasibility of a simple model that counts the references to modules from the standard library and Python Package Index in a programmers' code. We also show that programmers exhibit self-selection using which we can extract the modules a programmer is best at, even though we may not have all of their code. In our future work we aim to extend the model to encapsulate more features, and apply it for skill matching in a programming class as well as personalizing answers on StackOverflow.","New York, NY, USA",,"Pai, Anvisha H. and Guo, Philip J. and Miller, Robert C.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567871,9.78145E+12,"learner modeling, personalized learning, skill matching","Atlanta, Georgia, USA",2,181?€?182,Association for Computing Machinery,L@S '14,Modeling Programming Knowledge for Mentoring at Scale,https://doi.org/10.1145/2556325.2567871,2014
inproceedings,10.1145/2556325.2567872,"Online learners need various supports to survive, and it is especially true in the context of MOOCs. Yet, studies documenting the learning progress as a function of learner support are at its inception. Based on self-determination theory and via weekly study group, we devised a series of support strategies to promote the autonomy, relatedness, and competency of MOOCs learners. We evaluated how those support strategies influenced MOOCs learners' retention rate and their self-regulation behaviors such as goal setting, time management, and help seeking. While this study is still on going, initial results showed that participants had higher intrinsic motivation than extrinsic motivation. Furthermore, participants expressed that the weekly meet-up had been very helpful to keep them going, especially when they wanted to give up. Interestingly, participants' learning strategies rarely changed even new strategies had been shared in group. Implications for researchers, designers and MOOCs learners are discussed.","New York, NY, USA",,"Chen, Pin-Ju and Chen, Yang-Hsueh",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567872,9.78145E+12,"self-regulated learning, self-determination theory, learning strategies, mooc, distance learning","Atlanta, Georgia, USA",2,183?€?184,Association for Computing Machinery,L@S '14,Facilitating MOOCs Learning through Weekly Meet-up: A Case Study in Taiwan,https://doi.org/10.1145/2556325.2567872,2014
inproceedings,10.1145/2556325.2567873,"A common pattern among undergraduate computer science curriculums is to teach an introductory subject in Python followed by a more advanced software engineering subject in Java. We are building an online tool that will help students who already know Python learn the syntax and semantics of Java. Our system will differ from existing online tutors and tools for learning Java in two main aspects. First, our tutor will focus on the transition from Python to Java. Using this basis will allow us to gloss over basic concepts of programming which students are already familiar with and focus on the specifics of Java. Second, our tutor will crowdsource writing test cases for problems to the learners themselves. This will give students practice writing tests, and will also reduce the burden on instructors, who would otherwise need to implement test suites for every problem in the tutor.","New York, NY, USA",,"O'Brien, Casey and Goldman, Max and Miller, Robert C.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567873,9.78145E+12,"java, tutor, python","Atlanta, Georgia, USA",2,185?€?186,Association for Computing Machinery,L@S '14,Java Tutor: Bootstrapping with Python to Learn Java,https://doi.org/10.1145/2556325.2567873,2014
inproceedings,10.1145/2556325.2567874,"Google Research recently tested a massive online class model for an internal engineering education program, with machine learning as the topic, that blended theoretical concepts and Google-specific software tool tutorials. The goal of this training was to foster engineering capacity to leverage machine learning tools in future products. The course was delivered both synchronously and asynchronously, and students had the choice between studying independently or participating with a group. Since all students are company employees, unlike most publicly offered MOOCs we can continue to measure the students' behavioral change long after the course is complete. This paper describes the course, outlines the available data set and presents directions for analysis.","New York, NY, USA",,"Asuncion, Arthur and de Haan, Jac and Mohri, Mehryar and Patel, Kayur and Rostamizadeh, Afshin and Syed, Umar and Wong, Lauren",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567874,9.78145E+12,"corporate training, moocs, connectivist moocs, distance learning, online learning","Atlanta, Georgia, USA",2,187?€?188,Association for Computing Machinery,L@S '14,Corporate Learning at Scale: Lessons from a Large Online Course at Google,https://doi.org/10.1145/2556325.2567874,2014
inproceedings,10.1145/2556325.2567875,"With instructional methods such as MOOCs and flipped classrooms rapidly gaining popularity and school budget cuts becoming more prevalent across the nation, increasing the usability of Open Educational Resources (OER) is highly relevant for today's educators. Although several OER databases exist providing access to hundreds of thousands of resources, navigating these spaces, evaluating resources, and integrating them within classroom instruction has proven less than efficient. The present research explores learning analytics for understanding real-world interaction patterns with SAS?? Curriculum Pathways??, which has over 120,000 active teacher users and over 1,300 freely available resources across multiple disciplines. In this preliminary investigation, users are clustered based on overall usage patterns. Patterns of resource interaction are then identified using association analysis. Results of this exploratory investigation provide insight into how users interact with large OER databases and introduce many avenues for continued investigation.","New York, NY, USA",,"Sabourin, Jennifer and Kosturko, Lucy and McQuiggan, Scott",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567875,9.78145E+12,"open educational resources, recommendation systems","Atlanta, Georgia, USA",2,189?€?190,Association for Computing Machinery,L@S '14,Teacher Usage Behaviors within an Online Open Educational Resource Repository,https://doi.org/10.1145/2556325.2567875,2014
inproceedings,10.1145/2556325.2567876,"Coding style is important to teach to beginning programmers, so that bad habits don't become permanent. This is often done manually at the University level because automated Python static analyzers cannot accurately grade based on a given rubric. However, even manual analysis of coding style encounters problems, as we have seen quite a bit of inconsistency among our graders. We introduce ACCE--Automated Coding Composition Evaluator--a module that automates grading for the composition of programs. ACCE, given certain constraints, assesses the composition of a program through static analysis, conversion from code to AST, and clustering (unsupervised learning), helping automate the subjective process of grading based on style and identifying common mistakes. Further, we create visual representations of the clusters to allow readers and students understand where a submission falls, and the overall trends. We have applied this tool to CS61A--a CS1 level course at UC, Berkeley experiencing rapid growth in student enrollment--in an attempt to help expedite the involved process as well as reduce human grader inconsistencies.","New York, NY, USA",,"Rogers, Stephanie and Tang, Steven and Canny, John",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567876,9.78145E+12,"visualization, grading, cs1, clustering, composition, assessment, unsupervised learning, gephi, autograding, style, evaluation","Atlanta, Georgia, USA",2,191?€?192,Association for Computing Machinery,L@S '14,ACCE: Automatic Coding Composition Evaluator,https://doi.org/10.1145/2556325.2567876,2014
inproceedings,10.1145/2556325.2567877,"Massive Open Online Courses (MOOCs) employ a variety of components to engage students in learning (eg. videos, forums, quizzes). Some components are graded, which means that they play a key role in a student's final grade and certificate attainment. It is not yet clear how the due date structure of graded components affects student outcomes including academic performance and alternative modes of learning of students. Using data from HarvardX and MITx, Harvard's and MIT's divisions for online learning, we study the structure of due dates on graded components for 10 completed MOOCs. We find that stricter due dates are associated with higher certificate attainment rates but fewer students who join late being able to earn a certificate. Our findings motivate further studies of how the use of graded components and deadlines affects academic and alternative learning of MOOC students, and can help inform the design of online courses.","New York, NY, USA",,"Nesterko, Sergiy O. and Seaton, Daniel and Reich, Justin and McIntyre, Joseph and Han, Qiuyi and Chuang, Isaac and Ho, Andrew",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567877,9.78145E+12,mooc due dates online learning,"Atlanta, Georgia, USA",2,193?€?194,Association for Computing Machinery,L@S '14,Due Dates in MOOCs: Does Stricter Mean Better?,https://doi.org/10.1145/2556325.2567877,2014
inproceedings,10.1145/2556325.2567878,"We use visual analytics to explore participation in five MOOCs at the University of Maryland. In some of these courses, our analysis reveals interesting clustering patterns of student behavior. For other courses, visualizations provide ""color"" to help us better understand the range of student behavior.","New York, NY, USA",,"Xu, Zhengzheng and Goldwasser, Dan and Bederson, Benjamin B. and Lin, Jimmy",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567878,9.78145E+12,"learn-ing analytics, evidence-based education, moocs, massive open online courses, coursera","Atlanta, Georgia, USA",2,195?€?196,Association for Computing Machinery,L@S '14,Visual Analytics of MOOCs at Maryland,https://doi.org/10.1145/2556325.2567878,2014
inproceedings,10.1145/2556325.2567879,"In this paper, we explore student dropout behavior in a Massively Open Online Course (MOOC). We use a survival model to measure the impact of three social factors that make predictions about attrition along the way for students who have participated in the course discussion forum.","New York, NY, USA",,"Ros\'{e}, Carolyn Penstein and Carlson, Ryan and Yang, Diyi and Wen, Miaomiao and Resnick, Lauren and Goldman, Pam and Sherer, Jennifer",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567879,9.78145E+12,"mooc, survival modeling","Atlanta, Georgia, USA",2,197?€?198,Association for Computing Machinery,L@S '14,Social Factors That Contribute to Attrition in MOOCs,https://doi.org/10.1145/2556325.2567879,2014
inproceedings,10.1145/2556325.2567880,"The emergence of tablet devices, cloud computing, and abundant online multimedia content presents new opportunities to transform traditional paper-based textbooks into tablet-based electronic textbooks, and to further augment the educational experience by enriching them with relevant supplementary materials. Given a candidate set of relevant educational videos for augmenting an electronic textbook, how do we assign the videos at the appropriate granularity (a collection of logical units in the book)? We propose a rigorous formulation of the video assignment problem and present an algorithm for assigning each video to the optimum subset of logical units. Our experimental evaluation using a diverse collection of educational videos relevant to multiple chapters in a textbook demonstrates the efficacy of the proposed techniques for inferring the granularity at which a relevant video should be assigned.","New York, NY, USA",,"Kokkodis, Marios and Kannan, Anitha and Kenthapadi, Krishnaram",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567880,9.78145E+12,"electronic textbooks, algorithms, education, data mining, augmenting with videos","Atlanta, Georgia, USA",2,199?€?200,Association for Computing Machinery,L@S '14,Assigning Videos to Textbooks at Appropriate Granularity,https://doi.org/10.1145/2556325.2567880,2014
inproceedings,10.1145/2556325.2567881,"Ensuring authorship in online taken exams is a major challenge for e-learning in general and MOOC's in particular. In this paper, we introduce and evaluate a method to verify student identities using stylometry. We present a carefully composed feature set and use it with a K-Nearest Neighbor algorithm. We demonstrate that our method can effectively authenticate authors and is robust against imitation attacks.","New York, NY, USA",,"Krause, Markus",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567881,9.78145E+12,"computation stylometry, authentication, elearning","Atlanta, Georgia, USA",2,201?€?202,Association for Computing Machinery,L@S '14,A Behavioral Biometrics Based Authentication Method for MOOC's That is Robust against Imitation Attempts,https://doi.org/10.1145/2556325.2567881,2014
inproceedings,10.1145/2556325.2567882,"In 2012, when MOOCs became largely known, media reports were fascinated with the big number of enrollments. The number 150,000 students was mentioned for both Stanford's Artificial Intelligence course and MIT's Circuits and Electronics, to be later followed by the underwhelming completion rates, that often are in the single digit percentages. But what kind of enrollment do these large numbers really show? We try to answer this question by breaking this number into its components, while comparing two successive iterations of the same MOOC offered on the edX platform.","New York, NY, USA",,"Mustafaraj, Eni",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567882,9.78145E+12,"learning analytics, visualization, moocs, engagement","Atlanta, Georgia, USA",2,203?€?204,Association for Computing Machinery,L@S '14,What Does Enrollment in a MOOC Mean?,https://doi.org/10.1145/2556325.2567882,2014
inproceedings,10.1145/2556325.2567883,"Lack of teachers to teach computer science (CS) and pedagogically sound introductory CS curricula remain a significant challenge facing secondary schools attempting to teach CS. This paper describes our efforts to design and pilot an online 6-week middle/high school course using Stanford's OpenEdX platform. The pedagogy, curriculum and assessment are guided by learning theory. The course leverages OpenEdX features for contextual discussions and multiple-choice assessments that promote student learning and provide feedback. The paper reports on experiences in using instructor dashboards to identify targets of student difficulty and to aid curriculum redesign.","New York, NY, USA",,"Grover, Shuchi and Pea, Roy and Cooper, Stephen",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567883,9.78145E+12,"learning theory, openedx, analytics, k-12 cs education, mooc, blended learning, instructional design, instructor dashboards, assessment","Atlanta, Georgia, USA",2,205?€?206,Association for Computing Machinery,L@S '14,Promoting Active Learning &amp; Leveraging Dashboards for Curriculum Assessment in an OpenEdX Introductory CS Course for Middle School,https://doi.org/10.1145/2556325.2567883,2014
inproceedings,10.1145/2556325.2567884,"Education and learning are currently undergoing transformative changes due to the emergence of tablet devices, cloud computing, and abundant online content. These trends present opportunities to transform traditional paper-based textbooks into tablet-based electronic textbooks, and to further enrich the educational experience by augmenting them with relevant supplementary materials. A natural question is whether this educational intervention, namely, enriching textbooks with relevant web articles, images and videos, is effective. It turns out that designing an experiment at scale for this purpose is nontrivial. We report on progress in designing and carrying out such an experiment.","New York, NY, USA",,"Agrawal, Rakesh and Jhaveri, M. Hanif and Kenthapadi, Krishnaram",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567884,9.78145E+12,"educational interventions, evaluation at scale, data mining, algorithms, education, electronic textbooks, augmenting with videos","Atlanta, Georgia, USA",2,207?€?208,Association for Computing Machinery,L@S '14,Evaluating Educational Interventions at Scale,https://doi.org/10.1145/2556325.2567884,2014
inproceedings,10.1145/2556325.2567885,"We present an overview of the design of a conversational intelligent tutoring system, called DeepTutor, based on the framework of Learning Progressions. Learning Progressions capture students' successful paths towards mastery. The assumption of the proposed tutor is that by guiding instruction based on Learning Progressions, the system will be more effective (and efficient for that matter).","New York, NY, USA",,"Rus, Vasile and Stefanescu, Dan and Niraula, Nobal and Graesser, Arthur C.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567885,9.78145E+12,"conversational tutors, learning progressions, intelligent tutoring systems, conceptual physics","Atlanta, Georgia, USA",2,209?€?210,Association for Computing Machinery,L@S '14,DeepTutor: Towards Macro- and Micro-Adaptive Conversational Intelligent Tutoring at Scale,https://doi.org/10.1145/2556325.2567885,2014
inproceedings,10.1145/2556325.2567886,"Educational Robotics for Absolute Beginners is a MOOC designed to introduce K-12 teachers with no prior computer science or robotics experience to the basics of LEGO NXT Robot programming. The course was developed following several successful in-person workshops on the same topic. This paper introduces some of the issues that arose as we transitioned the material to a MOOC, describes some of the unique challenges we faced by incorporating specialized hardware into a MOOC, and presents some preliminary data evaluating the success of our approach.","New York, NY, USA",,"Kay, Jennifer S. and McKlin, Tom",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567886,9.78145E+12,"mooc, lego mindstorms, educational robotics, k-12 teacher education","Atlanta, Georgia, USA",2,211?€?212,Association for Computing Machinery,L@S '14,"The Challenges of Using a MOOC to Introduce ""Absolute Beginners"" to Programming on Specialized Hardware",https://doi.org/10.1145/2556325.2567886,2014
inproceedings,10.1145/2556325.2567887,"This demonstration will showcase a work in progress that implements a new and unique vision for electronic computer science textbooks. It incorporates a number of active components such as video, code editing and execution, and code visualization as a way to enhance the typical static electronic book format. In addition, the textbook is created with an open source authoring system that has been developed to allow the instructor to customize the content of the active and passive parts of the text.","New York, NY, USA",,"Miller, Brad and Ranum, David",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567887,9.78145E+12,"sphinx, interactive textbooks, python, electronic book","Atlanta, Georgia, USA",2,213?€?214,Association for Computing Machinery,L@S '14,Runestone Interactive: Tools for Creating Interactive Course Materials,https://doi.org/10.1145/2556325.2567887,2014
inproceedings,10.1145/2556325.2567888,"Web-CAT, the Web-based Center for Automated Testing, is the most widely used open-source automated grading system for programming assignments in the world. Web-CAT is customizable and extensible, allowing it to support a wide variety of programming languages and assessment strategies. Web-CAT is most well known as the system that ""grades students on how well they test their own code,"" with experimental evidence that it offers greater learning benefits than more traditional output-comparison grading. This work-in-progress demonstration will show how Web-CAT can be used to automatically grade student work, assess conformance with coding style guidelines, provide students with feedback on how well they have tested their own code, and allow instructors to provide directed hints to students on where to focus their attention for improvements.","New York, NY, USA",,"Edwards, Stephen H.",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567888,9.78145E+12,"test-driven development, software testing, static analysis, programming assignments, automated grading, automated marking","Atlanta, Georgia, USA",2,215?€?216,Association for Computing Machinery,L@S '14,Work-in-Progress: Program Grading and Feedback Generation with Web-CAT,https://doi.org/10.1145/2556325.2567888,2014
inproceedings,10.1145/2556325.2567889,"UC Berkeley's CS10 course captures high-definition lectures featuring a unique overlay of the professor over slides. This paper is a brief overview of the demo we presented at L@S 2014. We'll also go into other forms of video we incorporate into the class. Finally, we'll present tips and tricks we've learned in both the pre-production and production stages of the video process.","New York, NY, USA",,"Garcia, Daniel and Ball, Michael and Parikh, Aatash",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567889,9.78145E+12,"production, study resource, cs1, mooc, video","Atlanta, Georgia, USA",2,217?€?218,Association for Computing Machinery,L@S '14,L@S 2014 Demo: Best Practices for MOOC Video,https://doi.org/10.1145/2556325.2567889,2014
inproceedings,10.1145/2556325.2567864,"Hints are sometimes used in online learning system to help students when they are having difficulties. However, in all of the systems we are aware of, the hints are fixed ahead of time and do not depend on the unsuccessful attempts the student has already made. This severely limits the effectiveness of the hints.We have developed an alternative system for giving hints to students. The main difference is that the system allows an instructor to send a hint to a student after the student has made several attempts to solve the problem and failed. After analyzing the student's mistakes, the instructor is better able to understand the problem in the student's thinking and send them a more helpful hint.We have deployed this system in a probability and statistics course with 176 students. We have demonstrated the superiority of the new hints methodology over the traditional one.The limiting factor on the effectiveness of our system is the amount of manual labor required to send each hint. This is the main obstacle we see in scaling this approach to larger classes and to MOOCs. We are currently exploring several approaches for addressing this problem: 1) Letting students send hints to their peers. 2) Creating hint libraries. 3) Using machine learning methods to automate the process of mapping student mistakes to the most relevant hint.","New York, NY, USA",,"Elkherj, Matthew and Freund, Yoav",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567864,9.78145E+12,"real-time intervention, online homework, hints","Atlanta, Georgia, USA",2,219?€?220,Association for Computing Machinery,L@S '14,A System for Sending the Right Hint at the Right Time,https://doi.org/10.1145/2556325.2567864,2014
inproceedings,10.1145/2556325.2567870,"Code Hunt (http://www.codehunt.com/) is an educational coding game (that runs in a browser) for teaching and learning computer science at scale. The game consists of a series of worlds and levels, which get increasingly challenging. In each level, the player has to discover a secret code fragment and write code for it. The game has sounds and a leaderboard to keep the player engaged. Code Hunt targets teachers and students from introductory to advanced programming or software engineering courses. In addition, Code Hunt can be used by seasoned developers to hone their programming skills or by companies to evaluate job candidates. At the core of the game experience is an automated program analysis and grading engine based on dynamic symbolic execution. The engine detects any behavioral differences between the player's code and the secret code fragment. The game works in any modern browser, and currently supports C# or Java programs. Code Hunt is a dramatic evolution of our earlier Pex4Fun web platform, from which we have gathered considerable experience (including over 1.4 million programs submitted by users).","New York, NY, USA",,"Tillmann, Nikolai and de Halleux, Jonathan and Xie, Tao and Bishop, Judith",Proceedings of the First ACM Conference on Learning @ Scale Conference,10.1145/2556325.2567870,9.78145E+12,serious gaming,"Atlanta, Georgia, USA",2,221?€?222,Association for Computing Machinery,L@S '14,Code Hunt: Gamifying Teaching and Learning of Computer Science at Scale,https://doi.org/10.1145/2556325.2567870,2014
